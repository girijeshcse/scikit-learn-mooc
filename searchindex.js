Search.setIndex({"docnames": ["appendix/acknowledgement", "appendix/adult_census_description", "appendix/datasets_intro", "appendix/glossary", "appendix/notebook_timings", "appendix/toc_redirect", "concluding_remarks", "concluding_remarks_video", "ensemble/bagging_slides", "ensemble/boosting_slides", "ensemble/ensemble_boosting_index", "ensemble/ensemble_bootstrap_index", "ensemble/ensemble_hyperparameters_index", "ensemble/ensemble_module_intro", "ensemble/ensemble_module_take_away", "ensemble/ensemble_quiz_m6_01", "ensemble/ensemble_quiz_m6_02", "ensemble/ensemble_quiz_m6_03", "ensemble/ensemble_wrap_up_quiz", "evaluation/cross_validation_baseline_index", "evaluation/cross_validation_choices_index", "evaluation/cross_validation_nested_index", "evaluation/evaluation_module_intro", "evaluation/evaluation_module_take_away", "evaluation/evaluation_quiz_m7_01", "evaluation/evaluation_quiz_m7_02", "evaluation/evaluation_quiz_m7_03", "evaluation/evaluation_quiz_m7_04", "evaluation/evaluation_quiz_m7_05", "evaluation/evaluation_wrap_up_quiz", "evaluation/metrics_classification_index", "evaluation/metrics_regression_index", "feature_selection/feature_selection_limitation_index", "feature_selection/feature_selection_module_intro", "feature_selection/feature_selection_module_take_away", "feature_selection/feature_selection_quiz", "index", "interpretation/interpretation_quiz", "linear_models/linear_models_classification_index", "linear_models/linear_models_intuitions_index", "linear_models/linear_models_module_intro", "linear_models/linear_models_module_take_away", "linear_models/linear_models_non_linear_index", "linear_models/linear_models_quiz_m4_01", "linear_models/linear_models_quiz_m4_02", "linear_models/linear_models_quiz_m4_03", "linear_models/linear_models_quiz_m4_04", "linear_models/linear_models_quiz_m4_05", "linear_models/linear_models_regression_index", "linear_models/linear_models_regularization_index", "linear_models/linear_models_slides", "linear_models/linear_models_wrap_up_quiz", "linear_models/regularized_linear_models_slides", "ml_concepts/quiz_intro_01", "ml_concepts/slides", "overfit/bias_vs_variance_quiz_m2_03", "overfit/bias_vs_variance_slides", "overfit/learning_validation_curves_quiz_m2_02", "overfit/learning_validation_curves_slides", "overfit/overfit_bias_variance_index", "overfit/overfit_module_intro", "overfit/overfit_overfitting_underfitting_index", "overfit/overfit_take_away", "overfit/overfit_validation_learning_curves_index", "overfit/overfit_wrap_up_quiz", "overfit/overfitting_vs_under_fitting_quiz_m2_01", "overfit/overfitting_vs_under_fitting_slides", "predictive_modeling_pipeline/01_tabular_data_exploration_index", "predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01", "predictive_modeling_pipeline/02_numerical_pipeline_index", "predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02", "predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation", "predictive_modeling_pipeline/03_categorical_pipeline_index", "predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03", "predictive_modeling_pipeline/03_categorical_pipeline_visualization_video", "predictive_modeling_pipeline/predictive_modeling_module_intro", "predictive_modeling_pipeline/predictive_modeling_module_take_away", "predictive_modeling_pipeline/wrap_up_quiz", "python_scripts/01_tabular_data_exploration", "python_scripts/01_tabular_data_exploration_ex_01", "python_scripts/01_tabular_data_exploration_sol_01", "python_scripts/02_numerical_pipeline_cross_validation", "python_scripts/02_numerical_pipeline_ex_00", "python_scripts/02_numerical_pipeline_ex_01", "python_scripts/02_numerical_pipeline_hands_on", "python_scripts/02_numerical_pipeline_introduction", "python_scripts/02_numerical_pipeline_scaling", "python_scripts/02_numerical_pipeline_sol_00", "python_scripts/02_numerical_pipeline_sol_01", "python_scripts/03_categorical_pipeline", "python_scripts/03_categorical_pipeline_column_transformer", "python_scripts/03_categorical_pipeline_ex_01", "python_scripts/03_categorical_pipeline_ex_02", "python_scripts/03_categorical_pipeline_sol_01", "python_scripts/03_categorical_pipeline_sol_02", "python_scripts/03_categorical_pipeline_visualization", "python_scripts/cross_validation_baseline", "python_scripts/cross_validation_ex_01", "python_scripts/cross_validation_ex_02", "python_scripts/cross_validation_grouping", "python_scripts/cross_validation_learning_curve", "python_scripts/cross_validation_nested", "python_scripts/cross_validation_sol_01", "python_scripts/cross_validation_sol_02", "python_scripts/cross_validation_stratification", "python_scripts/cross_validation_time", "python_scripts/cross_validation_train_test", "python_scripts/cross_validation_validation_curve", "python_scripts/datasets_ames_housing", "python_scripts/datasets_bike_rides", "python_scripts/datasets_blood_transfusion", "python_scripts/datasets_california_housing", "python_scripts/dev_features_importance", "python_scripts/ensemble_adaboost", "python_scripts/ensemble_bagging", "python_scripts/ensemble_ex_01", "python_scripts/ensemble_ex_02", "python_scripts/ensemble_ex_03", "python_scripts/ensemble_ex_04", "python_scripts/ensemble_gradient_boosting", "python_scripts/ensemble_hist_gradient_boosting", "python_scripts/ensemble_hyperparameters", "python_scripts/ensemble_introduction", "python_scripts/ensemble_random_forest", "python_scripts/ensemble_sol_01", "python_scripts/ensemble_sol_02", "python_scripts/ensemble_sol_03", "python_scripts/ensemble_sol_04", "python_scripts/feature_selection_ex_01", "python_scripts/feature_selection_introduction", "python_scripts/feature_selection_limitation_model", "python_scripts/feature_selection_sol_01", "python_scripts/linear_models_ex_01", "python_scripts/linear_models_ex_02", "python_scripts/linear_models_ex_03", "python_scripts/linear_models_ex_04", "python_scripts/linear_models_ex_05", "python_scripts/linear_models_regularization", "python_scripts/linear_models_sol_01", "python_scripts/linear_models_sol_02", "python_scripts/linear_models_sol_03", "python_scripts/linear_models_sol_04", "python_scripts/linear_models_sol_05", "python_scripts/linear_regression_in_sklearn", "python_scripts/linear_regression_non_linear_link", "python_scripts/linear_regression_without_sklearn", "python_scripts/logistic_regression", "python_scripts/logistic_regression_non_linear", "python_scripts/metrics_classification", "python_scripts/metrics_ex_01", "python_scripts/metrics_ex_02", "python_scripts/metrics_regression", "python_scripts/metrics_sol_01", "python_scripts/metrics_sol_02", "python_scripts/parameter_tuning_ex_02", "python_scripts/parameter_tuning_ex_03", "python_scripts/parameter_tuning_grid_search", "python_scripts/parameter_tuning_manual", "python_scripts/parameter_tuning_nested", "python_scripts/parameter_tuning_parallel_plot", "python_scripts/parameter_tuning_randomized_search", "python_scripts/parameter_tuning_sol_02", "python_scripts/parameter_tuning_sol_03", "python_scripts/trees_classification", "python_scripts/trees_dataset", "python_scripts/trees_ex_01", "python_scripts/trees_ex_02", "python_scripts/trees_hyperparameters", "python_scripts/trees_regression", "python_scripts/trees_sol_01", "python_scripts/trees_sol_02", "toc", "trees/slides", "trees/trees_classification_index", "trees/trees_hyperparameters_index", "trees/trees_intuitions_index", "trees/trees_module_intro", "trees/trees_module_take_away", "trees/trees_quiz_m5_01", "trees/trees_quiz_m5_02", "trees/trees_quiz_m5_03", "trees/trees_quiz_m5_04", "trees/trees_regression_index", "trees/trees_wrap_up_quiz", "tuning/parameter_tuning_automated_index", "tuning/parameter_tuning_automated_quiz_m3_02", "tuning/parameter_tuning_manual_index", "tuning/parameter_tuning_manual_quiz_m3_01", "tuning/parameter_tuning_module_intro", "tuning/parameter_tuning_module_take_away", "tuning/parameter_tuning_parallel_plot_video", "tuning/parameter_tuning_wrap_up_quiz"], "filenames": ["appendix/acknowledgement.md", "appendix/adult_census_description.md", "appendix/datasets_intro.md", "appendix/glossary.md", "appendix/notebook_timings.md", "appendix/toc_redirect.md", "concluding_remarks.md", "concluding_remarks_video.md", "ensemble/bagging_slides.md", "ensemble/boosting_slides.md", "ensemble/ensemble_boosting_index.md", "ensemble/ensemble_bootstrap_index.md", "ensemble/ensemble_hyperparameters_index.md", "ensemble/ensemble_module_intro.md", "ensemble/ensemble_module_take_away.md", "ensemble/ensemble_quiz_m6_01.md", "ensemble/ensemble_quiz_m6_02.md", "ensemble/ensemble_quiz_m6_03.md", "ensemble/ensemble_wrap_up_quiz.md", "evaluation/cross_validation_baseline_index.md", "evaluation/cross_validation_choices_index.md", "evaluation/cross_validation_nested_index.md", "evaluation/evaluation_module_intro.md", "evaluation/evaluation_module_take_away.md", "evaluation/evaluation_quiz_m7_01.md", "evaluation/evaluation_quiz_m7_02.md", "evaluation/evaluation_quiz_m7_03.md", "evaluation/evaluation_quiz_m7_04.md", "evaluation/evaluation_quiz_m7_05.md", "evaluation/evaluation_wrap_up_quiz.md", "evaluation/metrics_classification_index.md", "evaluation/metrics_regression_index.md", "feature_selection/feature_selection_limitation_index.md", "feature_selection/feature_selection_module_intro.md", "feature_selection/feature_selection_module_take_away.md", "feature_selection/feature_selection_quiz.md", "index.md", "interpretation/interpretation_quiz.md", "linear_models/linear_models_classification_index.md", "linear_models/linear_models_intuitions_index.md", "linear_models/linear_models_module_intro.md", "linear_models/linear_models_module_take_away.md", "linear_models/linear_models_non_linear_index.md", "linear_models/linear_models_quiz_m4_01.md", "linear_models/linear_models_quiz_m4_02.md", "linear_models/linear_models_quiz_m4_03.md", "linear_models/linear_models_quiz_m4_04.md", "linear_models/linear_models_quiz_m4_05.md", "linear_models/linear_models_regression_index.md", "linear_models/linear_models_regularization_index.md", "linear_models/linear_models_slides.md", "linear_models/linear_models_wrap_up_quiz.md", "linear_models/regularized_linear_models_slides.md", "ml_concepts/quiz_intro_01.md", "ml_concepts/slides.md", "overfit/bias_vs_variance_quiz_m2_03.md", "overfit/bias_vs_variance_slides.md", "overfit/learning_validation_curves_quiz_m2_02.md", "overfit/learning_validation_curves_slides.md", "overfit/overfit_bias_variance_index.md", "overfit/overfit_module_intro.md", "overfit/overfit_overfitting_underfitting_index.md", "overfit/overfit_take_away.md", "overfit/overfit_validation_learning_curves_index.md", "overfit/overfit_wrap_up_quiz.md", "overfit/overfitting_vs_under_fitting_quiz_m2_01.md", "overfit/overfitting_vs_under_fitting_slides.md", "predictive_modeling_pipeline/01_tabular_data_exploration_index.md", "predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01.md", "predictive_modeling_pipeline/02_numerical_pipeline_index.md", "predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02.md", "predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation.md", "predictive_modeling_pipeline/03_categorical_pipeline_index.md", "predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03.md", "predictive_modeling_pipeline/03_categorical_pipeline_visualization_video.md", "predictive_modeling_pipeline/predictive_modeling_module_intro.md", "predictive_modeling_pipeline/predictive_modeling_module_take_away.md", "predictive_modeling_pipeline/wrap_up_quiz.md", "python_scripts/01_tabular_data_exploration.py", "python_scripts/01_tabular_data_exploration_ex_01.py", "python_scripts/01_tabular_data_exploration_sol_01.py", "python_scripts/02_numerical_pipeline_cross_validation.py", "python_scripts/02_numerical_pipeline_ex_00.py", "python_scripts/02_numerical_pipeline_ex_01.py", "python_scripts/02_numerical_pipeline_hands_on.py", "python_scripts/02_numerical_pipeline_introduction.py", "python_scripts/02_numerical_pipeline_scaling.py", "python_scripts/02_numerical_pipeline_sol_00.py", "python_scripts/02_numerical_pipeline_sol_01.py", "python_scripts/03_categorical_pipeline.py", "python_scripts/03_categorical_pipeline_column_transformer.py", "python_scripts/03_categorical_pipeline_ex_01.py", "python_scripts/03_categorical_pipeline_ex_02.py", "python_scripts/03_categorical_pipeline_sol_01.py", "python_scripts/03_categorical_pipeline_sol_02.py", "python_scripts/03_categorical_pipeline_visualization.py", "python_scripts/cross_validation_baseline.py", "python_scripts/cross_validation_ex_01.py", "python_scripts/cross_validation_ex_02.py", "python_scripts/cross_validation_grouping.py", "python_scripts/cross_validation_learning_curve.py", "python_scripts/cross_validation_nested.py", "python_scripts/cross_validation_sol_01.py", "python_scripts/cross_validation_sol_02.py", "python_scripts/cross_validation_stratification.py", "python_scripts/cross_validation_time.py", "python_scripts/cross_validation_train_test.py", "python_scripts/cross_validation_validation_curve.py", "python_scripts/datasets_ames_housing.py", "python_scripts/datasets_bike_rides.py", "python_scripts/datasets_blood_transfusion.py", "python_scripts/datasets_california_housing.py", "python_scripts/dev_features_importance.py", "python_scripts/ensemble_adaboost.py", "python_scripts/ensemble_bagging.py", "python_scripts/ensemble_ex_01.py", "python_scripts/ensemble_ex_02.py", "python_scripts/ensemble_ex_03.py", "python_scripts/ensemble_ex_04.py", "python_scripts/ensemble_gradient_boosting.py", "python_scripts/ensemble_hist_gradient_boosting.py", "python_scripts/ensemble_hyperparameters.py", "python_scripts/ensemble_introduction.py", "python_scripts/ensemble_random_forest.py", "python_scripts/ensemble_sol_01.py", "python_scripts/ensemble_sol_02.py", "python_scripts/ensemble_sol_03.py", "python_scripts/ensemble_sol_04.py", "python_scripts/feature_selection_ex_01.py", "python_scripts/feature_selection_introduction.py", "python_scripts/feature_selection_limitation_model.py", "python_scripts/feature_selection_sol_01.py", "python_scripts/linear_models_ex_01.py", "python_scripts/linear_models_ex_02.py", "python_scripts/linear_models_ex_03.py", "python_scripts/linear_models_ex_04.py", "python_scripts/linear_models_ex_05.py", "python_scripts/linear_models_regularization.py", "python_scripts/linear_models_sol_01.py", "python_scripts/linear_models_sol_02.py", "python_scripts/linear_models_sol_03.py", "python_scripts/linear_models_sol_04.py", "python_scripts/linear_models_sol_05.py", "python_scripts/linear_regression_in_sklearn.py", "python_scripts/linear_regression_non_linear_link.py", "python_scripts/linear_regression_without_sklearn.py", "python_scripts/logistic_regression.py", "python_scripts/logistic_regression_non_linear.py", "python_scripts/metrics_classification.py", "python_scripts/metrics_ex_01.py", "python_scripts/metrics_ex_02.py", "python_scripts/metrics_regression.py", "python_scripts/metrics_sol_01.py", "python_scripts/metrics_sol_02.py", "python_scripts/parameter_tuning_ex_02.py", "python_scripts/parameter_tuning_ex_03.py", "python_scripts/parameter_tuning_grid_search.py", "python_scripts/parameter_tuning_manual.py", "python_scripts/parameter_tuning_nested.py", "python_scripts/parameter_tuning_parallel_plot.py", "python_scripts/parameter_tuning_randomized_search.py", "python_scripts/parameter_tuning_sol_02.py", "python_scripts/parameter_tuning_sol_03.py", "python_scripts/trees_classification.py", "python_scripts/trees_dataset.py", "python_scripts/trees_ex_01.py", "python_scripts/trees_ex_02.py", "python_scripts/trees_hyperparameters.py", "python_scripts/trees_regression.py", "python_scripts/trees_sol_01.py", "python_scripts/trees_sol_02.py", "toc.md", "trees/slides.md", "trees/trees_classification_index.md", "trees/trees_hyperparameters_index.md", "trees/trees_intuitions_index.md", "trees/trees_module_intro.md", "trees/trees_module_take_away.md", "trees/trees_quiz_m5_01.md", "trees/trees_quiz_m5_02.md", "trees/trees_quiz_m5_03.md", "trees/trees_quiz_m5_04.md", "trees/trees_regression_index.md", "trees/trees_wrap_up_quiz.md", "tuning/parameter_tuning_automated_index.md", "tuning/parameter_tuning_automated_quiz_m3_02.md", "tuning/parameter_tuning_manual_index.md", "tuning/parameter_tuning_manual_quiz_m3_01.md", "tuning/parameter_tuning_module_intro.md", "tuning/parameter_tuning_module_take_away.md", "tuning/parameter_tuning_parallel_plot_video.md", "tuning/parameter_tuning_wrap_up_quiz.md"], "titles": ["Acknowledgement", "The adult census dataset", "Datasets description", "Glossary", "Notebook timings", "Table of contents", "Concluding remarks", "\ud83c\udfa5 Concluding remarks", "\ud83c\udfa5 Intuitions on ensemble models: bagging", "\ud83c\udfa5 Intuitions on ensemble models: boosting", "Ensemble based on boosting", "Ensemble method using bootstrapping", "Hyperparameter tuning with ensemble methods", "Module overview", "Main take-away", "\u2705 Quiz M6.01", "\u2705 Quiz M6.02", "\u2705 Quiz M6.03", "\ud83c\udfc1 Wrap-up quiz 6", "Comparing a model with simple baselines", "Choice of cross-validation", "Nested cross-validation", "Module overview", "Main take-away", "\u2705 Quiz M7.01", "\u2705 Quiz M7.02", "\u2705 Quiz M7.03", "\u2705 Quiz M7.04", "\u2705 Quiz M7.05", "\ud83c\udfc1 Wrap-up quiz 7", "Classification metrics", "Regression metrics", "Caveats of feature selection", "Module overview", "Main take-away", "\u2705 Quiz", "Introduction", "\u2705 Quiz", "Linear model for classification", "Intuitions on linear models", "Module overview", "Main take-away", "Modelling non-linear features-target relationships", "\u2705 Quiz M4.01", "\u2705 Quiz M4.02", "\u2705 Quiz M4.03", "\u2705 Quiz M4.04", "\u2705 Quiz M4.05", "Linear regression", "Regularization in linear model", "\ud83c\udfa5 Intuitions on linear models", "\ud83c\udfc1 Wrap-up quiz 4", "\ud83c\udfa5 Intuitions on regularized linear models", "\u2705 Quiz Intro.01", "\ud83c\udfa5 Introducing machine-learning concepts", "\u2705 Quiz M2.03", "\ud83c\udfa5 Bias versus Variance", "\u2705 Quiz M2.02", "\ud83c\udfa5 Comparing train and test errors", "Bias versus variance trade-off", "Module overview", "Overfitting and underfitting", "Main take-away", "Validation and learning curves", "\ud83c\udfc1 Wrap-up quiz 2", "\u2705 Quiz M2.01", "\ud83c\udfa5 Overfitting and Underfitting", "Tabular data exploration", "\u2705 Quiz M1.01", "Fitting a scikit-learn model on numerical data", "\u2705 Quiz M1.02", "\ud83c\udfa5 Validation of a model", "Handling categorical data", "\u2705 Quiz M1.03", "\ud83c\udfa5 Visualizing scikit-learn pipelines in Jupyter", "Module overview", "Main take-away", "\ud83c\udfc1 Wrap-up quiz 1", "First look at our dataset", "\ud83d\udcdd Exercise M1.01", "\ud83d\udcc3 Solution for Exercise M1.01", "Model evaluation using cross-validation", "\ud83d\udcdd Exercise M1.02", "\ud83d\udcdd Exercise M1.03", "Working with numerical data", "First model with scikit-learn", "Preprocessing for numerical features", "\ud83d\udcc3 Solution for Exercise M1.02", "\ud83d\udcc3 Solution for Exercise M1.03", "Encoding of categorical variables", "Using numerical and categorical variables together", "\ud83d\udcdd Exercise M1.04", "\ud83d\udcdd Exercise M1.05", "\ud83d\udcc3 Solution for Exercise M1.04", "\ud83d\udcc3 Solution for Exercise M1.05", "Visualizing scikit-learn pipelines in Jupyter", "Comparing model performance with a simple baseline", "\ud83d\udcdd Exercise M2.01", "\ud83d\udcdd Exercise M7.01", "Sample grouping", "Effect of the sample size in cross-validation", "Nested cross-validation", "\ud83d\udcc3 Solution for Exercise M2.01", "\ud83d\udcc3 Solution for Exercise M7.01", "Stratification", "Non i.i.d. data", "Cross-validation framework", "Overfit-generalization-underfit", "The Ames housing dataset", "The bike rides dataset", "The blood transfusion dataset", "The California housing dataset", "Feature importance", "Adaptive Boosting (AdaBoost)", "Bagging", "\ud83d\udcdd Exercise M6.01", "\ud83d\udcdd Exercise M6.02", "\ud83d\udcdd Exercise M6.03", "\ud83d\udcdd Exercise M6.04", "Gradient-boosting decision tree (GBDT)", "Speeding-up gradient-boosting", "Hyperparameter tuning", "Introductory example to ensemble models", "Random forests", "\ud83d\udcc3 Solution for Exercise M6.01", "\ud83d\udcc3 Solution for Exercise M6.02", "\ud83d\udcc3 Solution for Exercise M6.03", "\ud83d\udcc3 Solution for Exercise M6.04", "\ud83d\udcdd Exercise 01", "Benefits of using feature selection", "Limitation of selecting feature using a model", "\ud83d\udcc3 Solution for Exercise 01", "\ud83d\udcdd Exercise M4.01", "\ud83d\udcdd Exercise M4.02", "\ud83d\udcdd Exercise M4.03", "\ud83d\udcdd Exercise M4.04", "\ud83d\udcdd Exercise M4.05", "Regularization of linear regression model", "\ud83d\udcc3 Solution for Exercise M4.01", "\ud83d\udcc3 Solution for Exercise M4.02", "\ud83d\udcc3 Solution for Exercise M4.03", "\ud83d\udcc3 Solution for Exercise M4.04", "\ud83d\udcc3 Solution for Exercise M4.05", "Linear regression using scikit-learn", "Linear regression for a non-linear features-target relationship", "Linear regression without scikit-learn", "Linear model for classification", "Beyond linear separation in classification", "Classification", "\ud83d\udcdd Exercise M7.02", "\ud83d\udcdd Exercise M7.03", "Regression", "\ud83d\udcc3 Solution for Exercise M7.02", "\ud83d\udcc3 Solution for Exercise M7.03", "\ud83d\udcdd Exercise M3.01", "\ud83d\udcdd Exercise M3.02", "Hyperparameter tuning by grid-search", "Set and get hyperparameters in scikit-learn", "Evaluation and hyperparameter tuning", "Analysis of hyperparameter search results", "Hyperparameter tuning by randomized-search", "\ud83d\udcc3 Solution for Exercise M3.01", "\ud83d\udcc3 Solution for Exercise M3.02", "Build a classification decision tree", "The penguins datasets", "\ud83d\udcdd Exercise M5.01", "\ud83d\udcdd Exercise M5.02", "Importance of decision tree hyperparameters on generalization", "Decision tree for regression", "\ud83d\udcc3 Solution for Exercise M5.01", "\ud83d\udcc3 Solution for Exercise M5.02", "Table of contents", "\ud83c\udfa5 Intuitions on tree-based models", "Decision tree in classification", "Hyperparameters of decision tree", "Intuitions on tree-based models", "Module overview", "Main take-away", "\u2705 Quiz M5.01", "\u2705 Quiz M5.02", "\u2705 Quiz M5.03", "\u2705 Quiz M5.04", "Decision tree in regression", "\ud83c\udfc1 Wrap-up quiz 5", "Automated tuning", "\u2705 Quiz M3.02", "Manual tuning", "\u2705 Quiz M3.01", "Module overview", "Main take-away", "\ud83c\udfa5 Analysis of hyperparameter search results", "\ud83c\udfc1 Wrap-up quiz 3"], "terms": {"The": [0, 2, 3, 13, 18, 22, 33, 36, 37, 40, 46, 47, 51, 53, 60, 62, 64, 70, 75, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 176, 178, 180, 183, 188, 189, 191], "diagram": [0, 3, 86], "present": [0, 8, 9, 13, 22, 23, 29, 34, 40, 50, 51, 52, 54, 56, 58, 60, 66, 71, 75, 77, 78, 85, 89, 96, 100, 104, 105, 107, 108, 109, 110, 111, 113, 114, 119, 120, 122, 123, 130, 137, 141, 143, 145, 148, 149, 151, 152, 158, 160, 164, 168, 172, 176, 177, 178], "api": [0, 6, 76, 82, 85, 87, 90, 148], "design": [0, 6, 36, 84, 108, 144, 151], "modul": [0, 1, 14, 18, 23, 34, 36, 41, 62, 76, 78, 84, 90, 111, 148, 156, 157, 158, 165, 169, 171, 177, 189], "predict": [0, 1, 13, 16, 18, 22, 23, 24, 25, 29, 33, 36, 40, 41, 43, 45, 51, 53, 55, 60, 62, 64, 65, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 119, 121, 122, 123, 124, 125, 126, 128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 151, 155, 157, 159, 162, 163, 164, 166, 167, 168, 169, 170, 176, 180, 183, 188, 191], "model": [0, 1, 10, 11, 13, 14, 15, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 51, 55, 57, 60, 62, 64, 65, 68, 70, 73, 75, 76, 77, 78, 80, 82, 83, 84, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 114, 115, 117, 118, 120, 121, 123, 124, 126, 127, 128, 129, 131, 133, 134, 135, 136, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 161, 162, 163, 166, 167, 168, 170, 176, 177, 183, 185, 187, 188, 189, 191], "pipelin": [0, 1, 3, 13, 22, 33, 34, 36, 40, 45, 51, 54, 60, 64, 70, 72, 75, 76, 77, 81, 86, 90, 91, 93, 97, 98, 99, 101, 102, 103, 104, 108, 111, 112, 120, 123, 128, 129, 130, 131, 136, 137, 141, 142, 144, 146, 147, 154, 155, 156, 157, 158, 160, 161, 162, 176, 185, 187, 188, 191], "us": [0, 14, 17, 18, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 40, 41, 45, 46, 47, 48, 51, 53, 60, 64, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 178, 179, 183, 185, 188, 191], "follow": [0, 3, 13, 14, 17, 18, 22, 23, 27, 29, 33, 34, 41, 46, 51, 53, 60, 62, 64, 70, 73, 75, 76, 77, 78, 82, 85, 86, 87, 89, 90, 97, 98, 99, 101, 102, 103, 105, 112, 114, 118, 119, 123, 127, 136, 142, 144, 145, 147, 148, 151, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 168, 176, 177, 183, 185, 188, 189, 191], "paramet": [0, 6, 15, 18, 26, 27, 28, 29, 37, 41, 44, 46, 47, 51, 57, 60, 62, 64, 70, 77, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 97, 101, 102, 103, 106, 107, 112, 113, 114, 115, 117, 118, 121, 122, 123, 124, 126, 127, 130, 133, 136, 139, 141, 142, 143, 145, 146, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 176, 183, 185, 187, 188, 191], "free": [0, 6, 36, 118, 121, 127, 191], "icon": [0, 36], "licens": [0, 36], "under": [0, 24, 29, 36, 41, 78, 97, 102, 107, 122, 147, 148, 151, 167, 176], "cc": [0, 36], "BY": [0, 36], "3": [0, 4, 18, 29, 36, 44, 51, 60, 64, 77, 78, 80, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 124, 125, 127, 129, 130, 133, 134, 137, 139, 140, 141, 144, 145, 148, 149, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 166, 167, 168, 169, 170, 171, 176, 183, 188], "0": [0, 3, 4, 18, 29, 37, 51, 70, 77, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 183, 185, 191], "sourc": [0, 121], "set": [0, 6, 18, 26, 29, 35, 37, 40, 41, 43, 46, 47, 55, 57, 60, 62, 64, 65, 68, 70, 77, 78, 81, 83, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 156, 158, 160, 161, 162, 163, 164, 167, 168, 171, 181, 183, 185, 186, 187, 188, 191], "gear": 0, "svg": 0, "vector": [0, 44, 45, 97, 102, 104, 106, 119, 128, 131, 132, 133, 138, 139, 144, 147, 148], "cc0": 0, "close": [0, 3, 29, 46, 53, 78, 86, 101, 104, 105, 106, 111, 112, 119, 126, 127, 135, 137, 141, 143, 144, 156, 158, 160, 163], "mit": 0, "thi": [1, 13, 14, 18, 22, 23, 27, 29, 33, 34, 36, 40, 41, 45, 51, 53, 54, 60, 62, 64, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 176, 177, 180, 183, 185, 188, 189, 191], "collect": [1, 3, 6, 29, 78, 81, 98, 103, 106, 107, 122, 129], "inform": [1, 6, 24, 29, 51, 78, 81, 85, 89, 90, 96, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 119, 121, 122, 129, 130, 135, 137, 141, 144, 146, 148, 149, 152, 156, 157, 160, 162, 164], "relat": [1, 3, 14, 18, 23, 34, 41, 60, 62, 76, 78, 90, 148, 177, 188, 189], "person": [1, 6, 68, 78, 84, 110, 148, 156], "task": [1, 6, 78, 84, 95, 106, 110, 178], "whether": [1, 3, 68, 77, 78, 81, 86, 90, 92, 94, 95, 97, 102, 106, 107, 110, 112, 148, 156, 158, 162, 166, 167, 170], "earn": [1, 78, 156], "salari": [1, 68, 111, 133, 139], "abov": [1, 3, 6, 18, 29, 51, 78, 82, 86, 87, 89, 95, 101, 104, 106, 107, 111, 112, 114, 119, 120, 132, 137, 138, 145, 147, 148, 149, 152, 156, 158, 162, 164, 166, 168, 169, 170, 183, 185, 191], "below": [1, 3, 18, 51, 64, 81, 88, 89, 95, 111, 112, 120, 126, 132, 133, 138, 139, 145, 148, 160, 163, 164, 166, 169, 170, 183, 185, 187, 191], "50": [1, 18, 29, 33, 64, 78, 82, 84, 86, 87, 96, 103, 104, 106, 107, 108, 109, 110, 111, 117, 119, 120, 121, 122, 123, 126, 151, 156, 157, 159, 160], "k": [1, 3, 25, 64, 81, 84, 85, 86, 96, 100, 106, 107, 113, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 129, 130, 131, 134, 137, 140, 151, 153, 155, 156, 158, 159, 162, 188], "we": [1, 3, 13, 14, 18, 22, 23, 25, 28, 29, 33, 34, 37, 40, 41, 44, 51, 53, 57, 60, 62, 64, 68, 70, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 176, 177, 183, 185, 188, 191], "extens": [1, 106], "explor": [1, 6, 51, 79, 80, 84, 102, 116, 118, 125, 127, 137, 155, 156, 158, 159, 160, 162, 171, 191], "first": [1, 8, 9, 29, 50, 52, 54, 56, 58, 60, 66, 67, 68, 69, 71, 75, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 118, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 147, 148, 149, 150, 152, 153, 156, 158, 164, 166, 167, 168, 170, 171, 172, 188], "sequenc": [1, 89, 119, 154, 161], "tabular": [1, 6, 68, 75, 78, 85, 90, 171], "data": [1, 18, 20, 22, 23, 24, 28, 29, 36, 40, 41, 46, 51, 62, 64, 68, 70, 73, 75, 76, 77, 79, 80, 82, 83, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 179, 183, 185, 188, 191], "notebook": [1, 18, 23, 36, 51, 68, 77, 80, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 119, 120, 121, 122, 123, 124, 126, 129, 130, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 151, 152, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 168, 169, 170, 171, 185], "look": [1, 6, 29, 51, 67, 68, 70, 79, 80, 82, 84, 85, 87, 89, 99, 100, 102, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 121, 136, 137, 142, 144, 145, 147, 148, 156, 163, 164, 171, 185, 191], "our": [1, 6, 18, 29, 44, 51, 67, 68, 75, 81, 83, 84, 85, 86, 88, 90, 91, 93, 95, 96, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 117, 118, 119, 121, 126, 127, 128, 129, 131, 132, 136, 137, 138, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 157, 159, 163, 164, 168, 170, 171, 191], "To": [1, 3, 8, 9, 29, 37, 50, 51, 52, 54, 56, 58, 66, 71, 77, 78, 84, 85, 86, 90, 91, 93, 97, 99, 100, 101, 102, 104, 105, 106, 107, 112, 113, 114, 117, 120, 121, 126, 129, 133, 139, 143, 144, 147, 148, 160, 162, 165, 168, 169, 172, 183], "avoid": [1, 3, 6, 41, 77, 78, 101, 112, 113, 114, 117, 125, 126, 131, 143, 156, 159, 160, 162], "repeat": [1, 3, 18, 29, 51, 62, 64, 81, 83, 88, 91, 93, 99, 100, 101, 104, 106, 107, 129, 135, 141, 147, 149, 152, 155, 162, 163, 165, 166, 168, 169, 170, 191], "same": [1, 18, 26, 29, 37, 41, 46, 51, 70, 78, 83, 84, 85, 86, 88, 89, 90, 94, 99, 100, 101, 103, 104, 106, 107, 108, 112, 113, 114, 119, 120, 129, 132, 135, 137, 138, 141, 143, 144, 145, 147, 148, 151, 159, 160, 168, 183, 191], "redirect": 1, "reader": [1, 78, 114, 144, 146], "particular": [1, 3, 6, 27, 75, 78, 81, 82, 84, 85, 87, 90, 94, 96, 101, 102, 106, 123, 148, 156, 158, 159, 162], "penguin": [2, 18, 79, 80, 113, 116, 125, 132, 136, 138, 142, 143, 145, 146, 163, 165, 166, 168, 169, 170, 171, 191], "adult": [2, 51, 68, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 98, 103, 123, 154, 156, 157, 158, 160, 161, 171], "censu": [2, 51, 68, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 98, 103, 106, 111, 123, 154, 156, 157, 158, 160, 161, 171], "california": [2, 96, 106, 108, 112, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 134, 137, 140, 171], "hous": [2, 3, 53, 77, 95, 96, 100, 106, 107, 112, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 134, 137, 140, 141, 150, 151, 153, 171], "am": [2, 141, 150, 151, 153, 171], "blood": [2, 97, 102, 148, 149, 152, 171], "transfus": [2, 97, 102, 148, 149, 152, 171], "bike": [2, 29, 171], "ride": [2, 29, 171], "aim": [3, 36, 84, 97, 102, 105, 106, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 128, 129, 131, 132, 134, 138, 140, 148, 149, 152, 165, 166, 169, 170], "describ": [3, 73, 84, 85, 86, 96, 111, 191], "For": [3, 6, 36, 51, 57, 62, 75, 78, 81, 84, 85, 86, 89, 90, 95, 96, 99, 101, 103, 106, 107, 109, 111, 112, 116, 117, 119, 121, 123, 125, 126, 128, 129, 130, 131, 133, 137, 139, 144, 145, 146, 148, 151, 156, 157, 158, 160, 167, 170, 179, 183, 188], "you": [3, 6, 14, 18, 23, 29, 34, 36, 41, 51, 54, 62, 64, 70, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 100, 102, 103, 104, 106, 107, 109, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 177, 181, 183, 185, 187, 189, 191], "don": [3, 6, 82, 87, 97, 102, 106, 110, 128, 131, 156], "t": [3, 6, 82, 87, 89, 97, 99, 102, 105, 106, 110, 112, 120, 127, 128, 131, 137, 141, 148, 152, 156], "find": [3, 6, 53, 62, 78, 84, 85, 86, 89, 97, 98, 101, 102, 103, 105, 107, 115, 116, 118, 124, 125, 127, 130, 131, 133, 135, 136, 137, 139, 141, 142, 143, 147, 154, 155, 156, 158, 160, 161, 162, 165, 166, 169, 170, 176, 185], "ad": [3, 18, 41, 57, 97, 100, 102, 112, 117, 123, 126, 141, 144, 147, 156, 160], "bottom": [3, 78, 148], "page": [3, 36, 84, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "type": [3, 14, 23, 29, 45, 54, 75, 76, 78, 84, 85, 91, 92, 93, 94, 106, 108, 109, 110, 111, 114, 128, 131, 136, 142, 148, 151, 183], "problem": [3, 15, 18, 22, 29, 40, 41, 46, 51, 53, 54, 60, 64, 68, 77, 78, 83, 88, 89, 91, 93, 95, 97, 99, 102, 103, 104, 106, 109, 110, 111, 119, 129, 133, 137, 139, 141, 143, 144, 145, 146, 148, 151, 156, 158, 159, 162, 163, 164, 167, 168, 176, 177, 183, 191], "where": [3, 6, 29, 41, 44, 45, 47, 51, 64, 73, 77, 81, 86, 91, 93, 97, 99, 102, 104, 106, 111, 112, 117, 123, 126, 129, 137, 144, 145, 146, 147, 156, 158, 160, 162, 163, 167, 185, 191], "goal": [3, 36, 78, 81, 82, 83, 87, 88, 91, 92, 93, 94, 95, 99, 121, 122, 123, 129, 133, 139, 151, 154, 155, 161, 162, 191], "can": [3, 6, 14, 15, 18, 22, 23, 25, 28, 29, 34, 36, 40, 41, 46, 51, 57, 60, 62, 64, 70, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 177, 178, 180, 183, 185, 188, 189, 191], "take": [3, 16, 29, 78, 81, 84, 85, 86, 90, 94, 96, 98, 99, 101, 103, 105, 106, 108, 109, 110, 111, 114, 132, 138, 141, 145, 148, 156, 159, 160, 171, 183, 185], "finit": [3, 68, 73, 78, 89], "valu": [3, 13, 15, 18, 24, 28, 29, 36, 37, 41, 43, 46, 51, 53, 64, 68, 70, 73, 77, 78, 82, 84, 87, 89, 90, 91, 93, 96, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 129, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 179, 180, 183, 185, 187, 188, 191], "exampl": [3, 6, 11, 14, 23, 34, 41, 53, 62, 75, 76, 78, 81, 83, 86, 88, 89, 90, 95, 96, 99, 104, 105, 109, 113, 114, 120, 123, 129, 137, 138, 144, 145, 147, 151, 156, 157, 167, 171, 177, 188, 189], "ar": [3, 13, 14, 15, 16, 17, 18, 22, 23, 25, 27, 28, 29, 33, 34, 36, 37, 40, 41, 45, 51, 53, 57, 60, 62, 64, 70, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 89, 90, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 135, 137, 138, 141, 143, 144, 145, 146, 147, 148, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 176, 177, 179, 183, 185, 187, 188, 189, 191], "iri": [3, 104], "setosa": 3, "versicolor": 3, "virginica": 3, "from": [3, 6, 14, 18, 24, 25, 29, 36, 37, 46, 51, 53, 60, 62, 64, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 178, 180, 183, 185, 187, 188, 191], "petal": 3, "sepal": 3, "measur": [3, 6, 18, 29, 70, 79, 80, 81, 84, 109, 112, 126, 129, 132, 138, 145, 148, 158, 163, 164], "patient": [3, 6, 25], "ha": [3, 25, 37, 45, 46, 51, 68, 75, 77, 78, 84, 86, 88, 89, 90, 94, 99, 103, 106, 107, 108, 111, 112, 113, 114, 120, 121, 126, 137, 143, 145, 148, 149, 151, 152, 155, 157, 160, 162, 163, 169, 183, 185, 191], "diseas": [3, 6, 25, 78], "result": [3, 29, 70, 78, 81, 83, 84, 85, 86, 88, 89, 90, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 114, 117, 118, 119, 121, 122, 123, 126, 127, 128, 129, 130, 131, 133, 137, 139, 141, 143, 144, 148, 151, 156, 157, 158, 160, 162, 163, 169, 171, 184, 185, 191], "medic": [3, 6, 78], "an": [3, 16, 22, 23, 26, 35, 36, 41, 44, 45, 51, 53, 55, 57, 60, 62, 73, 75, 76, 77, 78, 81, 85, 86, 88, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 109, 110, 111, 112, 114, 117, 119, 120, 121, 122, 123, 126, 128, 129, 131, 133, 136, 137, 138, 139, 141, 142, 143, 144, 147, 148, 149, 151, 152, 154, 156, 157, 158, 161, 162, 163, 167, 168, 169, 176, 179, 183, 185, 187, 188, 189, 191], "email": 3, "spam": 3, "content": [3, 84, 90, 108, 156], "sender": 3, "titl": [3, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 127, 129, 130, 137, 140, 142, 143, 145, 146, 147, 148, 151, 152, 159, 163, 167, 168, 169, 170], "etc": [3, 29, 36, 78, 89, 101, 109, 122], "when": [3, 6, 16, 17, 18, 22, 23, 27, 28, 29, 35, 41, 46, 57, 62, 64, 70, 77, 78, 81, 84, 85, 86, 89, 90, 91, 93, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 117, 119, 120, 121, 123, 126, 127, 128, 129, 130, 131, 133, 135, 137, 139, 141, 143, 145, 146, 147, 148, 151, 153, 156, 157, 158, 160, 163, 164, 180, 185, 188, 189], "have": [3, 25, 29, 53, 57, 62, 64, 70, 73, 78, 81, 83, 84, 85, 86, 88, 89, 93, 96, 100, 101, 104, 105, 106, 108, 109, 110, 111, 112, 113, 116, 119, 120, 121, 122, 123, 125, 126, 128, 129, 131, 134, 137, 138, 140, 141, 144, 145, 146, 147, 148, 151, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 169, 176, 183, 185, 188, 189, 191], "two": [3, 13, 14, 29, 37, 51, 68, 70, 77, 78, 79, 80, 84, 85, 86, 89, 90, 99, 101, 103, 104, 106, 107, 108, 110, 112, 119, 121, 122, 129, 130, 131, 132, 137, 138, 141, 143, 144, 146, 147, 148, 154, 156, 158, 159, 160, 161, 162, 163, 164, 166, 168, 169, 170, 183, 191], "call": [3, 13, 14, 29, 46, 47, 62, 64, 70, 73, 77, 78, 84, 85, 86, 89, 90, 91, 93, 96, 97, 100, 102, 103, 106, 107, 110, 113, 119, 120, 121, 122, 123, 131, 133, 139, 141, 143, 144, 145, 148, 149, 151, 152, 154, 156, 157, 158, 160, 161, 188], "binari": [3, 6, 43, 64, 78, 95, 103, 141, 146, 148, 178, 191], "case": [3, 29, 33, 53, 78, 81, 84, 86, 89, 90, 92, 94, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 112, 119, 121, 123, 128, 131, 137, 141, 145, 147, 148, 149, 151, 152, 155, 157, 158, 160, 162, 163], "least": [3, 104, 121, 167, 191], "three": [3, 81, 90, 103, 104, 107, 111, 112, 113, 116, 125, 141, 163, 164], "multi": [3, 129, 159], "class": [3, 15, 27, 47, 51, 64, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 120, 123, 136, 142, 144, 145, 146, 147, 149, 152, 154, 156, 157, 158, 160, 161, 163, 165, 167, 169, 179, 191], "illustr": [3, 33, 62, 81, 85, 86, 89, 98, 101, 103, 104, 106, 112, 123, 141, 144, 147, 148, 158, 163, 164, 167, 168], "provid": [3, 37, 84, 86, 89, 90, 106, 109, 111, 115, 118, 119, 120, 124, 127, 131, 137, 141, 142, 143, 145, 146, 147, 148, 149, 152, 156, 158, 191], "user": [3, 6, 81, 90, 95, 107, 122, 123, 156, 160, 188, 191], "contain": [3, 18, 25, 29, 45, 51, 64, 68, 70, 77, 78, 81, 84, 85, 89, 90, 91, 93, 99, 104, 108, 109, 110, 111, 116, 123, 125, 128, 130, 131, 133, 135, 137, 139, 141, 144, 145, 146, 147, 148, 156, 160, 166, 168, 170, 183, 191], "2": [3, 4, 18, 28, 29, 37, 44, 45, 53, 70, 75, 78, 80, 81, 84, 85, 86, 87, 89, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 117, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 169, 171, 183, 191], "repres": [3, 6, 68, 70, 73, 77, 78, 84, 85, 86, 89, 90, 104, 108, 110, 112, 119, 120, 132, 133, 137, 138, 139, 144, 145, 146, 147, 148, 151, 163], "x": [3, 24, 28, 29, 44, 45, 70, 78, 84, 85, 86, 109, 111, 112, 113, 114, 119, 125, 132, 133, 138, 139, 141, 142, 143, 144, 145, 146, 147, 151, 155, 156, 159, 162, 163, 164, 167, 168, 169, 170, 185], "y": [3, 28, 29, 44, 70, 78, 84, 85, 86, 104, 111, 112, 113, 114, 119, 125, 126, 132, 133, 138, 139, 141, 142, 143, 144, 145, 146, 147, 151, 159, 163, 164, 167, 168, 169, 170, 185], "axi": [3, 18, 29, 80, 96, 100, 102, 103, 104, 107, 108, 111, 112, 114, 126, 127, 129, 130, 137, 141, 142, 144, 145, 147, 148, 151, 156, 159, 160, 162, 163, 167, 185], "becaus": [3, 6, 18, 78, 81, 82, 85, 86, 87, 89, 90, 91, 93, 103, 104, 105, 106, 107, 112, 114, 123, 126, 129, 137, 144, 149, 151, 152, 157, 158, 160, 162, 164, 168], "onli": [3, 6, 18, 29, 37, 47, 51, 53, 68, 70, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 100, 101, 102, 103, 104, 106, 109, 110, 113, 119, 121, 123, 129, 131, 134, 135, 136, 137, 140, 141, 142, 145, 146, 147, 148, 149, 151, 152, 156, 157, 158, 162, 167, 180, 183, 189], "here": [3, 29, 64, 78, 79, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93, 96, 97, 98, 105, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 144, 146, 147, 148, 149, 150, 154, 155, 156, 157, 158, 161, 164, 165, 166, 168], "encod": [3, 6, 29, 51, 72, 73, 84, 90, 91, 93, 108, 109, 111, 120, 123, 137, 171, 183], "color": [3, 78, 101, 111, 112, 113, 114, 119, 125, 127, 129, 130, 133, 137, 138, 139, 140, 143, 144, 145, 148, 151, 152, 159, 162, 167, 168, 170, 185], "blue": [3, 78, 81, 99, 106, 113, 114, 142, 146, 147, 148, 158, 163, 167, 169], "orang": [3, 78, 114, 119, 148, 168], "point": [3, 6, 15, 78, 82, 84, 86, 87, 94, 99, 104, 109, 110, 111, 112, 114, 120, 121, 123, 126, 144, 146, 147, 148, 158, 160, 163, 167], "thu": [3, 6, 29, 37, 65, 84, 86, 90, 97, 99, 101, 102, 105, 106, 107, 109, 110, 111, 112, 113, 117, 120, 121, 122, 123, 126, 128, 131, 137, 141, 142, 145, 146, 147, 151, 156, 157, 158, 159, 162, 163, 167, 168, 183], "each": [3, 6, 18, 29, 36, 41, 51, 53, 70, 73, 78, 79, 80, 81, 84, 85, 86, 89, 90, 98, 99, 101, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 129, 130, 132, 134, 137, 138, 140, 141, 144, 145, 146, 148, 154, 156, 157, 158, 160, 161, 162, 163, 164, 166, 167, 168, 170, 179, 183, 185, 191], "entir": [3, 35, 81, 89, 90, 110, 111, 126, 128, 131, 135, 136, 141, 142, 183], "wa": [3, 78, 85, 86, 94, 95, 99, 101, 102, 104, 106, 107, 108, 111, 113, 114, 119, 123, 129, 132, 137, 138, 144, 146, 148, 158, 163, 165, 168, 169], "linear": [3, 6, 13, 15, 16, 29, 37, 40, 41, 43, 44, 45, 46, 51, 57, 62, 78, 84, 86, 89, 90, 91, 92, 93, 94, 97, 99, 102, 111, 114, 122, 130, 132, 133, 134, 135, 138, 139, 140, 141, 150, 151, 153, 157, 163, 164, 166, 168, 170, 178, 180, 183, 188], "decis": [3, 6, 10, 13, 15, 16, 18, 27, 35, 47, 62, 86, 90, 92, 94, 96, 100, 105, 106, 107, 113, 114, 116, 117, 120, 122, 123, 124, 125, 126, 130, 136, 142, 144, 146, 147, 148, 149, 152, 164, 165, 166, 169, 170, 176, 177, 178, 179, 180, 181, 183], "rule": [3, 84, 85, 122, 137, 146, 179], "black": [3, 78, 84, 89, 96, 99, 101, 103, 106, 107, 108, 109, 110, 111, 113, 114, 119, 125, 127, 129, 130, 133, 137, 138, 139, 140, 143, 144, 145, 151, 152, 156, 160, 163, 167, 168, 169, 170], "dot": [3, 141], "line": [3, 29, 45, 73, 78, 84, 112, 114, 119, 137, 144, 146, 147, 148, 149, 151, 152, 159, 160, 163, 167, 168, 185, 191], "new": [3, 6, 29, 36, 41, 78, 82, 84, 85, 86, 87, 89, 90, 91, 93, 97, 98, 99, 100, 102, 103, 105, 106, 112, 113, 116, 117, 119, 125, 126, 134, 135, 140, 141, 144, 148, 154, 156, 157, 161, 166, 168, 169, 170], "accord": [3, 78], "its": [3, 6, 18, 23, 29, 51, 62, 65, 78, 83, 85, 86, 88, 89, 90, 97, 101, 102, 103, 105, 106, 107, 112, 115, 119, 121, 123, 124, 129, 137, 143, 145, 148, 149, 152, 155, 162, 163, 185], "posit": [3, 6, 27, 28, 29, 46, 51, 70, 107, 112, 114, 122, 137, 145, 148, 149, 152, 160, 191], "respect": [3, 25, 29, 44, 45, 89, 90, 94, 97, 102, 103, 105, 107, 121, 123, 137], "ly": [3, 137], "left": [3, 77, 78, 85, 96, 99, 102, 103, 104, 105, 109, 111, 112, 113, 114, 119, 121, 122, 125, 131, 138, 142, 148, 158, 159, 163, 167, 169], "while": [3, 18, 29, 84, 85, 86, 89, 102, 106, 107, 109, 111, 112, 113, 114, 119, 120, 121, 123, 126, 129, 131, 137, 141, 147, 148, 151, 159, 162, 167, 183], "right": [3, 78, 79, 80, 84, 89, 91, 93, 103, 112, 121, 126, 128, 131, 148, 158, 167], "defin": [3, 18, 29, 36, 51, 60, 70, 77, 81, 89, 90, 91, 93, 95, 98, 99, 103, 104, 105, 112, 113, 118, 127, 132, 133, 137, 138, 139, 144, 145, 147, 148, 154, 155, 156, 159, 160, 161, 162, 163, 165, 169, 183, 185, 187, 188, 191], "higher": [3, 6, 27, 40, 45, 87, 88, 90, 101, 106, 108, 109, 112, 113, 122, 143, 153, 158, 185], "dimens": [3, 45, 78, 162], "would": [3, 18, 25, 29, 53, 78, 81, 83, 84, 85, 88, 89, 91, 93, 101, 102, 103, 104, 105, 106, 108, 110, 111, 112, 114, 119, 120, 121, 123, 126, 129, 133, 137, 139, 141, 144, 145, 146, 148, 149, 151, 152, 155, 158, 162, 163, 167, 168], "hyperplan": 3, "howev": [3, 6, 22, 36, 84, 85, 86, 89, 90, 92, 94, 96, 99, 101, 103, 104, 106, 107, 108, 109, 110, 112, 113, 114, 117, 119, 120, 121, 122, 123, 126, 128, 129, 131, 137, 138, 141, 143, 144, 146, 148, 149, 151, 152, 158, 160, 162, 163, 167, 168, 188], "shape": [3, 44, 45, 78, 84, 85, 89, 108, 109, 111, 112, 113, 114, 133, 139, 144, 168], "depend": [3, 18, 22, 27, 28, 29, 37, 41, 81, 86, 89, 90, 101, 103, 105, 111, 112, 114, 121, 129, 142, 148, 156, 160, 164], "A": [3, 6, 29, 36, 46, 57, 65, 68, 70, 78, 86, 90, 99, 101, 105, 106, 111, 120, 121, 137, 143, 144, 148, 151, 162, 168, 178, 179, 183, 189], "These": [3, 6, 23, 78, 81, 85, 89, 108, 123, 143, 148, 157, 163, 168, 188], "handl": [3, 75, 76, 84, 89, 90, 94, 108, 119, 144, 156, 171], "discret": [3, 89, 106, 110, 120, 146, 151], "1": [3, 4, 18, 27, 29, 44, 45, 47, 51, 53, 64, 70, 78, 80, 81, 84, 85, 86, 87, 89, 90, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 171, 183, 185, 191], "cat": [3, 95], "dog": 3, "scikit": [3, 13, 14, 22, 23, 24, 27, 28, 33, 34, 37, 40, 41, 44, 47, 48, 60, 62, 64, 68, 70, 72, 75, 76, 81, 82, 84, 86, 87, 89, 90, 91, 93, 98, 103, 104, 106, 111, 113, 116, 118, 120, 123, 125, 127, 128, 131, 133, 136, 137, 139, 141, 142, 144, 146, 148, 149, 151, 152, 153, 156, 158, 171, 176, 177, 179, 180, 186, 188, 189, 191], "logisticregress": [3, 46, 47, 51, 77, 81, 83, 84, 86, 88, 89, 90, 91, 93, 95, 99, 103, 104, 131, 136, 141, 142, 146, 148, 157, 163, 185, 187], "histgradientboostingclassifi": [3, 90, 92, 94, 120, 154, 156, 158, 159, 160, 161], "note": [3, 8, 9, 36, 50, 51, 52, 54, 56, 58, 66, 71, 78, 81, 84, 85, 86, 89, 90, 94, 96, 97, 101, 102, 103, 106, 107, 110, 111, 112, 114, 122, 123, 137, 141, 144, 145, 146, 156, 157, 158, 162, 163, 168, 172, 183], "histor": 3, "reason": [3, 6, 18, 51, 62, 78, 80, 86, 92, 94, 101, 105, 106, 109, 112, 119, 121, 131, 148, 162], "name": [3, 15, 29, 51, 64, 78, 80, 84, 85, 86, 87, 88, 89, 90, 96, 97, 102, 103, 104, 106, 108, 109, 110, 111, 112, 114, 119, 121, 124, 127, 137, 141, 145, 148, 156, 157, 159, 160, 187, 191], "confus": [3, 119, 157, 168, 188], "contrari": [3, 78, 89, 106, 112, 168], "what": [3, 6, 15, 24, 27, 28, 29, 35, 43, 45, 51, 53, 54, 62, 64, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 98, 101, 103, 104, 105, 106, 107, 112, 121, 122, 123, 133, 135, 139, 141, 143, 145, 147, 148, 157, 158, 163, 168, 183, 185], "suggest": 3, "procedur": [3, 6, 18, 51, 81, 84, 101, 105, 106, 114, 121, 123, 126, 129, 130, 135, 141, 144, 158, 162, 178, 185], "how": [3, 18, 22, 23, 26, 29, 33, 34, 40, 44, 51, 60, 62, 68, 73, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 95, 96, 100, 102, 104, 105, 107, 112, 113, 114, 119, 121, 123, 137, 141, 143, 148, 149, 152, 156, 157, 158, 159, 160, 162, 163, 165, 167, 168, 169, 176, 181, 185, 187, 188], "well": [3, 6, 13, 15, 22, 70, 80, 86, 89, 99, 103, 104, 107, 110, 111, 112, 113, 114, 119, 121, 122, 130, 137, 148, 157, 167], "idea": [3, 78, 95, 102, 112, 119, 158], "behind": [3, 6, 13, 22, 122], "dataset": [3, 16, 18, 25, 29, 35, 37, 40, 41, 43, 45, 51, 57, 60, 64, 67, 68, 70, 73, 75, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 183, 185, 191], "evalu": [3, 18, 22, 23, 25, 26, 29, 37, 46, 51, 60, 64, 69, 70, 78, 83, 84, 85, 88, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 104, 105, 106, 110, 112, 114, 115, 117, 119, 120, 124, 126, 130, 131, 137, 143, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 168, 183, 184, 188, 191], "separ": [3, 29, 38, 43, 46, 47, 68, 78, 80, 83, 84, 88, 90, 103, 108, 109, 110, 142, 146, 158, 163, 167, 171, 179, 183], "sever": [3, 13, 16, 23, 70, 81, 99, 101, 106, 112, 113, 114, 117, 119, 120, 122, 123, 126, 132, 138, 147, 160], "time": [3, 18, 29, 51, 70, 78, 81, 84, 86, 89, 90, 91, 92, 93, 94, 95, 99, 101, 104, 105, 106, 107, 109, 110, 112, 114, 117, 119, 120, 121, 122, 123, 126, 129, 141, 146, 148, 156, 159, 160, 163, 165, 169, 171, 178, 183], "differ": [3, 6, 15, 16, 18, 22, 25, 29, 37, 46, 51, 57, 62, 64, 68, 70, 73, 78, 79, 80, 81, 85, 86, 89, 90, 94, 96, 97, 99, 100, 101, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 119, 120, 121, 123, 131, 132, 137, 138, 143, 144, 149, 151, 152, 155, 157, 158, 159, 160, 162, 163, 164, 167, 168, 183, 191], "get": [3, 6, 18, 34, 43, 51, 57, 64, 70, 78, 79, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 99, 100, 101, 104, 105, 106, 107, 109, 111, 113, 114, 117, 118, 119, 126, 127, 128, 129, 131, 133, 137, 139, 144, 148, 149, 150, 151, 152, 153, 156, 158, 159, 160, 162, 163, 166, 167, 168, 170, 171, 185, 186, 187], "s": [3, 4, 6, 17, 23, 26, 29, 35, 36, 51, 77, 78, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 119, 121, 122, 124, 125, 129, 130, 135, 136, 137, 138, 141, 142, 144, 147, 148, 151, 153, 156, 157, 158, 159, 160, 163, 164, 167, 168, 188, 191], "uncertainti": [3, 81, 90, 114, 128, 131, 158], "see": [3, 8, 9, 40, 50, 52, 54, 56, 58, 66, 71, 78, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 99, 100, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 119, 120, 121, 122, 124, 126, 127, 129, 131, 137, 141, 142, 144, 145, 146, 147, 148, 151, 156, 157, 158, 159, 160, 162, 163, 164, 165, 167, 168, 169, 172], "document": [3, 4, 6, 15, 64, 82, 84, 85, 87, 89, 91, 93, 96, 98, 99, 103, 133, 139, 144, 148, 149, 150, 152, 153, 157], "more": [3, 18, 29, 36, 57, 60, 64, 78, 81, 84, 85, 86, 89, 91, 93, 94, 96, 97, 100, 101, 102, 103, 107, 108, 109, 111, 112, 113, 114, 119, 120, 121, 122, 123, 129, 134, 137, 140, 142, 143, 144, 145, 146, 147, 148, 149, 152, 156, 157, 158, 159, 160, 162, 163, 164, 167, 168, 191], "detail": [3, 13, 18, 29, 40, 65, 78, 81, 82, 84, 85, 87, 89, 90, 91, 93, 97, 99, 102, 109, 111, 112, 119, 121, 122, 144, 148, 149, 152, 156, 164, 176, 177, 191], "n_sampl": [3, 114, 119, 129, 130, 133, 135, 139, 141, 144, 147, 167], "row": [3, 18, 64, 68, 78, 89, 95, 106, 108, 111, 114, 133, 139, 141, 144, 156, 159, 160, 162, 191], "n_featur": [3, 45, 121, 123, 129, 130, 133, 135, 139, 141, 144, 147], "column": [3, 6, 18, 29, 37, 44, 45, 51, 64, 68, 73, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 102, 103, 105, 106, 108, 109, 110, 111, 112, 114, 119, 121, 123, 124, 125, 127, 129, 130, 133, 135, 137, 139, 140, 141, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 160, 161, 162, 167, 168, 170, 183, 191], "number": [3, 6, 16, 17, 18, 29, 37, 44, 46, 51, 53, 57, 64, 73, 77, 78, 81, 82, 84, 85, 86, 87, 89, 90, 91, 93, 97, 99, 100, 102, 104, 106, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 123, 126, 127, 129, 130, 131, 133, 137, 138, 139, 141, 148, 150, 151, 153, 155, 156, 158, 159, 160, 162, 167, 168, 178, 183, 185, 189, 191], "equal": [3, 6, 29, 46, 64, 86, 104, 119, 137, 156, 157, 168], "flower": 3, "4": [3, 4, 18, 29, 77, 78, 80, 84, 85, 86, 87, 88, 89, 95, 96, 99, 102, 103, 104, 106, 108, 109, 110, 111, 112, 114, 119, 120, 121, 122, 124, 126, 127, 129, 133, 134, 135, 137, 139, 140, 141, 144, 145, 148, 153, 156, 157, 158, 159, 160, 162, 164, 167, 169, 171, 183], "length": [3, 6, 18, 29, 79, 80, 84, 85, 108, 109, 113, 116, 125, 132, 136, 138, 141, 142, 143, 145, 146, 148, 156, 160, 163, 164, 165, 166, 167, 168, 169, 170, 191], "width": [3, 120], "In": [3, 6, 15, 22, 23, 29, 34, 36, 37, 40, 41, 51, 62, 68, 76, 78, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 118, 119, 120, 121, 122, 123, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 177, 183, 185, 188], "common": [3, 62, 81, 89, 105, 114, 137, 141, 191], "math": [3, 108], "convent": [3, 78, 86, 133, 139, 144], "matric": [3, 89], "capit": [3, 51, 78, 81, 83, 84, 85, 86, 88, 89, 90, 156, 157, 160], "letter": [3, 106, 111], "f": [3, 8, 9, 18, 29, 50, 52, 54, 56, 58, 66, 71, 78, 81, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 99, 101, 102, 104, 105, 106, 111, 112, 113, 114, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 151, 152, 153, 156, 157, 158, 160, 161, 163, 167, 169, 172, 185], "consist": [3, 41, 77, 81, 106, 134, 140, 151], "iter": [3, 29, 70, 81, 86, 89, 104, 105, 106, 117, 121, 126, 137, 158, 159, 160], "optim": [3, 22, 23, 46, 68, 86, 97, 101, 102, 113, 118, 119, 120, 122, 127, 131, 137, 143, 148, 151, 156, 157, 158, 160, 162, 163, 167, 183, 189, 191], "method": [3, 4, 6, 14, 64, 77, 78, 79, 80, 84, 85, 86, 90, 99, 105, 112, 115, 119, 122, 123, 124, 130, 137, 144, 147, 148, 151, 157, 158, 160, 171, 191], "befor": [3, 46, 51, 78, 82, 84, 86, 87, 89, 104, 106, 107, 108, 112, 120, 123, 128, 131, 137, 145, 148, 151, 165, 169], "converg": [3, 70, 86, 89], "algorithm": [3, 13, 16, 18, 24, 35, 78, 85, 86, 89, 99, 112, 113, 117, 119, 120, 121, 123, 126, 128, 129, 131, 134, 140, 144, 146, 163, 164], "over": [3, 15, 24, 29, 40, 41, 78, 97, 99, 101, 102, 105, 107, 112, 116, 120, 122, 125, 137, 154, 156, 161, 163, 165, 167, 169, 176, 179], "done": [3, 6, 77, 85, 93, 120, 121, 123, 131, 137, 144, 157, 158, 163, 167], "monitor": [3, 6, 29], "score": [3, 18, 27, 28, 29, 37, 51, 62, 64, 70, 77, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 111, 112, 117, 118, 119, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 137, 140, 141, 142, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 169, 181, 183, 185, 191], "jargon": 3, "object": [3, 6, 29, 51, 62, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 106, 108, 109, 110, 123, 137, 141, 148, 149, 152, 154, 156, 157, 158, 160, 161, 162, 163, 168, 183], "onc": [3, 6, 18, 29, 84, 86, 94, 99, 104, 106, 114, 121, 123, 146, 148, 150, 151, 153, 154, 155, 156, 159, 160, 161, 162, 165, 169, 185], "quantiti": [3, 6, 89, 90, 109, 112], "e": [3, 6, 18, 29, 51, 64, 68, 70, 73, 75, 76, 77, 78, 84, 85, 86, 88, 89, 90, 93, 99, 100, 101, 104, 105, 106, 112, 119, 120, 121, 122, 129, 137, 141, 142, 143, 146, 148, 151, 154, 156, 160, 161, 162, 183, 185, 187, 191], "g": [3, 6, 18, 29, 78, 89, 90, 99, 101, 105, 112, 116, 121, 122, 125, 129, 132, 137, 138, 143, 145, 146, 154, 156, 160, 161, 162, 164, 166, 167, 168, 170, 183, 191], "size": [3, 53, 60, 62, 63, 89, 96, 97, 102, 109, 111, 113, 114, 121, 131, 141, 163, 171], "weight": [3, 29, 41, 43, 46, 47, 51, 84, 97, 99, 102, 112, 113, 119, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 163, 178], "dure": [3, 13, 22, 29, 33, 34, 40, 41, 60, 62, 76, 77, 78, 84, 89, 91, 93, 104, 106, 109, 113, 122, 129, 137, 141, 143, 149, 152, 156, 158, 160, 163, 166, 168, 170, 176, 177, 188, 189], "four": [3, 109, 110, 148], "never": [3, 18, 60, 78, 84, 85, 89, 113, 114, 156, 160, 185], "seen": [3, 51, 81, 83, 85, 86, 88, 89, 106, 145, 148, 156, 157, 158, 160, 166, 170], "aspect": [3, 6, 22, 34, 81, 86, 100, 130, 137, 178], "configur": [3, 118, 127, 144, 156], "learnt": [3, 62, 100, 112, 144, 163], "nearest": [3, 64, 84, 85, 86, 188, 191], "neighbor": [3, 64, 82, 84, 85, 86, 87, 155, 162, 188, 191], "approach": [3, 6, 14, 23, 34, 41, 62, 76, 89, 104, 120, 143, 156, 158, 160, 162, 177, 189], "polynomi": [3, 45, 57, 114, 144], "sai": [3, 64, 112], "degre": [3, 45, 57, 112, 114, 137, 144], "between": [3, 6, 13, 15, 18, 22, 29, 41, 51, 57, 60, 62, 64, 78, 80, 81, 84, 86, 89, 97, 101, 102, 105, 107, 109, 110, 112, 114, 116, 119, 121, 125, 128, 129, 131, 133, 135, 137, 138, 139, 144, 145, 148, 151, 159, 160, 162, 164, 167, 168, 176, 191], "10": [3, 4, 18, 25, 36, 51, 64, 77, 78, 81, 82, 84, 87, 89, 94, 96, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 114, 117, 120, 121, 122, 124, 126, 131, 134, 136, 137, 140, 141, 142, 149, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 167, 183, 185, 191], "impact": [3, 18, 46, 51, 60, 89, 91, 92, 93, 94, 100, 101, 117, 121, 126, 136, 137, 141, 142, 151, 159, 162, 167, 185, 188, 189, 191], "comput": [3, 6, 29, 51, 64, 70, 78, 81, 82, 85, 86, 87, 89, 90, 92, 94, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 112, 113, 114, 117, 119, 120, 121, 122, 126, 128, 129, 131, 133, 134, 137, 138, 139, 140, 143, 144, 145, 148, 149, 150, 151, 152, 153, 155, 158, 159, 160, 162, 163, 165, 168, 169, 185], "inde": [3, 18, 29, 78, 84, 85, 86, 90, 94, 97, 99, 101, 102, 105, 106, 108, 109, 110, 111, 112, 113, 114, 119, 120, 121, 122, 128, 129, 130, 131, 137, 141, 143, 144, 146, 147, 148, 149, 151, 152, 157, 158, 160, 163, 164, 167, 168], "usual": [3, 17, 84, 86, 90, 99, 105, 107, 109, 148, 159, 160], "inspect": [3, 6, 29, 64, 68, 86, 95, 106, 113, 118, 121, 127, 130, 134, 136, 140, 142, 144, 146, 147, 156, 159, 160, 163, 165, 167, 169, 191], "regard": [3, 13, 14, 22, 24, 33, 34, 40, 75, 77, 86, 89, 91, 93, 96, 97, 99, 100, 102, 104, 107, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 134, 136, 137, 138, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 161, 163, 165, 166, 167, 168, 169, 170], "tune": [3, 13, 17, 26, 35, 41, 46, 51, 97, 101, 102, 107, 115, 122, 123, 124, 129, 131, 141, 155, 159, 161, 162, 177, 183, 188, 191], "maxim": [3, 51, 99, 101, 137, 154, 155, 156, 160, 161, 162, 181, 188], "It": [3, 6, 29, 36, 62, 78, 82, 85, 86, 87, 89, 90, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 120, 122, 123, 127, 128, 131, 137, 141, 142, 144, 145, 148, 149, 151, 152, 153, 156, 158, 159, 160, 163, 167, 168], "involv": [3, 6, 78, 103, 106, 141, 157], "grid": [3, 101, 109, 118, 121, 122, 127, 137, 155, 158, 160, 162, 167, 171, 181, 183, 184, 185, 189, 191], "search": [3, 51, 100, 101, 118, 120, 121, 122, 123, 124, 127, 137, 143, 154, 155, 158, 161, 162, 167, 171, 181, 183, 184, 185, 188, 189, 191], "random": [3, 11, 13, 14, 15, 17, 18, 37, 51, 55, 84, 99, 103, 104, 105, 106, 109, 111, 112, 114, 116, 117, 119, 120, 122, 125, 126, 128, 129, 130, 131, 133, 139, 144, 155, 156, 159, 162, 171, 179, 184, 185, 189], "some": [3, 6, 18, 22, 23, 29, 33, 36, 47, 51, 64, 68, 70, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 91, 93, 95, 99, 101, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 116, 118, 119, 120, 121, 122, 123, 125, 127, 128, 130, 131, 135, 137, 141, 144, 145, 146, 147, 151, 156, 158, 159, 160, 162, 163, 167, 168, 170, 183, 191], "further": [3, 40, 78, 99, 100, 145, 158, 167], "read": [3, 6, 78, 99, 109, 112, 191], "post": [3, 53, 73, 177], "mean": [3, 6, 28, 29, 51, 64, 77, 78, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 131, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 150, 151, 152, 153, 156, 157, 158, 160, 161, 162, 163, 168, 180, 191], "machin": [3, 23, 29, 34, 36, 41, 60, 62, 68, 73, 76, 78, 84, 85, 86, 88, 89, 90, 91, 93, 95, 97, 98, 101, 102, 103, 104, 105, 106, 114, 123, 128, 129, 130, 131, 137, 141, 143, 144, 146, 147, 148, 151, 156, 160], "mooc": [3, 78, 85, 95, 96, 97, 100, 102, 106, 107, 113, 115, 116, 117, 120, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 163, 165, 166, 167, 168, 169, 170], "refer": [3, 14, 23, 34, 41, 62, 76, 77, 78, 85, 91, 93, 96, 97, 98, 99, 100, 102, 103, 106, 107, 111, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 157, 163, 165, 166, 167, 168, 169, 170, 177, 189], "process": [3, 6, 36, 62, 70, 76, 77, 78, 90, 105, 114, 120, 128, 129, 131, 157, 158, 165, 169, 188], "make": [3, 6, 24, 25, 29, 46, 51, 55, 60, 64, 65, 75, 78, 81, 82, 84, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 99, 101, 102, 103, 105, 106, 107, 108, 109, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 134, 137, 140, 143, 144, 145, 147, 148, 150, 151, 153, 154, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 178], "appli": [3, 6, 15, 16, 17, 18, 24, 25, 26, 27, 29, 40, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 86, 89, 90, 95, 104, 107, 108, 109, 111, 135, 141, 145, 147, 156, 157, 159, 162, 167, 178, 179, 181, 185, 187, 191], "unlabel": 3, "word": [3, 29, 143, 157, 166, 170, 185], "equival": [3, 18, 29, 51, 77, 78, 85, 97, 102, 106, 121, 136, 142, 144, 146, 148, 162, 183], "unseen": [3, 25, 70, 78, 104, 105, 121, 147], "notion": 3, "out": [3, 6, 25, 77, 78, 81, 84, 85, 89, 98, 100, 103, 105, 106, 112, 114, 117, 118, 121, 122, 126, 127, 131, 136, 137, 142, 148, 156, 158, 163, 165, 166, 169, 170], "ti": 3, "definit": [3, 144, 157], "distribut": [3, 6, 78, 79, 80, 86, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 111, 120, 134, 137, 140, 146, 151, 155, 158, 160, 162, 164, 168, 185], "condit": [3, 6, 89, 112, 137], "check": [3, 6, 29, 51, 64, 78, 81, 84, 85, 86, 88, 89, 90, 97, 99, 100, 102, 104, 105, 106, 107, 109, 111, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 135, 137, 141, 143, 144, 145, 147, 148, 149, 152, 156, 158, 159, 163, 164, 166, 167, 168, 170, 176, 183], "wikipedia": [3, 62, 114], "articl": [3, 6, 62, 114], "finish": [3, 137], "_": [3, 78, 80, 85, 86, 90, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 124, 125, 126, 127, 129, 130, 133, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 157, 159, 163, 164, 167, 168, 169, 170], "end": [3, 86, 89, 96, 97, 100, 102, 103, 104, 106, 107, 109, 113, 115, 116, 117, 120, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 161, 163, 165, 166, 167, 168, 169, 170], "thei": [3, 6, 29, 60, 70, 78, 82, 84, 86, 87, 89, 90, 94, 103, 104, 107, 108, 111, 112, 114, 120, 121, 123, 137, 141, 148, 157, 163, 168, 170, 177, 183, 188], "avail": [3, 6, 29, 36, 53, 77, 78, 79, 80, 81, 84, 85, 95, 99, 100, 108, 110, 111, 116, 125, 129, 131, 137, 141, 143, 145, 157, 160, 183], "after": [3, 18, 28, 51, 81, 89, 106, 108, 114, 117, 120, 121, 124, 126, 143, 157, 161, 162], "been": [3, 78, 81, 84, 89, 96, 104, 106, 112, 113, 120, 126, 129, 146, 157, 158, 163], "slope": [3, 29, 109, 145, 151], "intercept": [3, 41, 132, 133, 138, 139, 143, 144, 145, 146, 163], "one": [3, 6, 14, 18, 25, 37, 47, 51, 62, 70, 73, 77, 78, 80, 81, 83, 84, 85, 86, 88, 89, 90, 92, 94, 97, 98, 99, 101, 102, 103, 104, 106, 109, 111, 112, 113, 119, 120, 121, 123, 130, 137, 143, 144, 146, 148, 149, 151, 152, 156, 157, 158, 162, 163, 164, 167, 169, 179, 191], "section": [3, 81, 84, 89, 90, 96, 97, 99, 100, 102, 106, 107, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 160, 163, 165, 166, 167, 168, 169, 170], "about": [3, 13, 17, 22, 24, 29, 33, 36, 40, 60, 64, 75, 76, 78, 81, 85, 86, 89, 98, 100, 103, 106, 107, 108, 110, 112, 119, 122, 134, 137, 140, 147, 156, 164, 168, 176, 185, 188, 191], "also": [3, 13, 22, 27, 29, 33, 36, 47, 62, 64, 78, 84, 85, 86, 89, 90, 91, 92, 93, 94, 97, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 117, 118, 120, 121, 123, 126, 127, 129, 133, 136, 137, 139, 141, 142, 144, 145, 146, 147, 148, 151, 157, 158, 159, 160, 162, 163], "python": [3, 6, 29, 36, 70, 75, 78, 81, 91, 93, 106, 114, 120, 137, 149, 152], "pass": [3, 18, 29, 51, 64, 70, 77, 81, 89, 90, 91, 93, 97, 101, 102, 106, 114, 145, 149, 150, 152, 153, 155, 156, 158, 162, 163, 191], "function": [3, 6, 18, 29, 36, 45, 55, 62, 64, 70, 77, 81, 84, 85, 86, 89, 97, 98, 102, 103, 106, 107, 108, 111, 112, 113, 114, 118, 119, 127, 128, 131, 132, 133, 134, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 158, 159, 163, 165, 168, 169, 180, 191], "anoth": [3, 6, 18, 62, 78, 81, 101, 103, 105, 114, 123, 129, 130, 132, 138, 141, 144, 147, 148, 151, 160, 163, 167], "includ": [3, 29, 34, 36, 68, 89, 101, 108, 129, 130, 137, 144, 157, 180], "gridsearchcv": [3, 6, 101, 122, 127, 155, 156, 158, 160, 162, 167, 183, 185, 191], "someth": [3, 94, 147, 157], "occur": [3, 89], "your": [3, 6, 34, 40, 51, 64, 77, 78, 79, 82, 83, 87, 89, 90, 91, 92, 93, 94, 97, 98, 102, 104, 115, 116, 117, 118, 121, 128, 131, 132, 133, 134, 135, 136, 140, 149, 150, 154, 155, 161, 165, 166, 170, 183, 185], "stick": 3, "too": [3, 6, 65, 85, 95, 101, 106, 107, 117, 120, 121, 123, 126, 156, 162, 167, 185], "so": [3, 6, 14, 29, 70, 78, 80, 86, 88, 89, 91, 93, 96, 97, 102, 103, 104, 105, 106, 108, 109, 112, 113, 118, 119, 121, 127, 143, 148, 149, 152, 157, 158, 162, 183], "up": [3, 6, 10, 35, 46, 78, 81, 84, 89, 99, 101, 103, 106, 111, 112, 129, 132, 138, 144, 145, 148, 156, 168, 171, 188], "nois": [3, 51, 57, 62, 107, 114, 119, 133, 135, 139, 141, 144, 147], "rather": [3, 29, 34, 81, 84, 109, 110, 148, 160, 162], "than": [3, 6, 18, 27, 29, 34, 36, 45, 51, 57, 64, 77, 78, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 96, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 112, 113, 114, 120, 121, 122, 123, 126, 128, 130, 131, 132, 134, 137, 138, 140, 146, 147, 148, 151, 155, 156, 158, 159, 160, 162, 166, 167, 170, 180, 183, 185, 191], "relev": [3, 64, 84, 99, 112, 135, 141, 148], "pattern": [3, 23, 78, 99, 128, 131, 141, 149, 152, 158], "tell": [3, 78, 107, 112], "great": [3, 6, 53], "poorli": [3, 93], "real": [3, 53, 78, 84, 85, 89, 90, 104, 106, 132, 138, 148, 168], "world": [3, 168], "fit_predict": 3, "kneighborsclassifi": [3, 64, 82, 85, 87, 191], "decisiontreeregressor": [3, 18, 96, 100, 105, 106, 107, 114, 115, 119, 122, 123, 124, 144, 167, 168, 170, 183], "One": [3, 53, 64, 73, 77, 81, 82, 87, 89, 104, 105, 110, 112, 120, 148, 151, 158], "focu": [3, 18, 78, 84, 106, 108, 111, 113, 119, 137, 141, 148, 151, 156, 157], "were": [3, 29, 70, 81, 84, 90, 99, 106, 107, 110, 119, 128, 131, 132, 138, 144, 148, 160, 162, 167, 170], "If": [3, 6, 28, 29, 37, 44, 57, 70, 78, 81, 85, 89, 96, 97, 99, 100, 101, 102, 105, 106, 107, 111, 112, 113, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 129, 132, 133, 134, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 157, 158, 162, 163, 165, 166, 167, 168, 169, 170, 181, 191], "do": [3, 6, 17, 18, 29, 62, 70, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 98, 101, 103, 105, 106, 107, 108, 111, 117, 120, 123, 126, 128, 129, 131, 135, 141, 143, 144, 148, 149, 152, 156, 157, 158, 159, 163, 168, 185, 187, 191], "1d": [3, 29, 133, 139, 144], "5": [3, 4, 18, 29, 51, 64, 70, 77, 78, 80, 81, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 130, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 151, 156, 158, 159, 160, 162, 163, 164, 167, 168, 169, 170, 171, 187, 188, 191], "someon": [3, 78], "come": [3, 6, 29, 60, 78, 84, 119, 122, 129, 132, 138, 145, 157, 158, 168], "along": [3, 78, 81, 89, 91, 93, 108, 132, 138, 163], "doe": [3, 6, 18, 24, 29, 36, 51, 78, 81, 86, 89, 90, 92, 93, 94, 96, 99, 100, 101, 102, 104, 105, 109, 112, 121, 124, 146, 147, 151, 156, 160, 162, 163, 168, 185, 189], "15": [3, 4, 78, 84, 86, 89, 96, 107, 108, 118, 120, 121, 124, 127, 160, 162, 163, 183], "continu": [3, 6, 37, 43, 45, 68, 78, 84, 106, 108, 112, 145, 146, 148, 151, 164, 167], "price": [3, 53, 77, 95, 96, 106, 108, 111, 112, 134, 140, 150, 151, 153], "descript": [3, 29, 53, 77, 78, 82, 87, 96, 97, 100, 102, 106, 107, 111, 113, 115, 116, 117, 120, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 163, 165, 166, 167, 168, 169, 170, 171], "room": [3, 53, 106, 111, 112], "surfac": [3, 29], "locat": [3, 79, 80, 96, 108, 109, 111, 159], "ag": [3, 25, 51, 78, 81, 83, 84, 85, 86, 88, 89, 90, 106, 111, 112, 137, 156, 157, 160], "mri": 3, "scan": [3, 6, 157], "want": [3, 18, 78, 79, 80, 84, 85, 89, 92, 94, 95, 96, 97, 99, 100, 102, 104, 105, 106, 107, 109, 113, 115, 116, 117, 120, 122, 123, 124, 125, 126, 129, 130, 132, 134, 136, 137, 138, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 157, 158, 163, 164, 165, 166, 167, 168, 169, 170, 183, 185, 191], "tree": [3, 6, 10, 13, 15, 16, 17, 18, 62, 78, 86, 89, 90, 92, 94, 96, 100, 105, 106, 107, 112, 113, 114, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 130, 144, 149, 152, 154, 156, 160, 161, 164, 165, 166, 169, 170, 176, 177, 178, 179, 180, 181, 183], "piecewis": [3, 168, 180], "constant": [3, 24, 88, 112, 168, 180], "given": [3, 6, 18, 25, 29, 53, 62, 70, 84, 86, 89, 98, 101, 103, 104, 106, 108, 110, 111, 112, 114, 119, 123, 130, 133, 136, 137, 139, 142, 143, 145, 146, 148, 153, 158, 160, 163, 178, 185, 187, 188], "output": [3, 18, 43, 78, 81, 86, 89, 90, 105, 106, 109, 112, 114, 132, 138, 146, 148], "correspond": [3, 18, 29, 78, 81, 84, 89, 90, 91, 93, 99, 101, 106, 107, 108, 109, 110, 111, 112, 114, 116, 125, 145, 148, 156, 157, 159, 160, 168, 180, 183], "ridg": [3, 41, 46, 47, 51, 111, 112, 114, 135, 137, 141, 142], "order": [3, 6, 18, 29, 41, 51, 73, 78, 86, 90, 93, 94, 95, 99, 104, 106, 108, 118, 123, 127, 145, 156, 159, 160, 191], "shrink": [3, 46, 47, 51, 137, 141, 142], "constrain": [3, 41, 46, 65, 107], "toward": [3, 46, 47, 51, 112, 129, 137, 141, 142], "zero": [3, 28, 29, 43, 45, 46, 47, 51, 57, 60, 78, 89, 107, 112, 137, 141, 142, 144, 146], "2d": [3, 133, 139, 144, 146], "singl": [3, 15, 16, 18, 24, 27, 28, 29, 35, 43, 44, 45, 46, 47, 51, 53, 57, 64, 68, 70, 73, 77, 78, 81, 84, 86, 89, 90, 95, 98, 101, 103, 104, 105, 106, 112, 114, 119, 122, 123, 124, 129, 130, 132, 133, 134, 138, 139, 140, 144, 148, 149, 151, 152, 156, 157, 158, 163, 167, 178, 179, 180, 181, 183, 185, 187, 191], "orient": [3, 112], "clf": 3, "give": [3, 6, 14, 22, 24, 29, 33, 57, 60, 62, 75, 78, 81, 86, 88, 89, 90, 99, 100, 101, 104, 106, 109, 110, 112, 113, 114, 119, 120, 121, 122, 123, 129, 137, 141, 143, 144, 148, 151, 158, 162, 163], "concret": [3, 29, 62], "graphic": [3, 70, 90, 104, 111, 145], "plot": [3, 18, 29, 51, 64, 70, 78, 79, 80, 86, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 118, 119, 125, 127, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 185], "compos": [3, 51, 77, 78, 85, 89, 90, 91, 92, 93, 94, 95, 98, 103, 108, 123, 151, 154, 156, 158, 160, 161, 167], "sinc": [3, 78, 81, 86, 97, 101, 102, 103, 104, 106, 109, 110, 111, 112, 113, 114, 119, 120, 121, 123, 129, 137, 143, 144, 146, 147, 148, 151, 156, 163, 164, 168, 169], "potenti": [3, 53, 78, 86, 90, 100, 106, 107, 120, 143, 147, 148, 158], "choic": [3, 29, 36, 46, 57, 60, 62, 89, 102, 103, 106, 109, 111, 112, 114, 137, 143, 156, 160, 162, 171, 191], "circl": [3, 78, 111, 114, 147], "vs": [3, 86, 89, 148], "squar": [3, 62, 109, 133, 137, 138, 139, 143, 144, 151], "boil": 3, "down": [3, 6, 121], "fact": [3, 18, 86, 88, 94, 109, 119, 137, 160, 170, 183], "access": [3, 15, 29, 36, 51, 62, 82, 87, 97, 102, 106, 112, 114, 116, 125, 137, 191], "exactli": [3, 46, 47, 60, 64, 84, 94, 99, 141, 147, 191], "know": [3, 6, 90, 97, 102, 106, 107, 108, 111, 114, 119, 131, 144, 148, 156], "frame": [3, 108, 109, 110, 111], "scienc": [3, 6, 36, 99, 109], "solv": [3, 6, 29, 46, 64, 78, 84, 90, 99, 102, 104, 106, 109, 110, 137, 141, 143, 144, 146, 151, 168, 191], "try": [3, 6, 29, 78, 84, 86, 87, 90, 91, 93, 95, 101, 106, 109, 113, 114, 119, 121, 123, 139, 141, 143, 146, 147, 148, 149, 152, 154, 156, 158, 160, 161, 162, 163, 169, 170, 183, 188], "might": [3, 6, 29, 37, 53, 88, 89, 90, 92, 94, 99, 100, 104, 105, 106, 107, 109, 112, 121, 138, 148, 151, 156, 160], "speci": [3, 18, 79, 80, 113, 136, 142, 146, 163, 164, 165, 167, 169, 191], "commonli": [3, 78, 84, 85], "denot": 3, "eventu": 3, "ideal": [3, 106, 148], "let": [3, 6, 18, 45, 77, 78, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 121, 129, 130, 135, 136, 137, 138, 141, 142, 144, 147, 148, 151, 156, 157, 160, 163, 164, 167, 168, 191], "On": [3, 6, 29, 84, 86, 87, 90, 95, 101, 106, 112, 113, 114, 121, 126, 128, 131, 137, 139, 143, 147, 148, 151, 156, 158, 160, 163, 168, 169, 170], "figur": [3, 27, 81, 84, 104, 106, 112, 113, 114, 119, 146, 158, 159, 160, 163, 185], "mathemat": [3, 62, 97, 102, 141, 144, 145, 146, 163], "b": [3, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 43, 44, 45, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 132, 138, 145, 160, 162, 178, 179, 180, 181, 183, 185, 187, 191], "creat": [3, 29, 46, 51, 64, 73, 75, 76, 77, 81, 82, 84, 86, 87, 89, 90, 97, 98, 100, 102, 103, 104, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 146, 147, 148, 149, 150, 152, 153, 156, 157, 158, 160, 163, 165, 166, 168, 169, 170, 179, 183, 188], "infin": 3, "vari": [3, 18, 84, 97, 100, 102, 104, 107, 109, 112, 127, 129, 143, 145, 148, 157, 162, 183], "specif": [3, 13, 22, 23, 37, 68, 85, 86, 91, 92, 93, 94, 99, 106, 107, 109, 111, 112, 113, 119, 120, 123, 129, 137, 148, 156, 157, 159, 163, 167, 168, 183], "fulfil": 3, "requir": [3, 6, 13, 18, 22, 29, 33, 36, 40, 41, 51, 60, 64, 75, 77, 78, 81, 84, 86, 90, 97, 102, 103, 109, 113, 120, 121, 137, 158, 160, 162, 167, 176, 183, 188, 191], "minim": [3, 6, 41, 62, 68, 96, 101, 106, 107, 143, 151, 163, 179], "sum": [3, 41, 43, 62, 78, 85, 87, 119, 138, 141, 148], "error": [3, 6, 16, 28, 29, 41, 43, 55, 57, 60, 62, 63, 65, 78, 81, 85, 91, 93, 96, 99, 100, 101, 107, 113, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 132, 133, 134, 137, 138, 139, 140, 141, 143, 144, 147, 148, 150, 151, 153, 154, 161, 171, 179], "red": [3, 27, 81, 106, 113, 114, 119, 142, 146, 147, 158, 163, 167, 169], "best": [3, 13, 18, 22, 33, 40, 57, 62, 64, 78, 95, 101, 102, 104, 107, 115, 117, 118, 120, 121, 123, 124, 126, 127, 132, 137, 138, 143, 144, 148, 151, 154, 155, 156, 157, 158, 160, 161, 162, 163, 176, 185, 188, 189, 191], "possibl": [3, 6, 15, 29, 36, 43, 45, 62, 64, 68, 73, 78, 89, 96, 100, 101, 104, 106, 107, 112, 114, 120, 121, 123, 131, 132, 138, 141, 144, 146, 147, 151, 155, 156, 158, 159, 162, 166, 168, 170, 185, 191], "abstract": [3, 109], "manner": [3, 14, 29, 89, 99, 137], "state": [3, 6, 14, 64, 78, 84, 85, 86, 89, 90, 111, 156, 160], "jockei": 3, "wheel": 3, "i": [3, 13, 18, 20, 22, 29, 51, 75, 76, 77, 78, 81, 84, 85, 86, 88, 89, 90, 93, 94, 100, 101, 104, 106, 112, 114, 119, 120, 121, 122, 132, 137, 138, 141, 142, 143, 148, 151, 156, 162, 171, 185, 191], "support": [3, 6, 92, 94, 97, 102, 144, 147, 149, 152], "fit_transform": [3, 70, 86, 89, 90, 108, 120, 131, 141, 144], "standardscal": [3, 29, 51, 64, 70, 77, 81, 86, 90, 92, 94, 95, 97, 102, 103, 104, 111, 112, 136, 137, 142, 146, 147, 155, 157, 162, 183, 185, 187, 191], "columntransform": [3, 76, 90, 92, 94, 95, 154, 156, 158, 160, 161], "enough": [3, 6, 93, 94, 103, 106, 107, 119, 121, 147, 157, 163, 167, 169, 183], "flexibl": [3, 6, 57, 60, 62, 65, 97, 102, 107, 123, 147], "both": [3, 15, 16, 18, 22, 29, 40, 41, 51, 57, 68, 77, 78, 80, 85, 86, 89, 90, 91, 92, 93, 94, 98, 99, 101, 103, 104, 107, 108, 112, 113, 117, 119, 120, 121, 123, 126, 128, 129, 131, 132, 133, 137, 138, 139, 144, 146, 147, 148, 149, 152, 156, 158, 162, 163, 164, 166, 167, 170, 176, 177, 183, 185, 191], "opposit": [3, 141], "cluster": [3, 106, 178], "whose": [3, 120, 157], "group": [3, 6, 20, 25, 29, 78, 104, 105, 106, 111, 171], "subset": [3, 17, 43, 46, 75, 78, 81, 84, 85, 90, 95, 106, 109, 111, 121, 123, 126, 128, 129, 130, 131, 141, 154, 161, 163, 164, 167, 183], "similar": [3, 47, 51, 64, 70, 82, 86, 87, 89, 92, 94, 108, 114, 121, 129, 137, 144, 147, 148, 156, 157, 158, 159, 160, 163, 191], "applic": [3, 6, 99, 105, 148, 151, 167], "them": [3, 6, 13, 64, 78, 80, 81, 86, 89, 90, 98, 101, 103, 106, 112, 114, 116, 120, 121, 122, 125, 144, 146, 148, 156, 157, 158, 162, 166, 169, 170, 183, 191], "broad": 3, "topic": [3, 99, 106, 111], "custom": 3, "commerc": 3, "websit": [3, 36, 53, 82, 87], "although": 3, "mention": [3, 53, 81, 97, 102, 105, 108, 113, 120, 122, 137, 143, 148, 149, 152, 157, 160, 170], "cover": [3, 54, 78, 81, 84, 89, 90, 141], "impli": [3, 167], "fix": [3, 29, 51, 57, 62, 89, 97, 102, 121, 137, 155, 156, 162, 167, 183, 185, 189], "like": [3, 6, 18, 25, 29, 57, 78, 84, 85, 89, 90, 91, 93, 101, 103, 106, 108, 110, 112, 113, 114, 121, 129, 137, 138, 145, 148, 149, 152, 157], "necessari": [3, 6, 46, 78, 121, 158], "subdivid": [3, 163], "select": [3, 6, 13, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 40, 43, 44, 45, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 79, 80, 81, 83, 84, 86, 88, 91, 92, 93, 94, 101, 104, 106, 112, 114, 119, 121, 123, 127, 128, 131, 132, 138, 143, 144, 146, 156, 157, 158, 159, 162, 164, 176, 178, 179, 180, 181, 183, 185, 187, 191], "final": [3, 13, 23, 40, 46, 60, 64, 75, 85, 86, 89, 90, 101, 105, 106, 109, 111, 114, 118, 119, 121, 126, 127, 128, 130, 131, 137, 141, 149, 150, 152, 153, 156, 157, 158, 166, 170, 188], "sometim": [3, 6, 62, 90, 103, 148, 151, 158, 160], "context": [3, 6, 15, 105, 146, 148], "clear": [3, 78, 102, 107, 167], "mani": [3, 6, 29, 44, 51, 64, 77, 78, 79, 80, 85, 86, 89, 90, 101, 103, 104, 106, 107, 108, 111, 114, 123, 141, 148, 157, 162, 191], "need": [3, 6, 22, 24, 29, 37, 41, 64, 70, 78, 82, 84, 86, 87, 89, 90, 95, 97, 101, 102, 106, 107, 109, 112, 113, 114, 119, 121, 122, 123, 124, 133, 137, 139, 141, 143, 144, 147, 149, 150, 152, 153, 154, 156, 157, 158, 160, 161, 167, 181, 183], "criteria": 3, "ml": [3, 6, 99], "cheatsheet": 3, "http": [3, 6, 36, 78, 85, 99, 106, 111], "readthedoc": 3, "io": [3, 36], "en": 3, "latest": [3, 28], "html": [3, 84, 86, 87, 90, 95, 101, 106, 111, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "googl": 3, "develop": [3, 6, 36, 75, 78, 91, 93, 109, 144], "com": [3, 6, 36], "advanc": [3, 6, 36, 75, 92, 94], "terminolog": 3, "org": [3, 78, 84, 85, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "stabl": [3, 112, 114, 137, 183, 191], "modifi": [4, 6, 120, 122, 144], "run": [4, 6, 18, 46, 70, 82, 87, 96, 100, 101, 112, 118, 127, 159, 160, 183, 185, 191], "statu": [4, 25, 78, 84, 89, 90, 156, 158, 160], "python_script": 4, "01_tabular_data_explor": 4, "2023": 4, "04": [4, 12, 30, 49, 72, 86, 113, 121, 171, 174], "19": [4, 80, 89, 96, 108, 109, 120, 121, 122, 124, 143, 159, 160, 162, 164], "23": [4, 89, 96, 106, 108, 109, 110, 111, 112, 119, 120, 122, 124, 134, 137, 140, 160], "cach": 4, "13": [4, 78, 84, 86, 96, 99, 105, 108, 109, 110, 121, 124, 141, 147, 151, 160, 162], "01": [4, 11, 19, 32, 39, 48, 61, 63, 67, 86, 101, 109, 121, 122, 136, 141, 142, 156, 157, 159, 171, 173, 175, 186], "01_tabular_data_exploration_ex_01": 4, "16": [4, 78, 86, 89, 96, 99, 108, 110, 120, 121, 124, 137, 144, 149, 152, 159, 160, 162, 163, 169], "01_tabular_data_exploration_sol_01": 4, "6": [4, 13, 22, 40, 51, 75, 77, 78, 80, 86, 87, 95, 96, 99, 102, 103, 104, 106, 108, 109, 111, 112, 120, 121, 124, 134, 137, 140, 148, 151, 156, 159, 160, 162, 163, 164, 167, 168, 171, 183], "03": [4, 10, 12, 21, 29, 31, 42, 59, 69, 72, 171, 182], "02_numerical_pipeline_cross_valid": 4, "02_numerical_pipeline_ex_00": 4, "02_numerical_pipeline_ex_01": 4, "22": [4, 96, 106, 108, 109, 111, 112, 134, 137, 140, 151, 153, 159], "02_numerical_pipeline_hands_on": 4, "35": [4, 78, 108, 110, 121], "02_numerical_pipeline_introduct": 4, "83": [4, 78, 105, 120, 121], "02_numerical_pipeline_sc": 4, "02_numerical_pipeline_sol_00": 4, "59": [4, 86, 89, 108, 109], "02_numerical_pipeline_sol_01": 4, "24": [4, 96, 106, 108, 109, 110, 111, 112, 124, 134, 137, 140, 141, 148, 153, 160], "03_categorical_pipelin": 4, "82": [4, 83, 85, 88, 120, 121], "03_categorical_pipeline_column_transform": 4, "9": [4, 29, 77, 78, 87, 95, 96, 99, 102, 103, 104, 106, 108, 111, 112, 120, 121, 122, 124, 135, 137, 140, 141, 149, 152, 156, 160, 162, 164, 191], "03_categorical_pipeline_ex_01": 4, "11": [4, 78, 81, 89, 96, 108, 121, 124, 141, 156, 160, 162, 167, 183], "03_categorical_pipeline_ex_02": 4, "8": [4, 64, 78, 80, 84, 87, 89, 95, 96, 99, 102, 103, 104, 105, 106, 107, 108, 111, 112, 114, 118, 119, 120, 121, 122, 124, 125, 127, 134, 137, 140, 142, 144, 148, 154, 156, 159, 160, 161, 162, 163, 168, 183, 185, 191], "03_categorical_pipeline_sol_01": 4, "63": [4, 108, 114, 124, 156], "03_categorical_pipeline_sol_02": 4, "25": [4, 64, 78, 84, 85, 86, 90, 96, 106, 107, 108, 109, 111, 112, 124, 134, 137, 138, 140, 145, 156, 157, 160], "34": [4, 108, 111, 121, 159], "03_categorical_pipeline_visu": 4, "27": [4, 78, 89, 96, 108, 109], "cross_validation_baselin": 4, "cross_validation_ex_01": 4, "cross_validation_ex_02": 4, "77": [4, 108, 110, 120, 121, 148], "cross_validation_group": 4, "7": [4, 18, 51, 77, 78, 80, 86, 87, 89, 96, 99, 102, 103, 104, 106, 107, 108, 109, 111, 112, 120, 121, 122, 124, 134, 137, 140, 141, 156, 159, 160, 162, 164, 167, 169, 171, 183, 191], "87": [4, 89, 121, 156, 160], "cross_validation_learning_curv": 4, "cross_validation_nest": 4, "26": [4, 96, 108, 109, 124, 160], "69": [4, 108, 113], "cross_validation_sol_01": 4, "92": [4, 85, 89, 96, 141, 159, 191], "cross_validation_sol_02": 4, "cross_validation_stratif": 4, "46": [4, 89, 96, 106, 108, 119, 120, 121, 124, 162], "cross_validation_tim": 4, "55": [4, 100, 108, 109, 124], "cross_validation_train_test": 4, "12": [4, 78, 86, 95, 96, 107, 108, 109, 110, 111, 121, 122, 124, 141, 148, 156, 160, 162, 169], "cross_validation_validation_curv": 4, "datasets_ames_h": 4, "datasets_bike_rid": 4, "28": [4, 78, 84, 86, 89, 96, 106, 108, 109, 110, 120, 124, 156, 157, 160], "78": [4, 108, 148, 163], "datasets_blood_transfus": 4, "37": [4, 84, 85, 86, 89, 106, 108, 111, 112, 121, 126, 134, 137, 140, 159, 160], "datasets_california_h": 4, "02": [4, 10, 11, 20, 30, 42, 48, 63, 69, 86, 171, 173, 182, 184], "dev_features_import": 4, "29": [4, 96, 108, 112, 120, 124, 129, 144], "75": [4, 64, 84, 86, 89, 95, 96, 103, 105, 108, 111], "ensemble_adaboost": 4, "30": [4, 78, 84, 89, 90, 96, 97, 99, 100, 102, 107, 108, 110, 111, 114, 120, 122, 124, 135, 141, 154, 156, 157, 158, 160, 161, 167, 170], "93": [4, 105, 120, 160], "ensemble_bag": 4, "ensemble_ex_01": 4, "ensemble_ex_02": 4, "ensemble_ex_03": 4, "ensemble_ex_04": 4, "ensemble_gradient_boost": 4, "31": [4, 108, 118, 127, 148, 160], "99": [4, 86], "43": [4, 90, 96, 99, 106, 108, 109, 120, 121], "ensemble_hist_gradient_boost": 4, "32": [4, 90, 108, 122, 137], "49": [4, 89, 108, 120, 121, 124, 129, 143, 160], "ensemble_hyperparamet": 4, "258": [4, 148], "71": [4, 108, 121, 160, 168], "ensemble_introduct": 4, "33": [4, 106, 108, 111, 121, 159], "64": [4, 99, 108, 109, 160], "ensemble_random_forest": 4, "38": [4, 78, 84, 86, 89, 108, 156, 157, 160], "09": [4, 105, 109], "ensemble_sol_01": 4, "68": [4, 80, 95, 108, 152, 160, 162], "ensemble_sol_02": 4, "ensemble_sol_03": 4, "39": [4, 80, 89, 90, 108, 120, 156, 160, 164], "60": [4, 29, 78, 85, 95, 108, 109, 112, 114, 124, 159, 167], "ensemble_sol_04": 4, "40": [4, 29, 78, 80, 84, 85, 86, 90, 105, 106, 108, 121, 124, 135, 138, 141, 145, 155, 156, 157, 160, 162, 164], "91": [4, 96, 108], "feature_selection_ex_01": 4, "feature_selection_introduct": 4, "41": [4, 85, 106, 108, 111, 112, 134, 137, 140], "20": [4, 18, 29, 64, 78, 80, 89, 94, 95, 96, 101, 106, 107, 108, 109, 110, 111, 117, 121, 122, 124, 126, 148, 153, 154, 155, 161, 162, 164], "feature_selection_limitation_model": 4, "42": [4, 77, 84, 86, 88, 89, 90, 107, 108, 121, 124, 131, 147, 154, 155, 156, 158, 160, 161, 162], "58": [4, 108, 109], "feature_selection_sol_01": 4, "linear_models_ex_01": 4, "linear_models_ex_02": 4, "linear_models_ex_03": 4, "06": 4, "linear_models_ex_04": 4, "linear_models_ex_05": 4, "linear_models_regular": 4, "linear_models_sol_01": 4, "linear_models_sol_02": 4, "47": [4, 96, 106, 108, 124], "linear_models_sol_03": 4, "linear_models_sol_04": 4, "linear_models_sol_05": 4, "linear_regression_in_sklearn": 4, "96": 4, "linear_regression_non_linear_link": 4, "linear_regression_without_sklearn": 4, "05": [4, 29, 31, 38, 72, 96, 99, 102, 103, 104, 105, 109, 111, 114, 119, 122, 125, 148, 158, 163, 167, 169, 171], "logistic_regress": [4, 136, 142, 146], "logistic_regression_non_linear": 4, "95": [4, 102, 105, 111, 160], "metrics_classif": 4, "metrics_ex_01": 4, "metrics_ex_02": 4, "metrics_regress": 4, "44": [4, 78, 84, 96, 106, 108, 156, 157, 160], "metrics_sol_01": 4, "metrics_sol_02": 4, "parameter_tuning_ex_02": 4, "parameter_tuning_ex_03": 4, "parameter_tuning_grid_search": 4, "parameter_tuning_manu": 4, "parameter_tuning_nest": 4, "parameter_tuning_parallel_plot": 4, "61": [4, 108, 121, 122, 160], "parameter_tuning_randomized_search": 4, "45": [4, 78, 85, 86, 89, 96, 106, 108, 110, 120, 124, 138, 145, 156, 163], "48": [4, 84, 85, 86, 108, 124, 159], "parameter_tuning_sol_02": 4, "parameter_tuning_sol_03": 4, "trees_classif": 4, "trees_dataset": 4, "trees_ex_01": 4, "trees_ex_02": 4, "trees_hyperparamet": 4, "74": [4, 108, 121], "trees_regress": 4, "trees_sol_01": 4, "trees_sol_02": 4, "lot": [6, 78, 111, 112, 131, 148], "materi": 6, "far": [6, 96, 107, 119, 126, 130, 141], "congratul": 6, "And": [6, 105], "thank": [6, 158], "everyon": 6, "instructor": 6, "staff": 6, "peopl": [6, 78, 99, 106, 111, 112, 148], "who": [6, 90, 148], "help": [6, 64, 70, 86, 88, 92, 94, 97, 98, 102, 103, 107, 108, 109, 110, 111, 112, 121, 128, 131, 141, 146, 148, 191], "forum": [6, 36], "student": [6, 36], "hard": [6, 78, 79, 80, 128, 131, 148], "work": [6, 41, 51, 64, 69, 78, 86, 89, 90, 104, 105, 109, 114, 121, 123, 130, 131, 137, 154, 157, 159, 161, 163, 165, 168, 169, 171, 176, 191], "summar": [6, 106, 113, 123], "train": [6, 15, 16, 17, 18, 26, 29, 34, 35, 37, 41, 43, 44, 46, 51, 55, 57, 60, 62, 63, 64, 65, 70, 73, 75, 76, 78, 81, 82, 83, 86, 87, 88, 89, 90, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 180, 181, 183, 188, 191], "test": [6, 18, 26, 29, 34, 35, 37, 46, 51, 57, 60, 62, 63, 64, 70, 76, 77, 81, 82, 83, 86, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 112, 114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 137, 140, 141, 142, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 160, 161, 162, 165, 168, 169, 171, 181, 183, 185, 191], "built": [6, 37, 98, 103, 112, 114, 148, 167, 169, 179], "matrix": [6, 29, 86, 89, 99, 123, 128, 131, 133, 137, 139, 141, 144], "featur": [6, 15, 16, 17, 18, 24, 29, 33, 34, 35, 37, 41, 43, 45, 47, 51, 53, 62, 64, 68, 69, 70, 73, 75, 76, 77, 78, 79, 80, 81, 84, 85, 90, 91, 93, 95, 96, 98, 102, 103, 106, 108, 109, 110, 111, 113, 114, 119, 120, 121, 123, 128, 131, 133, 134, 135, 139, 140, 142, 145, 146, 147, 156, 157, 158, 162, 163, 164, 165, 166, 167, 168, 169, 170, 178, 179, 183, 191], "observ": [6, 28, 46, 51, 55, 57, 78, 80, 86, 88, 89, 90, 92, 94, 96, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 110, 113, 114, 117, 119, 121, 123, 126, 127, 129, 133, 135, 137, 139, 141, 146, 147, 148, 156, 159, 162, 163, 164, 167, 168, 170, 180], "transform": [6, 29, 41, 70, 73, 85, 86, 89, 90, 95, 98, 101, 103, 106, 107, 109, 114, 120, 123, 128, 131, 137, 144, 151, 156, 157, 158, 159, 160, 185], "often": [6, 41, 46, 62, 65, 78, 89, 90, 101, 103, 114, 144, 158, 183, 188, 191], "typic": [6, 13, 53, 75, 78, 89, 106, 111, 121, 128, 131, 146, 151, 158, 160, 178], "categor": [6, 37, 51, 68, 73, 75, 76, 77, 78, 79, 80, 91, 93, 108, 123, 137, 141, 146, 148, 156, 164, 171, 183], "variabl": [6, 24, 29, 36, 41, 51, 53, 62, 64, 68, 70, 72, 73, 77, 81, 82, 85, 86, 87, 91, 93, 96, 99, 100, 105, 106, 107, 108, 110, 111, 114, 121, 123, 145, 146, 151, 156, 158, 160, 162, 164, 171, 183, 185, 191], "must": [6, 46, 51, 112, 137, 158, 191], "seek": [6, 34, 121, 122, 148], "suffic": [6, 121], "But": [6, 95, 102, 105, 106, 111, 134, 137, 140, 158, 159], "larg": [6, 18, 51, 73, 90, 101, 106, 109, 111, 117, 118, 120, 121, 126, 127, 130, 131, 136, 137, 142, 151, 155, 158, 159, 160, 162, 185], "detect": [6, 151], "underfit": [6, 13, 22, 29, 33, 40, 46, 55, 57, 60, 62, 63, 64, 65, 100, 119, 121, 122, 123, 147, 171, 176, 178], "simpl": [6, 78, 83, 88, 97, 102, 108, 113, 114, 122, 123, 137, 144, 145, 146, 157, 163, 169, 171], "multipl": [6, 89, 99, 112, 114, 119, 149, 150, 152, 153, 159, 178, 179], "hyper": [6, 18, 37, 101, 103, 158, 162, 185], "control": [6, 47, 82, 86, 87, 97, 101, 102, 107, 121, 123, 129, 136, 142, 154, 155, 157, 159, 161, 162, 163, 167, 178, 188], "import": [6, 13, 18, 22, 29, 36, 37, 51, 62, 64, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 174, 176, 183, 185, 187, 191], "randomsearchcv": 6, "understand": [6, 13, 22, 33, 40, 60, 82, 84, 87, 89, 99, 100, 104, 107, 132, 138, 148, 167, 168, 176, 177, 188], "suit": [6, 177], "intuit": [6, 10, 11, 13, 14, 22, 40, 49, 60, 75, 84, 85, 89, 109, 111, 113, 114, 119, 127, 133, 137, 139, 143, 144, 147, 163, 164, 168, 169, 171], "debug": 6, "build": [6, 18, 29, 75, 77, 78, 85, 95, 97, 102, 114, 120, 130, 133, 139, 156, 167, 171, 173], "combin": [6, 13, 14, 16, 43, 45, 47, 70, 78, 84, 86, 90, 99, 101, 110, 111, 112, 113, 114, 118, 119, 120, 121, 122, 123, 127, 130, 137, 143, 144, 146, 154, 155, 156, 158, 160, 161, 162, 163, 178, 179, 185, 188, 189], "particularli": [6, 91, 93, 121], "few": [6, 78, 79, 80, 83, 84, 88, 106, 108, 110, 111, 121, 123, 158, 164], "benefit": [6, 17, 24, 33, 86, 89, 100, 119, 122, 123, 151, 165, 169, 171], "non": [6, 20, 29, 40, 43, 45, 46, 70, 73, 78, 86, 94, 97, 101, 102, 103, 108, 109, 110, 111, 112, 114, 129, 133, 137, 139, 146, 162, 163, 168, 170, 171, 177, 178, 189], "engin": [6, 41, 99, 109, 144], "base": [6, 13, 14, 15, 16, 18, 29, 34, 36, 43, 51, 53, 64, 78, 79, 80, 86, 92, 94, 99, 106, 109, 114, 119, 122, 123, 129, 130, 134, 137, 140, 144, 147, 148, 156, 158, 163, 164, 171, 191], "seri": [6, 96, 98, 99, 103, 105, 112, 114, 119, 135, 141, 142, 146, 163], "threshold": [6, 15, 27, 78, 95, 111, 163, 168, 169, 179], "variou": [6, 60, 95], "attribut": [6, 37, 78, 86, 89, 99, 101, 106, 111, 112, 114, 116, 125, 143, 144, 155, 156, 160, 162, 185, 191], "natur": [6, 22, 36, 85, 89, 90, 106, 109, 114, 141, 160], "miss": [6, 78, 89, 99, 106, 108, 110, 111, 191], "histgradientboostingregressor": [6, 18, 29, 120, 127], "classifi": [6, 15, 24, 27, 43, 51, 73, 79, 80, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 102, 103, 104, 110, 113, 114, 123, 129, 136, 142, 146, 147, 149, 152, 154, 156, 157, 158, 160, 161, 163, 165, 167, 169, 177, 178, 185, 187, 191], "goto": 6, "strongli": [6, 112], "advis": [6, 112, 141], "pointer": 6, "doc": 6, "rich": 6, "didact": [6, 36, 89, 90, 108], "improv": [6, 36, 70, 94, 95, 99, 100, 102, 103, 107, 115, 117, 121, 124, 126, 159, 185, 188], "compris": [6, 148], "guid": [6, 191], "everi": [6, 78, 81, 106, 109, 112, 143, 158], "explain": [6, 18, 29, 40, 62, 90, 112, 119, 120, 126, 130, 142, 151, 156, 176], "tri": [6, 70, 109, 113, 137], "demonstr": [6, 90, 96, 113, 119, 120, 144, 167], "good": [6, 22, 25, 51, 78, 81, 83, 84, 85, 88, 89, 90, 92, 94, 104, 105, 106, 107, 110, 112, 121, 122, 123, 130, 132, 133, 137, 138, 139, 143, 147, 148, 156, 158, 159, 160, 162, 163, 185], "softwar": [6, 36], "ask": [6, 128, 131, 132, 136, 138, 142, 144, 148], "question": [6, 84, 92, 94, 108, 132, 137, 138, 148, 162], "stackoverflow": 6, "github": [6, 36, 84, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "discuss": [6, 14, 18, 36, 51, 78, 81, 85, 113, 119, 121, 122], "driven": [6, 157], "inclus": 6, "contribut": [6, 64, 86, 99, 137, 162, 185], "other": [6, 14, 27, 29, 36, 46, 64, 77, 78, 81, 85, 86, 89, 90, 91, 93, 96, 97, 98, 102, 103, 104, 105, 109, 112, 114, 121, 129, 137, 141, 143, 144, 147, 151, 156, 158, 159, 160, 166, 170, 185, 188, 191], "advocaci": 6, "curat": 6, "overflow": 6, "code": [6, 29, 36, 51, 53, 73, 79, 82, 83, 91, 97, 98, 114, 115, 116, 117, 118, 120, 128, 131, 132, 133, 134, 135, 136, 137, 138, 149, 150, 154, 155, 156, 158, 159, 161, 162, 165, 166, 185], "start": [6, 36, 51, 78, 82, 83, 84, 86, 87, 88, 89, 90, 92, 94, 96, 99, 103, 104, 105, 106, 109, 110, 119, 121, 122, 128, 129, 131, 136, 137, 142, 145, 146, 148, 151, 153, 155, 157, 162, 163, 164, 165, 169], "carpentri": 6, "resourc": [6, 36, 75, 78, 109, 121, 158], "git": 6, "lab": [6, 36], "unsupervis": [6, 53], "structur": [6, 62, 75, 78, 86, 89, 90, 99, 121, 162, 163, 168, 177], "instanc": [6, 51, 68, 78, 84, 85, 86, 89, 99, 106, 108, 109, 111, 112, 115, 118, 124, 127, 128, 129, 130, 131, 133, 137, 139, 143, 145, 148, 150, 153, 157, 160, 181, 187, 188], "sampl": [6, 14, 15, 16, 18, 20, 29, 46, 53, 63, 65, 68, 78, 79, 80, 81, 84, 85, 86, 89, 90, 97, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 120, 121, 123, 126, 128, 131, 132, 133, 135, 137, 138, 139, 141, 144, 145, 146, 147, 148, 155, 156, 158, 160, 162, 163, 164, 166, 167, 168, 170, 171, 180, 189], "supervis": [6, 53, 106, 178], "recov": [6, 18, 99], "link": [6, 15, 83, 84, 88, 99, 108, 109, 110, 111, 112, 128, 131, 133, 137, 139, 144, 148], "drive": 6, "system": [6, 78, 99], "hand": [6, 29, 95, 99, 113, 126, 137, 144, 156, 158], "nuanc": 6, "deep": [6, 94, 121, 122, 167], "better": [6, 17, 18, 28, 51, 70, 77, 81, 85, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 114, 121, 122, 123, 126, 128, 131, 132, 137, 138, 141, 143, 153, 157, 158, 160, 162, 167, 183, 191], "gradient": [6, 10, 13, 14, 16, 17, 18, 29, 86, 90, 113, 117, 118, 122, 126, 127, 137, 156, 160, 171], "boost": [6, 13, 14, 16, 17, 18, 29, 90, 117, 118, 122, 126, 127, 137, 156, 160, 171], "classif": [6, 15, 22, 40, 51, 53, 64, 68, 77, 78, 84, 85, 91, 93, 95, 97, 98, 99, 102, 103, 104, 106, 110, 113, 145, 149, 150, 151, 152, 153, 165, 167, 168, 169, 171, 176, 177, 178, 191], "regress": [6, 18, 22, 27, 40, 41, 42, 43, 44, 45, 46, 47, 49, 51, 53, 57, 62, 64, 70, 77, 84, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 106, 111, 114, 116, 119, 125, 128, 131, 133, 134, 135, 136, 139, 140, 141, 142, 146, 147, 148, 150, 153, 155, 157, 162, 163, 166, 167, 170, 171, 176, 177, 178, 183, 191], "nativ": [6, 51, 78, 84, 89, 90, 106, 129, 144, 156, 158, 160], "input": [6, 24, 41, 43, 47, 62, 77, 78, 83, 85, 86, 88, 89, 92, 93, 94, 96, 99, 102, 103, 112, 114, 132, 138, 145, 158, 163, 164, 178, 191], "speech": 6, "text": [6, 36, 53, 109, 145], "imag": [6, 99], "voic": 6, "pretrain": 6, "human": [6, 78, 109], "cost": [6, 85, 106, 109, 122, 159, 160], "mainten": 6, "Not": [6, 90, 91, 93, 101], "pytorch": 6, "tensorflow": 6, "introduct": [6, 60, 75, 171], "andrea": 6, "c": [6, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 43, 44, 45, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 99, 101, 110, 136, 142, 148, 157, 178, 179, 180, 181, 183, 185, 187, 191], "m\u00fcller": 6, "sarah": 6, "guido": 6, "handbook": 6, "jake": 6, "van": 6, "der": 6, "pla": 6, "broader": [6, 166, 170], "statist": [6, 18, 60, 78, 80, 85, 86, 89, 92, 94, 106, 111, 113, 114, 128, 131, 148, 191], "jame": 6, "witten": 6, "hasti": 6, "tibshirani": 6, "theori": [6, 113], "concept": [6, 13, 14, 22, 23, 33, 34, 40, 41, 60, 62, 76, 99, 104, 106, 137, 144, 176, 177, 189], "kera": 6, "aur\u00e9lien": 6, "g\u00e9ron": 6, "kaggl": 6, "particip": 6, "challeng": [6, 36, 110], "team": 6, "solut": [6, 10, 11, 12, 18, 19, 30, 31, 32, 36, 38, 42, 48, 49, 63, 67, 69, 72, 89, 105, 128, 129, 143, 147, 156, 171, 173, 182, 184, 186], "share": [6, 114], "winner": 6, "wai": [6, 75, 77, 78, 81, 84, 88, 89, 101, 102, 103, 105, 113, 114, 119, 120, 121, 128, 129, 131, 141, 144, 148, 151, 168, 183, 191], "now": [6, 18, 29, 51, 64, 77, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 137, 138, 140, 141, 145, 148, 149, 152, 154, 156, 158, 159, 160, 161, 163, 166, 167, 170, 183, 191], "touch": 6, "briefli": 6, "fit": [6, 14, 24, 26, 29, 40, 41, 43, 44, 45, 46, 51, 55, 68, 70, 81, 82, 84, 87, 88, 89, 92, 94, 95, 97, 101, 102, 103, 105, 106, 107, 112, 113, 114, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 151, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 176, 180, 185], "wider": [6, 36, 57], "mai": [6, 46, 53, 78, 106, 111, 137, 148, 162], "fail": [6, 105, 149, 152], "weak": [6, 16, 121, 160], "analysi": [6, 75, 84, 97, 102, 110, 111, 137, 160, 162, 163, 171, 184], "kei": [6, 8, 9, 50, 52, 54, 56, 58, 66, 70, 71, 97, 102, 104, 107, 121, 124, 127, 129, 130, 142, 156, 157, 160, 167, 172], "achiev": [6, 18, 78, 83, 86, 88, 100, 102, 110, 167], "reliabl": [6, 99], "even": [6, 36, 40, 65, 80, 81, 85, 89, 90, 92, 93, 94, 99, 103, 105, 106, 113, 120, 121, 126, 129, 137, 141, 144, 147, 148, 149, 150, 152, 153, 156, 162, 188, 189], "cross": [6, 13, 18, 22, 23, 24, 25, 26, 29, 33, 34, 40, 41, 46, 51, 60, 61, 63, 64, 69, 70, 77, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 107, 111, 112, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 134, 137, 140, 147, 148, 149, 150, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 167, 171, 176, 181, 183, 185, 188, 189, 191], "accuraci": [6, 18, 27, 51, 64, 70, 77, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 110, 113, 119, 129, 130, 131, 132, 138, 142, 146, 149, 152, 156, 157, 158, 159, 160, 161, 162, 163, 165, 169, 191], "imperfect": [6, 112], "estim": [6, 13, 17, 22, 29, 33, 40, 46, 51, 60, 64, 70, 75, 81, 90, 95, 101, 103, 105, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 134, 137, 140, 144, 149, 150, 151, 152, 153, 156, 157, 158, 160, 176, 183, 185, 188, 191], "actual": [6, 78, 82, 85, 87, 96, 105, 106, 107, 137, 148, 158], "gener": [6, 17, 18, 22, 23, 28, 29, 51, 54, 60, 62, 63, 64, 70, 81, 83, 84, 85, 86, 88, 89, 90, 91, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 135, 137, 139, 141, 144, 146, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 168, 171, 174, 183, 185, 191], "As": [6, 29, 51, 78, 81, 84, 85, 86, 89, 90, 92, 94, 97, 99, 101, 102, 103, 108, 110, 111, 112, 114, 119, 120, 137, 147, 148, 150, 151, 153, 157, 158, 159, 162, 167, 170], "narrow": 6, "spend": [6, 109, 121], "increasingli": 6, "effort": [6, 109], "split": [6, 15, 18, 23, 29, 37, 46, 70, 78, 81, 83, 88, 89, 90, 96, 101, 104, 105, 106, 108, 112, 115, 119, 120, 121, 123, 124, 126, 128, 131, 147, 148, 151, 156, 158, 160, 163, 165, 167, 168, 169, 178, 179], "afford": 6, "trust": [6, 84, 85, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 157, 158, 160, 163, 169, 170], "think": [6, 79, 80, 105, 109, 133, 139], "carefulli": [6, 99], "complet": [6, 15, 29, 36, 51, 101, 103, 128, 131, 137, 155, 158, 162, 185], "futur": [6, 78, 81, 90, 95, 105, 106, 156], "upon": [6, 95, 102, 103], "affect": [6, 105, 137, 146, 156, 168], "live": [6, 137], "sure": [6, 18, 64, 84, 86, 89, 94, 118, 127, 134, 140], "divers": [6, 163], "demograph": [6, 122], "increas": [6, 16, 18, 28, 29, 46, 51, 55, 57, 62, 80, 86, 89, 102, 106, 107, 112, 117, 120, 121, 126, 137, 145, 146, 147, 156, 160, 162, 163, 165, 167, 168, 169, 181, 189], "coverag": 6, "phrase": 6, "recommend": [6, 36, 75, 78, 89], "identifi": [6, 13, 75, 90, 99, 102, 107, 148, 185], "ani": [6, 15, 18, 29, 36, 77, 78, 81, 84, 86, 88, 90, 93, 94, 96, 99, 102, 104, 105, 106, 107, 109, 110, 111, 112, 114, 121, 122, 123, 127, 128, 129, 130, 131, 143, 146, 156, 158, 159, 162, 167, 180, 191], "bia": [6, 37, 55, 60, 62, 112, 151, 171], "acquisit": 6, "full": [6, 8, 9, 18, 36, 50, 52, 53, 54, 56, 58, 66, 70, 71, 81, 82, 86, 87, 89, 101, 106, 121, 126, 128, 130, 131, 145, 154, 158, 161, 172, 185, 188], "chain": [6, 81, 86, 90], "acquir": [6, 13, 22, 33, 40, 60, 107, 109, 176, 188], "fanci": 6, "put": [6, 33, 37, 86, 107, 112, 137, 163], "product": [6, 101, 104, 106, 137, 156], "routin": [6, 18, 99, 191], "debt": 6, "simpler": [6, 14, 90], "easier": [6, 89, 96, 137, 144], "maintain": 6, "less": [6, 29, 90, 99, 105, 111, 112, 113, 114, 121, 122, 130, 137, 156, 162], "power": [6, 29, 36, 109, 121, 122, 144, 163], "drift": 6, "gave": [6, 148], "methodolog": [6, 36, 60, 106, 168], "element": [6, 22, 85, 89, 99, 106, 138, 145, 148], "alwai": [6, 15, 18, 22, 24, 46, 57, 83, 84, 85, 88, 90, 94, 96, 99, 101, 102, 103, 104, 106, 107, 110, 111, 117, 123, 126, 129, 141, 147, 148, 158, 159, 170, 183, 185, 191], "solid": 6, "conclus": [6, 78, 98, 99, 101, 103, 104, 105, 107, 110, 121, 129], "standpoint": 6, "biggest": 6, "shortcom": 6, "cannot": [6, 18, 29, 62, 78, 104, 105, 107, 112, 121, 128, 131, 147, 148, 151, 156, 159, 170, 188], "autom": [6, 78, 171, 189], "domain": 6, "knowledg": [6, 36, 75, 101, 107, 114, 131, 144, 147, 158], "critic": [6, 36, 108], "thing": [6, 78, 89, 90, 95, 105, 121, 156], "oper": [6, 86, 114, 148, 158], "risk": [6, 147], "advertis": 6, "individu": [6, 17, 29, 78, 86, 90, 110, 114, 116, 123, 125, 147, 163, 191], "caus": [6, 18, 55, 62, 78, 89, 93, 94, 137, 141, 156, 158, 185], "wast": [6, 121], "bit": [6, 29, 88, 106, 107, 112, 149, 152, 158], "monei": 6, "annoi": 6, "otherwis": [6, 18, 84, 93, 99, 101, 123, 144, 145, 167], "mostli": [6, 162], "harmless": 6, "medicin": 6, "kill": 6, "logic": [6, 156], "fals": [6, 16, 57, 85, 89, 92, 94, 99, 101, 105, 109, 111, 127, 129, 130, 135, 137, 140, 141, 144, 148, 152, 155, 156, 160, 162, 163, 169, 181], "brain": 6, "tumor": 6, "sent": 6, "surgeri": 6, "veri": [6, 18, 60, 64, 78, 84, 90, 92, 94, 101, 102, 104, 107, 110, 111, 112, 114, 119, 121, 123, 127, 137, 144, 148, 156, 157, 158, 159, 160, 167, 185], "danger": [6, 137, 160], "mr": 6, "confirm": [6, 96, 104, 109, 111, 114, 128, 131, 137, 158, 159], "should": [6, 18, 23, 29, 34, 35, 46, 73, 77, 78, 85, 86, 90, 94, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 118, 119, 121, 122, 127, 128, 129, 131, 132, 133, 137, 138, 139, 144, 146, 147, 148, 149, 152, 153, 154, 156, 157, 158, 161, 163, 165, 167, 168, 169, 181, 183, 185, 188, 189], "delai": 6, "life": [6, 78, 128, 131], "save": [6, 191], "treatment": [6, 62], "hospit": [6, 25], "stai": [6, 41, 46, 114], "overcrowd": 6, "unit": [6, 78, 84, 86, 89, 90, 106, 109, 111, 112, 113, 137, 143, 145, 151, 156, 160], "chang": [6, 28, 29, 37, 51, 86, 98, 103, 112, 113, 117, 126, 129, 154, 157, 161, 163, 188, 191], "inpati": 6, "chose": [6, 57, 78, 119, 137], "load": [6, 18, 51, 68, 79, 80, 81, 82, 86, 87, 89, 90, 91, 93, 97, 100, 101, 102, 104, 105, 106, 107, 110, 111, 113, 115, 120, 121, 122, 124, 134, 136, 137, 139, 140, 141, 142, 143, 147, 148, 156, 157, 159, 160, 163, 164, 165, 166, 167, 168, 169, 170, 185, 191], "interest": [6, 53, 78, 79, 80, 96, 98, 103, 104, 106, 107, 109, 111, 114, 119, 143, 144, 148, 151, 156, 157, 158, 159, 160, 162, 191], "focus": [6, 14, 65, 111, 113, 148, 158], "easi": [6, 90, 105, 106, 109, 167], "accumul": 6, "target": [6, 18, 29, 40, 41, 45, 51, 53, 62, 64, 68, 70, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 169, 171, 183, 191], "proxi": [6, 148], "reflect": [6, 106, 114, 123], "ground": [6, 119, 148], "truth": [6, 119, 148], "polici": 6, "uneven": 6, "across": [6, 51, 81, 86, 96, 112, 137, 160, 191], "popul": [6, 25, 78, 106, 111, 112, 134, 137, 140, 148, 162], "eg": 6, "qualiti": [6, 112, 151, 158], "affair": 6, "desir": [6, 83, 88, 123], "qualif": 6, "respons": 6, "women": 6, "pai": [6, 89, 113], "men": 6, "pick": [6, 29, 95, 101, 108, 109, 112, 120, 157, 188], "amplifi": 6, "inequ": 6, "mechan": [6, 29, 85, 86, 158], "die": 6, "naiv": [6, 18, 29, 78, 101, 110, 120, 123], "bad": [6, 93, 102, 131, 147, 148, 185], "health": [6, 36], "fallaci": 6, "compar": [6, 13, 17, 18, 22, 29, 37, 51, 53, 63, 64, 77, 78, 81, 83, 85, 86, 88, 89, 90, 91, 93, 101, 102, 103, 107, 111, 112, 114, 117, 119, 120, 124, 126, 129, 130, 131, 137, 148, 151, 160, 162, 163, 171, 183, 191], "wors": [6, 18, 28, 51, 77, 102, 103, 105, 143, 183], "baselin": [6, 22, 24, 83, 88, 90, 91, 93, 98, 99, 102, 103, 122, 171], "heart": [6, 29, 109], "pressur": 6, "greater": [6, 29, 77], "trigger": 6, "care": [6, 34, 89, 101, 104, 110, 111, 128, 131, 137], "which": [6, 14, 16, 17, 18, 23, 25, 27, 29, 33, 34, 41, 46, 51, 62, 64, 70, 73, 76, 77, 78, 81, 84, 85, 86, 88, 89, 90, 94, 95, 96, 97, 100, 101, 102, 103, 105, 106, 107, 109, 110, 111, 112, 113, 114, 119, 120, 121, 123, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 156, 157, 159, 160, 162, 167, 168, 169, 176, 177, 178, 183, 185, 187, 189, 191], "learner": [6, 14, 113, 114, 119, 121, 122], "predictor": [6, 14, 15, 16, 17, 51, 70, 85, 86, 90, 103, 124, 137, 156, 163], "pure": [6, 131, 169], "benefici": [6, 33, 86, 129, 158, 160, 167], "intervent": [6, 78], "brittl": 6, "interpret": [6, 17, 36, 109, 111, 112, 143, 151, 159, 163], "subject": [6, 78, 148], "caution": [6, 94, 112], "feedback": 6, "loop": [6, 101, 112, 121, 154, 156, 158, 161, 191], "todai": 6, "ai": 6, "alloc": 6, "loan": 6, "screen": [6, 8, 9, 50, 52, 54, 56, 58, 66, 71, 172], "job": [6, 86], "prioritis": 6, "treatement": 6, "law": [6, 29], "enforc": [6, 105, 109, 121, 137], "court": 6, "fairlearn": [6, 78], "assess": [6, 51, 81, 85, 98, 100, 101, 103, 107, 117, 126, 132, 137, 138, 147, 148, 158, 162], "shift": [6, 86], "technolog": [6, 99], "induc": [6, 112, 114, 141], "societi": 6, "though": [6, 103, 120, 150, 153], "difficult": [6, 109, 121, 143, 151], "intersect": [6, 159, 162], "No": [6, 24], "found": [6, 64, 101, 110, 111, 118, 121, 127, 137, 143, 154, 156, 158, 161, 162, 163, 167, 168, 185, 191], "short": [6, 34, 84, 111, 122, 164], "move": [6, 90, 109, 159, 162], "choos": [6, 18, 36, 78, 91, 93, 106, 112, 128, 129, 131, 137, 144, 158, 181, 191], "revolut": 6, "fantast": [6, 131], "opportun": 6, "With": [6, 37, 93, 106, 109, 121, 129, 130, 148, 156, 160, 167], "lift": 6, "roadblock": 6, "hope": [6, 95], "empow": 6, "varieti": [6, 36, 81], "mindset": 6, "dream": 6, "being": [6, 44, 96, 162], "adventur": 6, "navig": [8, 9, 50, 52, 54, 56, 58, 66, 71, 172], "slide": [8, 9, 50, 52, 54, 56, 58, 66, 71, 159, 162, 172], "click": [8, 9, 15, 50, 52, 54, 56, 58, 66, 71, 159, 162, 172, 185], "press": [8, 9, 50, 52, 54, 56, 58, 66, 71, 172], "arrow": [8, 9, 50, 52, 54, 56, 58, 66, 71, 172], "go": [8, 9, 13, 22, 29, 33, 36, 40, 50, 52, 54, 56, 58, 60, 66, 71, 75, 81, 82, 87, 89, 97, 99, 101, 102, 105, 106, 107, 109, 111, 112, 119, 122, 129, 146, 148, 156, 163, 172, 176, 188], "next": [8, 9, 50, 52, 54, 56, 58, 62, 66, 71, 84, 85, 89, 95, 97, 98, 102, 103, 104, 105, 113, 119, 122, 137, 157, 163, 172], "previou": [8, 9, 16, 18, 22, 29, 50, 51, 52, 54, 56, 58, 64, 66, 68, 70, 71, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 98, 99, 100, 101, 103, 104, 105, 106, 107, 114, 115, 118, 119, 120, 121, 123, 124, 127, 128, 131, 132, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 147, 149, 152, 154, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166, 169, 170, 172, 183, 185, 188, 191], "p": [8, 9, 50, 52, 54, 56, 58, 66, 71, 99, 149, 152, 172], "toggl": [8, 9, 50, 52, 54, 56, 58, 66, 71, 172], "mode": [8, 9, 36, 50, 52, 54, 56, 58, 66, 71, 172], "adapt": [10, 104, 122, 144, 147, 160, 171], "adaboost": [10, 13, 119, 171], "gbdt": [10, 113, 121, 126, 171], "exercis": [10, 11, 12, 19, 29, 30, 31, 32, 36, 38, 42, 48, 49, 51, 63, 67, 69, 72, 84, 89, 121, 143, 144, 156, 158, 163, 171, 173, 182, 183, 184, 186], "m6": [10, 11, 12, 121, 171], "speed": [10, 29, 34, 35, 46, 109, 112, 129, 158, 160, 171], "quiz": [10, 11, 12, 19, 20, 21, 30, 31, 38, 39, 42, 48, 49, 59, 61, 63, 67, 69, 72, 162, 171, 173, 174, 175, 182, 184, 186], "bag": [11, 13, 15, 16, 113, 115, 121, 122, 123, 124, 171], "introductori": [11, 171], "forest": [11, 13, 14, 15, 17, 18, 37, 112, 116, 117, 119, 120, 122, 125, 126, 129, 130, 171], "togeth": [13, 14, 72, 77, 85, 86, 93, 98, 99, 101, 103, 113, 119, 147, 167, 171], "ensembl": [13, 14, 17, 18, 29, 62, 90, 92, 94, 112, 113, 114, 117, 119, 120, 121, 123, 124, 125, 126, 127, 129, 130, 154, 156, 158, 160, 161], "famili": [13, 14, 40, 60, 62, 78, 84, 86, 90, 122, 157], "techniqu": [13, 33, 78, 112], "bootstrap": [13, 14, 18, 121, 122, 123, 124, 171], "ii": [13, 22, 81, 85, 137, 143], "belong": [13, 18, 51, 84, 88, 89, 99, 102, 110, 163, 183], "former": [13, 77, 78, 86, 129, 148], "strategi": [13, 14, 18, 22, 23, 24, 25, 29, 51, 64, 81, 83, 85, 88, 91, 93, 95, 96, 98, 99, 101, 103, 104, 105, 106, 108, 113, 114, 117, 120, 123, 126, 138, 141, 143, 148, 151, 158, 188, 191], "later": [13, 18, 78, 84, 85, 95, 102, 106, 120, 133, 139, 144, 147, 148, 155, 156, 158, 162], "hyperparamet": [13, 17, 26, 41, 64, 97, 100, 101, 102, 107, 115, 119, 122, 124, 131, 136, 137, 142, 155, 162, 176, 177, 184, 185, 186, 187, 188, 189], "allow": [13, 14, 29, 46, 70, 78, 81, 84, 86, 89, 97, 102, 106, 108, 111, 112, 121, 128, 131, 132, 133, 137, 138, 139, 141, 145, 146, 149, 151, 152, 158, 160, 167, 168, 176, 185, 188, 189], "technic": [13, 22, 33, 36, 40, 60, 75, 176, 188], "skill": [13, 22, 33, 40, 60, 75, 176, 188], "carri": [13, 22, 33, 40, 51, 60, 75, 89, 100, 111, 130, 176, 188], "basic": [13, 22, 33, 36, 40, 54, 60, 75, 104, 106, 112, 124, 151, 176, 188], "usag": [13, 22, 33, 40, 60, 84, 108, 109, 110, 111, 123, 158, 176, 188], "mainli": [13, 14, 22, 33, 40, 78, 108, 163, 176], "around": [13, 22, 33, 40, 78, 84, 95, 99, 102, 105, 106, 107, 109, 112, 147, 148, 176], "overfit": [13, 16, 18, 22, 29, 33, 40, 46, 55, 57, 60, 62, 63, 64, 65, 100, 101, 105, 112, 113, 114, 117, 121, 122, 123, 126, 130, 137, 147, 158, 162, 167, 171, 176, 178, 181], "valid": [13, 18, 22, 23, 24, 25, 26, 29, 33, 34, 40, 41, 46, 51, 60, 61, 62, 64, 69, 70, 77, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 111, 112, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 134, 137, 140, 147, 148, 149, 150, 152, 153, 154, 156, 157, 158, 159, 160, 161, 167, 168, 171, 176, 181, 183, 185, 188, 189, 191], "principl": [13, 22, 34, 148], "through": [13, 22, 29, 33, 36, 40, 60, 75, 97, 102, 107, 112, 118, 127, 137, 145, 146, 149, 152, 156, 176, 185, 188], "hour": [13, 22, 40, 51, 60, 75, 78, 81, 83, 84, 85, 86, 88, 89, 90, 156, 157, 160, 176, 188], "saw": [14, 29, 41, 84, 86, 89, 90, 106, 107, 119, 121, 135, 137, 141, 143, 146, 147, 149, 152, 156, 158, 159, 160, 163, 167, 168, 169, 177], "parallel": [14, 16, 119, 158, 159, 162, 185], "sequenti": [14, 16, 57, 86, 120, 159, 185], "intern": [14, 46, 70, 86, 90, 101, 106, 113, 114, 117, 118, 126, 127, 141, 156, 157, 158, 185], "machineri": [14, 113, 119], "art": 14, "learn": [14, 16, 17, 23, 24, 27, 28, 29, 34, 37, 41, 44, 47, 48, 55, 62, 64, 68, 70, 72, 73, 76, 78, 81, 82, 84, 86, 87, 88, 89, 90, 91, 93, 97, 98, 99, 101, 102, 103, 104, 105, 106, 110, 111, 113, 116, 118, 120, 121, 123, 125, 127, 128, 129, 130, 131, 133, 136, 137, 139, 141, 142, 144, 146, 147, 148, 149, 151, 152, 153, 156, 158, 159, 161, 164, 168, 177, 178, 179, 180, 186, 189, 191], "earli": [14, 29, 117, 118, 126, 127], "stop": [14, 29, 91, 93, 96, 103, 109, 117, 118, 126, 127], "stack": 14, "By": [15, 18, 29, 47, 51, 78, 89, 101, 104, 107, 109, 123, 131, 137, 141, 148, 151, 166, 170, 183], "default": [15, 18, 27, 28, 47, 51, 64, 70, 81, 82, 87, 89, 97, 102, 104, 109, 115, 121, 122, 124, 136, 137, 141, 142, 148, 149, 150, 151, 152, 153, 157, 158, 183, 188], "baggingclassifi": [15, 123], "baggingregressor": [15, 114, 115, 122, 123, 124], "draw": [15, 29, 78, 98, 103, 114, 121, 129, 160, 163, 185], "replac": [15, 29, 89, 108, 109, 111, 114], "without": [15, 36, 48, 51, 64, 78, 82, 85, 87, 96, 99, 101, 102, 105, 106, 108, 109, 110, 121, 122, 129, 130, 141, 143, 147, 148, 149, 151, 152, 171, 191], "d": [15, 16, 17, 18, 20, 25, 27, 29, 37, 44, 46, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 78, 85, 99, 171, 178, 183, 185, 187, 191], "all": [15, 16, 17, 18, 24, 25, 26, 27, 29, 37, 45, 46, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 81, 82, 84, 85, 86, 87, 89, 92, 94, 96, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 120, 121, 122, 123, 129, 134, 137, 138, 140, 144, 145, 148, 155, 156, 157, 158, 159, 162, 163, 166, 168, 170, 178, 179, 181, 183, 185, 187, 191], "answer": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 43, 44, 45, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 89, 108, 162, 178, 179, 180, 181, 183, 185, 187, 191], "hint": [15, 29, 51, 64, 70, 77, 79, 80, 82, 83, 87, 88, 92, 94, 134, 140, 191], "those": [15, 60, 84, 98, 103, 114, 120, 144, 156, 158, 162, 180, 191], "base_estim": [15, 124], "decid": [15, 22, 78, 84, 106, 111, 128, 131, 158], "resampl": [15, 55, 101, 109, 113, 137], "perform": [15, 17, 18, 19, 22, 23, 24, 26, 29, 34, 35, 51, 64, 68, 70, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 110, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 137, 144, 147, 148, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 167, 176, 183, 185, 188, 189, 191], "correct": [16, 17, 18, 29, 64, 85, 87, 113, 119, 121, 148, 151, 154, 160, 161, 167, 191], "statement": [16, 18, 27, 29, 64, 185, 191], "simultan": 16, "slightli": [16, 78, 87, 89, 90, 106, 109, 113, 114, 121, 122, 123, 126], "histogram": [16, 29, 70, 78, 79, 80, 86, 98, 103, 108, 111, 118, 120, 127, 146, 156, 160], "acceler": [16, 29, 109, 120], "subsampl": [16, 111, 123, 128, 131], "origin": [16, 70, 81, 84, 85, 89, 90, 104, 105, 108, 113, 114, 119, 120, 123, 134, 135, 140, 141, 144, 145, 151, 163, 164, 168], "bin": [16, 78, 86, 96, 99, 103, 106, 107, 108, 109, 110, 111, 120, 159, 160], "numer": [16, 51, 68, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 98, 103, 106, 108, 109, 111, 137, 141, 144, 155, 156, 157, 162, 171, 183, 191], "tend": [16, 29, 99, 121, 122, 151, 158], "true": [16, 18, 27, 29, 51, 57, 62, 64, 70, 85, 96, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 129, 132, 134, 135, 137, 138, 140, 141, 146, 148, 151, 155, 156, 158, 162, 181, 185, 191], "shallow": [17, 113, 119, 121, 167], "deeper": [17, 96, 97, 100, 102, 106, 107, 113, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 163, 165, 166, 167, 168, 169, 170], "exist": [17, 78, 81, 99, 141], "maximum": [17, 29, 86, 89, 101, 107, 144, 148, 156, 160, 163, 165, 166, 168, 169, 170, 178, 181], "depth": [17, 18, 36, 79, 80, 107, 111, 113, 119, 120, 121, 122, 136, 142, 146, 154, 161, 163, 164, 165, 166, 167, 168, 169, 170, 178, 181, 183], "rate": [17, 29, 85, 96, 100, 106, 109, 121, 148, 156, 159, 161], "option": [17, 89, 96, 104, 106, 109, 117, 126, 141, 188, 191], "reduc": [17, 18, 41, 46, 51, 95, 99, 100, 120, 121, 122, 123, 129, 137, 138], "sensit": [17, 55, 147, 148, 159, 162, 177], "program": [18, 29, 36, 51, 64, 75, 77, 99, 128, 131, 183, 191], "notic": [18, 86, 102, 106, 111, 112, 146, 148, 155, 162], "tradit": 18, "panda": [18, 29, 36, 51, 64, 68, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 119, 121, 123, 124, 125, 127, 129, 130, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 183, 185, 191], "pd": [18, 29, 51, 64, 68, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 119, 121, 123, 124, 125, 127, 129, 130, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 183, 185, 191], "read_csv": [18, 29, 51, 64, 68, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 102, 103, 105, 108, 109, 110, 113, 116, 123, 125, 132, 136, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 183, 185, 191], "csv": [18, 29, 51, 64, 68, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 102, 103, 105, 108, 109, 110, 113, 116, 123, 125, 132, 136, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 183, 185, 191], "feature_nam": [18, 51, 89, 108, 111, 116, 125, 132, 135, 137, 138, 141, 143, 145, 146, 147, 163, 164, 166, 167, 168, 169, 170], "culmen": [18, 79, 80, 113, 136, 142, 146, 163, 164, 165, 167, 169, 191], "mm": [18, 80, 113, 116, 125, 132, 136, 138, 142, 143, 145, 146, 163, 164, 165, 166, 167, 168, 169, 170, 191], "flipper": [18, 116, 125, 132, 138, 143, 145, 164, 166, 167, 168, 170, 191], "target_nam": [18, 29, 51, 64, 77, 81, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 108, 109, 116, 123, 125, 132, 138, 141, 143, 145, 147, 154, 156, 157, 158, 160, 161, 166, 167, 168, 170, 183, 191], "bodi": [18, 79, 80, 109, 116, 125, 132, 138, 143, 145, 164, 166, 167, 168, 170, 191], "mass": [18, 29, 116, 125, 132, 138, 143, 145, 164, 166, 167, 168, 170, 191], "dropna": [18, 191], "frac": [18, 29], "random_st": [18, 37, 84, 86, 88, 90, 96, 97, 101, 102, 103, 104, 105, 106, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 135, 136, 137, 141, 142, 146, 147, 148, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 167, 169, 183], "reset_index": [18, 136, 142, 146], "drop": [18, 29, 37, 51, 64, 77, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 102, 103, 105, 108, 109, 110, 111, 112, 123, 141, 148, 149, 150, 151, 152, 153, 154, 156, 158, 160, 161, 183], "therefor": [18, 29, 77, 78, 81, 86, 88, 90, 96, 99, 100, 101, 103, 106, 107, 111, 113, 119, 120, 121, 123, 129, 130, 131, 133, 137, 138, 139, 141, 144, 146, 147, 148, 153, 158, 162, 167], "randomli": [18, 29, 101, 103, 106, 112, 114, 123, 160], "shuffl": [18, 37, 84, 99, 101, 104, 105, 106, 112, 118, 127, 135, 141, 148, 151], "break": [18, 99, 137, 141], "spuriou": 18, "troubl": [18, 104], "outsid": [18, 156, 163, 166, 170], "scope": [18, 78, 144], "regressor": [18, 24, 28, 29, 41, 47, 51, 85, 86, 96, 100, 105, 106, 107, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 135, 137, 141, 144, 151, 177, 180, 183], "sklearn": [18, 29, 46, 51, 64, 77, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 165, 167, 168, 169, 170, 183, 185, 187, 191], "randomforestregressor": [18, 112, 119, 121, 123, 125, 126], "except": [18, 91, 93, 149, 152], "exact": [18, 29, 119], "fold": [18, 25, 29, 51, 64, 77, 81, 99, 104, 106, 112, 118, 127, 129, 130, 131, 132, 134, 137, 138, 140, 150, 153, 158, 160, 162, 183, 191], "model_select": [18, 29, 51, 64, 81, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 136, 137, 140, 141, 142, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 165, 167, 169, 183, 185, 191], "cross_valid": [18, 29, 51, 64, 70, 77, 81, 89, 90, 91, 92, 93, 94, 95, 96, 97, 102, 103, 104, 107, 111, 112, 118, 119, 120, 122, 127, 129, 130, 137, 140, 149, 150, 152, 153, 156, 157, 158, 183, 191], "cv": [18, 29, 51, 70, 77, 81, 90, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 112, 118, 122, 127, 130, 137, 140, 149, 152, 153, 156, 158, 160, 161, 167, 183, 185, 191], "store": [18, 29, 78, 84, 86, 96, 98, 103, 104, 106, 108, 109, 110, 114, 122, 129, 130, 137, 143, 147, 155, 156, 162, 191], "return_train_scor": [18, 29, 64, 107, 137], "count": [18, 51, 64, 77, 78, 80, 84, 86, 88, 89, 96, 99, 104, 108, 109, 110, 111, 163, 183, 191], "rang": [18, 41, 51, 64, 70, 77, 84, 86, 99, 101, 104, 106, 109, 110, 111, 112, 114, 137, 145, 158, 159, 160, 162, 164, 166, 170, 180, 183, 185, 191], "substanti": [18, 51, 77, 183, 191], "almost": [18, 51, 77, 85, 94, 106, 112, 142, 145, 158, 169, 183], "100": [18, 51, 64, 84, 85, 96, 100, 103, 106, 107, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 128, 129, 130, 131, 133, 134, 137, 139, 140, 144, 147, 148, 151, 155, 160, 161, 162, 191], "again": [18, 97, 102, 112, 114, 117, 126, 135, 141, 144, 148, 159], "curv": [18, 62, 64, 97, 102, 117, 126, 145, 148, 171], "n_estim": [18, 113, 114, 117, 119, 120, 121, 122, 123, 124, 125, 126], "200": [18, 64, 77, 99, 109, 119, 120, 121, 160], "500": [18, 64, 89, 90, 93, 106, 109, 111, 121, 151, 159, 160], "1_000": [18, 29, 99, 117, 126], "decreas": [18, 29, 51, 57, 62, 86, 112, 120, 129, 137, 151, 156, 162], "becom": [18, 97, 100, 102, 107, 112, 120, 121, 156, 185], "reach": [18, 70, 100, 107, 117, 126, 156, 159, 167, 185], "plateau": [18, 100, 117, 126], "experi": [18, 36, 51, 64, 75, 83, 88, 97, 99, 100, 101, 102, 106, 107, 111, 117, 118, 120, 126, 127, 133, 139, 147, 149, 152, 162, 165, 168, 169], "instead": [18, 29, 51, 64, 77, 81, 85, 86, 89, 91, 92, 93, 94, 96, 97, 99, 100, 102, 103, 106, 114, 119, 121, 122, 123, 137, 141, 144, 148, 149, 150, 152, 153, 154, 155, 158, 159, 160, 161, 162, 164, 168, 183], "max_depth": [18, 107, 113, 114, 117, 118, 119, 121, 122, 126, 127, 144, 163, 168, 169, 170, 183], "limit": [18, 29, 32, 34, 43, 60, 62, 65, 84, 90, 106, 107, 114, 137, 144, 147, 151, 160, 164, 166, 170, 171], "gap": [18, 107, 137], "begin": [18, 85, 117, 126, 158], "consid": [18, 45, 64, 73, 77, 89, 105, 107, 108, 111, 112, 113, 119, 120, 121, 123, 137, 141, 144, 149, 152, 163, 169, 178, 191], "none": [18, 51, 97, 99, 102, 106, 108, 109, 110, 111, 114, 117, 121, 122, 126, 136, 142, 146, 159, 191], "rf_1_tree": 18, "cv_results_tre": 18, "train_scor": [18, 29, 100, 102, 107, 137], "return": [18, 28, 29, 70, 81, 84, 85, 89, 91, 93, 112, 114, 119, 132, 133, 134, 135, 137, 138, 139, 140, 141, 145, 148, 149, 152, 156, 157, 159, 160, 185], "arrai": [18, 29, 44, 45, 70, 81, 84, 85, 86, 87, 89, 90, 99, 100, 106, 112, 113, 114, 120, 125, 137, 141, 146, 148, 152, 156, 163], "83120264": 18, "83309064": 18, "83195043": 18, "84834224": 18, "85790323": 18, "86235297": 18, "84791111": 18, "85183089": 18, "82241954": 18, "85045978": 18, "perfect": [18, 43, 60, 96, 106, 112, 119, 128, 130, 131, 147, 148, 151, 167], "r2": [18, 28, 105, 111, 122, 127, 141, 151, 153], "surpris": [18, 88, 99, 104, 105, 128, 131, 144, 163, 169], "memor": [18, 85, 105, 106, 107], "expect": [18, 29, 70, 78, 80, 84, 89, 90, 101, 104, 105, 106, 111, 114, 121, 131, 137, 141, 147, 151, 153, 158, 162, 167], "itself": [18, 86, 99, 101, 102, 106, 110, 114, 158, 188], "automat": [18, 70, 78, 84, 86, 91, 93, 106, 157, 158, 183, 188], "prevent": [18, 89, 93, 114, 121, 185], "max_it": [18, 29, 86, 89, 90, 93, 99, 120, 127], "recal": [18, 27, 64, 89, 101, 106, 120, 122, 137, 148, 157, 158, 160, 162, 191], "averag": [18, 29, 64, 85, 96, 99, 103, 104, 106, 109, 111, 112, 114, 119, 120, 121, 122, 123, 126, 129, 137, 143, 148, 149, 151, 152, 191], "small": [18, 41, 80, 81, 90, 99, 102, 104, 106, 107, 112, 114, 119, 120, 121, 137, 142, 144, 154, 156, 161, 185], "behav": [18, 97, 102, 103, 183], "high": [18, 29, 37, 55, 57, 62, 68, 78, 80, 84, 88, 89, 102, 107, 108, 109, 110, 111, 112, 137, 141, 151, 156, 157, 160], "optimum": 18, "m7": [19, 20, 21, 30, 31, 171], "stratif": [20, 171], "framework": [22, 23, 34, 60, 61, 100, 104, 107, 118, 127, 150, 153, 158, 171, 188], "keep": [22, 29, 78, 95, 99, 106, 108, 109, 111, 112, 121, 129, 130, 131, 136, 142, 146, 147, 158, 160], "mind": [22, 78, 106, 112, 121, 128, 129, 130, 131, 147, 160], "metric": [22, 27, 29, 70, 81, 85, 105, 106, 110, 114, 115, 117, 124, 125, 126, 129, 134, 137, 138, 139, 140, 143, 144, 149, 150, 151, 152, 153, 159, 168, 171, 191], "besid": [22, 23, 33, 40, 84, 90, 92, 94, 96, 99, 100, 118, 127, 129, 137, 142, 163, 176, 189], "insight": [22, 33, 36, 51, 78, 105, 107, 114, 128, 131, 145, 146, 151, 160], "addit": [22, 29, 73, 81, 85, 89, 106, 109, 111, 117, 118, 122, 123, 126, 127, 135, 137, 141, 144, 145, 148, 151, 156, 157, 158, 160, 162, 183], "necess": [22, 106], "appropri": [22, 78], "nest": [22, 23, 26, 121, 137, 154, 156, 158, 161, 171, 183, 189, 191], "wise": [23, 158, 159, 189], "encount": [23, 77, 89, 91, 93, 104], "show": [23, 40, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 95, 100, 101, 104, 106, 107, 108, 111, 113, 114, 119, 121, 122, 123, 130, 132, 134, 137, 138, 139, 140, 143, 144, 145, 147, 148, 149, 152, 156, 157, 158, 159, 160, 162, 163, 165, 168, 169, 170, 176, 185, 188], "comparison": [23, 41, 101, 122, 148], "remov": [24, 35, 51, 78, 112, 120, 131, 156, 159, 191], "dummi": [24, 51, 64, 83, 88, 93, 96, 98, 103, 148, 151], "reli": [24, 78, 84, 86, 112, 113, 130, 148], "ye": [24, 43, 45], "whatev": [24, 159, 163], "chosen": [24, 89, 93, 110, 117, 126, 189], "record": [25, 29, 53, 78, 85, 89, 106, 109, 110, 112], "suspect": 25, "systemat": [25, 55, 62, 102, 157], "bias": 25, "socioeconom": 25, "genet": 25, "most": [25, 29, 51, 78, 84, 85, 88, 89, 93, 94, 97, 98, 99, 102, 103, 106, 108, 112, 113, 114, 120, 129, 143, 148, 149, 152, 156, 159, 163, 169, 178, 180, 183, 185], "adequ": [25, 137, 167], "abil": [25, 107, 148, 154, 161], "stratifi": [25, 98, 103, 104, 191], "leav": [25, 85, 97, 102, 121, 160, 167, 169], "inner": [26, 101, 118, 121, 127, 137, 158, 183], "outer": [26, 101, 118, 126, 127, 137, 158, 183, 191], "balanc": [27, 64, 107, 121, 137, 148, 149, 152, 191], "roc": [27, 148], "auc": [27, 148], "precis": [27, 29, 62, 90, 121, 145, 148, 149, 152, 156], "regular": [27, 37, 40, 41, 46, 47, 51, 112, 114, 135, 136, 141, 142, 146, 160, 168, 171, 189], "assum": [27, 29, 45, 46, 57, 73, 93, 104, 105, 112, 144, 146, 183], "logist": [27, 46, 47, 51, 70, 84, 86, 89, 90, 91, 92, 93, 94, 97, 98, 99, 102, 103, 104, 128, 131, 136, 142, 146, 148, 157, 163], "stronger": [27, 109, 114, 162], "lead": [27, 62, 78, 89, 90, 93, 99, 105, 119, 121, 122, 123, 133, 137, 139, 141, 148, 155, 158, 159, 160, 162], "lower": [27, 29, 51, 57, 93, 99, 100, 103, 106, 109, 112, 121, 126, 137, 148, 151, 158, 162], "r": [28, 102, 105, 106, 111, 112, 150, 151, 153], "absolut": [28, 29, 51, 96, 100, 106, 107, 115, 116, 117, 119, 120, 124, 125, 126, 134, 138, 140, 143, 144, 150, 151, 153], "median": [28, 95, 96, 101, 106, 111, 112, 122, 127, 129, 130, 134, 137, 140, 151, 152, 179, 180], "cross_val_scor": [28, 64, 99, 101, 105, 106, 123, 131, 149, 150, 152, 153, 154, 161], "neg_mean_squared_error": [28, 137], "guarante": [28, 112, 167], "neg": [28, 29, 51, 70, 106, 107, 112, 137, 138, 145, 148], "either": [28, 73, 85, 99, 102, 104, 128, 129, 131, 138, 146, 148], "open": [29, 51, 64, 77, 82, 84, 87, 105, 108, 109, 183], "bike_rid": [29, 109], "command": [29, 51, 64, 77, 183, 191], "cycl": [29, 109], "index_col": [29, 105, 109, 159, 160, 185], "parse_d": [29, 105, 109], "index": [29, 51, 78, 85, 99, 104, 105, 109, 112, 114, 120, 129, 135, 137, 141, 142, 146, 152, 156, 158, 163], "appendix": [29, 96, 97, 100, 102, 106, 107, 113, 115, 116, 117, 120, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 163, 165, 166, 167, 168, 169, 170], "remind": 29, "cheap": [29, 53, 90], "sensor": [29, 78, 109], "gp": [29, 109], "cyclist": [29, 109], "via": [29, 36, 81, 89, 101, 107, 111, 118, 119, 120, 122, 123, 127, 129, 156, 157, 167], "meter": [29, 109], "devic": 29, "expens": [29, 77, 120, 156, 189], "blindli": 29, "introduc": [29, 36, 85, 86, 106, 112, 114, 129, 137, 144, 145, 151, 171], "flavor": 29, "classic": 29, "newton": 29, "second": [29, 37, 86, 92, 94, 98, 103, 104, 109, 113, 119, 120, 141, 147, 160, 167, 169], "p_": 29, "meca": 29, "rho": 29, "sc_x": 29, "v_": 29, "c_r": 29, "mg": 29, "co": 29, "alpha": [29, 46, 47, 51, 78, 99, 102, 111, 112, 113, 114, 119, 125, 133, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 151, 163, 167, 168, 169, 170], "sin": 29, "ma": 29, "v_d": 29, "air": 29, "densiti": 29, "kg": [29, 164], "m": [29, 89, 99], "frontal": 29, "c_x": 29, "drag": 29, "coeffici": [29, 37, 41, 45, 51, 111, 134, 135, 137, 140, 141, 142, 144, 145, 146, 151, 178], "v_a": 29, "roll": 29, "rider": 29, "bicycl": 29, "standard": [29, 51, 78, 81, 86, 90, 91, 93, 98, 99, 101, 103, 106, 107, 112, 118, 127, 137, 147, 148, 158], "due": [29, 88, 90, 104, 119, 123, 163], "graviti": 29, "81": [29, 77, 83, 88, 120, 160], "radian": 29, "equat": [29, 143, 146], "complex": [29, 51, 65, 84, 90, 91, 93, 95, 100, 108, 119, 149, 152, 167, 168], "term": [29, 78, 85, 86, 105, 106, 114, 116, 119, 120, 123, 125, 129, 145, 168], "within": [29, 34, 81, 99, 101, 104, 106, 111, 112, 114, 118, 120, 127, 129, 137, 150, 153, 158, 159, 163, 170], "parenthesi": 29, "produc": 29, "fight": [29, 40], "wind": 29, "resist": 29, "tire": 29, "floor": 29, "third": [29, 119], "hill": 29, "forward": [29, 109], "fourth": 29, "last": [29, 36, 51, 73, 104, 108, 110, 137, 144, 148, 149, 152], "hi": [29, 110, 160], "simplifi": [29, 51, 105, 106, 129, 146, 162, 164, 183], "beta_": 29, "closer": [29, 104, 109, 137, 146], "previous": [29, 77, 89, 90, 97, 102, 105, 108, 113, 119, 120, 121, 122, 141, 144, 146, 154, 156, 158, 160, 161, 167, 168], "part": [29, 78, 89, 90, 101, 107, 112, 120, 131, 132, 138, 148, 165, 169], "cube": 29, "multipli": [29, 153], "sine": 29, "angl": 29, "arc": 29, "tangent": 29, "np": [29, 51, 96, 97, 99, 100, 102, 103, 104, 109, 111, 112, 113, 114, 119, 120, 123, 125, 128, 129, 131, 132, 133, 137, 138, 139, 141, 143, 144, 145, 147, 148, 150, 151, 153, 155, 159, 162, 167, 168, 170, 180, 185], "arctan": 29, "ourself": [29, 148], "clip": 29, "brake": 29, "preprocess": [29, 36, 51, 64, 69, 70, 77, 78, 81, 89, 90, 91, 92, 93, 94, 95, 97, 99, 102, 103, 104, 111, 112, 114, 120, 123, 136, 137, 141, 142, 144, 146, 147, 151, 154, 156, 157, 158, 160, 161, 162, 171, 183, 185, 187, 191], "linear_model": [29, 46, 51, 77, 81, 84, 86, 89, 90, 91, 93, 95, 99, 103, 104, 111, 112, 114, 131, 133, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 151, 153, 157, 163, 168, 170, 183, 185, 187], "ridgecv": [29, 51, 111, 112, 137, 141], "shufflesplit": [29, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 137], "n_split": [29, 96, 100, 101, 103, 104, 105, 106, 107, 112, 127, 137, 152, 158], "mae": [29, 126, 134, 138, 140, 153], "return_estim": [29, 51, 106, 111, 112, 118, 122, 127, 129, 137, 140, 158, 191], "subsequ": [29, 75, 99, 118, 121, 127, 128, 131, 137, 188], "Be": [29, 78, 89, 90, 91, 93, 107, 121, 134, 140, 147, 156, 157, 183], "awar": [29, 33, 34, 78, 85, 89, 90, 91, 93, 95, 107, 108, 121, 147, 156, 157, 183], "investig": [29, 86, 105, 112, 115, 118, 122, 124, 127, 129, 163], "consequ": [29, 104, 114, 120, 123], "003": [29, 81, 90, 92, 94, 157, 158], "obtain": [29, 51, 64, 77, 81, 85, 89, 90, 91, 93, 95, 99, 101, 103, 105, 106, 109, 111, 112, 115, 121, 122, 124, 131, 137, 143, 147, 148, 151, 158, 159, 160, 161, 163, 185], "closest": [29, 85], "watt": [29, 109], "70": [29, 78, 95, 108], "90": [29, 78, 84, 86, 96, 99, 104, 121, 138], "neg_mean_absolute_error": [29, 96, 100, 106, 107, 119, 120, 121, 124, 126, 140, 153], "request": [29, 89, 120, 137], "h": [29, 112], "beta": 29, "cadenc": [29, 109], "turn": [29, 109, 134, 140], "pedal": [29, 109], "rotat": [29, 78, 99, 109], "per": [29, 51, 78, 81, 83, 84, 85, 86, 88, 89, 90, 101, 106, 109, 111, 120, 123, 144, 148, 156, 157, 158, 160], "minut": [29, 33, 90, 109, 160], "beat": [29, 109], "1000": [29, 51, 90, 109, 121, 126, 127, 148, 150, 151, 153, 162], "activ": [29, 73, 159, 185], "early_stop": [29, 121, 127], "80": [29, 77, 95, 96, 108, 154, 161], "consider": [29, 121, 145], "test_scor": [29, 81, 89, 90, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 111, 119, 120, 122, 127, 129, 130, 131, 137, 140, 157, 158, 161, 163, 169], "dictionari": [29, 70, 81, 106], "made": [29, 35, 44, 78, 97, 99, 102, 105, 106, 110, 119, 148, 157], "ignor": [29, 77, 89, 90, 92, 93, 94, 95, 96, 112, 162], "datafram": [29, 51, 64, 77, 78, 79, 80, 84, 85, 86, 89, 90, 95, 96, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 119, 121, 122, 124, 125, 127, 129, 130, 133, 137, 139, 140, 141, 144, 145, 147, 148, 151, 152, 153, 156, 158, 159, 160, 162, 163, 167, 168, 170, 183, 191], "account": [29, 85, 96, 99, 108, 112, 148, 183], "date": [29, 90, 99, 108, 109], "hesit": 29, "uniqu": [29, 64, 84, 89, 99, 104, 114, 120, 156, 160], "dai": 29, "datetimeindex": [29, 109], "went": 29, "df": [29, 77, 134, 140, 159], "capac": [29, 100], "leaveonegroupout": [29, 105], "numpi": [29, 36, 68, 70, 75, 86, 89, 96, 99, 100, 102, 103, 104, 109, 111, 112, 113, 114, 119, 120, 125, 128, 129, 131, 132, 133, 137, 138, 139, 141, 143, 144, 145, 147, 148, 150, 151, 153, 159, 162, 167, 168, 170, 185], "had": [29, 106, 112, 144, 146], "indic": [29, 78, 90, 99, 106, 109, 111, 112, 114, 129, 132, 137, 138, 162, 163], "differenti": [29, 75, 78, 158, 164], "factor": [29, 96], "integ": [29, 51, 73, 81, 84, 89, 91, 93, 99, 108, 110, 112, 114, 160, 162, 191], "align": [29, 110, 144, 160], "pessimist": 29, "optimist": [29, 85, 99, 101, 106], "deviat": [29, 51, 81, 86, 99, 101, 106, 107, 112, 118, 127, 137, 158], "analys": [29, 84, 112], "reus": [29, 132, 138, 144, 149, 152, 158], "train_indic": 29, "test_indic": 29, "list": [29, 36, 64, 89, 92, 94, 104, 112, 114, 115, 117, 124, 126, 149, 150, 152, 153, 157, 191], "data_linear_model_train": 29, "data_linear_model": 29, "iloc": [29, 87, 104, 109, 111, 112, 113, 114, 119, 156, 167], "data_linear_model_test": 29, "data_train": [29, 84, 86, 90, 105, 106, 114, 115, 116, 117, 119, 121, 124, 125, 126, 131, 136, 142, 146, 148, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 166, 168, 169, 170], "data_test": [29, 84, 85, 86, 87, 90, 105, 106, 114, 115, 116, 117, 119, 121, 124, 125, 126, 131, 136, 142, 146, 148, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 167, 168, 169, 170], "target_train": [29, 84, 86, 88, 90, 104, 105, 106, 114, 115, 116, 117, 119, 121, 124, 125, 126, 131, 136, 142, 146, 148, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 166, 168, 169, 170], "target_test": [29, 84, 85, 86, 87, 88, 90, 104, 105, 106, 115, 116, 117, 121, 124, 125, 126, 131, 136, 142, 146, 148, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 169], "scatter": [29, 80, 111, 114, 116, 119, 125, 147, 164, 166, 168, 170], "catastroph": [29, 86], "portion": 29, "time_slic": 29, "slice": 29, "2020": [29, 109], "08": [29, 109, 137], "18": [29, 36, 78, 80, 84, 96, 108, 109, 121, 124, 144, 156, 157, 159, 160, 162, 164], "17": [29, 78, 80, 84, 86, 96, 106, 108, 120, 121, 124, 137, 159, 162, 163, 164], "00": [29, 86, 106, 109, 121, 138, 143, 156], "data_test_linear_model_subset": 29, "data_test_subset": [29, 131], "target_test_subset": 29, "pm": 29, "until": [29, 121, 148], "accur": [29, 113, 137, 148], "motiv": [33, 122], "known": [33, 78, 110, 111, 137, 138, 146, 148, 151, 156, 163], "caveat": [33, 128, 131, 158, 171], "practic": [33, 62, 78, 81, 84, 85, 88, 95, 101, 103, 104, 106, 121, 123, 137, 141, 147, 148, 149, 152, 158, 159, 160], "magic": [34, 105], "tool": [34, 36, 81, 90, 114, 146, 158, 160], "margin": [34, 99, 112], "gain": [34, 36, 51, 78, 81, 83, 84, 85, 86, 88, 89, 90, 100, 115, 124, 128, 129, 131, 146, 156, 157, 160], "tackl": [34, 51, 62, 130], "selector": [34, 89, 90, 91, 92, 93, 94, 128, 131, 154, 156, 158, 160, 161], "recurs": 34, "main": [35, 51, 81, 86, 92, 94, 121, 129, 162, 171], "advantag": [35, 81, 129, 135, 137, 141], "fine": [35, 41, 90, 94, 158, 162, 188], "noisi": [35, 65, 107, 112, 114, 135, 141, 147, 162, 167], "teach": [36, 54], "beginn": 36, "strong": [36, 112, 141, 142, 162], "background": 36, "bring": 36, "vast": 36, "busi": 36, "intellig": 36, "industri": 36, "scientif": [36, 123], "discoveri": 36, "pillar": 36, "modern": 36, "field": [36, 78, 191], "central": 36, "easili": [36, 78, 85, 86, 89, 167], "yet": [36, 77, 90, 92, 94, 144], "dovetail": 36, "ecosystem": 36, "languag": 36, "step": [36, 51, 64, 78, 84, 85, 86, 90, 95, 121, 123, 129, 130, 137, 144, 147, 150, 153, 156, 157, 158, 160, 191], "lesson": [36, 157], "fundament": [36, 60, 102, 151], "stone": 36, "artifici": 36, "mine": 36, "cookbook": 36, "failur": [36, 60], "session": [36, 158, 160], "octob": 36, "2022": 36, "month": [36, 110, 148], "enrol": 36, "quizz": 36, "execut": [36, 134, 140, 154, 160, 161, 185], "platform": 36, "purpos": [36, 89, 90, 101, 103, 105, 106, 116, 125, 128, 129, 131, 137, 148, 157, 183], "educ": [36, 51, 78, 84, 89, 90, 91, 92, 93, 94, 123, 146, 154, 156, 158, 160, 161], "write": [36, 79, 82, 83, 91, 92, 94, 97, 98, 99, 115, 116, 117, 118, 128, 132, 133, 134, 135, 136, 149, 150, 154, 155, 161, 165, 166], "prior": [36, 75], "matplotlib": [36, 75, 78, 86, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 125, 126, 127, 129, 130, 137, 138, 140, 142, 143, 145, 146, 147, 148, 151, 152, 163, 167, 168, 169, 170], "librari": [36, 75, 78, 162], "quick": [36, 75, 78, 108, 111, 120, 164], "publicli": 36, "cite": 36, "project": [36, 159], "zenodo": 36, "archiv": [36, 95, 99], "doi": 36, "5281": 36, "7220306": 36, "repositori": [36, 106, 111], "inria": 36, "publish": [36, 106, 111], "static": 36, "rocket": 36, "top": [36, 78, 148, 159, 160, 166, 167, 170], "interact": [36, 78, 109, 137, 144, 159, 160, 162, 185], "cell": [36, 78, 82, 84, 86, 87, 90, 95, 101, 106, 113, 119, 120, 137, 139, 143, 144, 147, 148, 156, 158, 160, 163, 169, 170], "binder": 36, "servic": [36, 90], "video": [36, 95, 178], "youtub": 36, "playlist": 36, "channel": 36, "www": [36, 78, 85, 106, 111], "pl2oka_2qdj": 36, "m44koooi7x8tu85wr4ez4f": 36, "version": [36, 86, 108, 120, 122, 160], "host": [36, 160], "fun": 36, "infer": [37, 109, 129, 133, 139, 141, 145, 188], "importance_permut": 37, "correl": [37, 51, 78, 110, 112, 123, 129, 135, 144], "divid": [37, 86, 96, 99, 107, 138, 141, 148, 158, 160], "receiv": [37, 148], "cardin": [37, 89, 112], "independ": [37, 89, 99, 101, 105, 114, 120, 148, 151, 157, 160], "could": [37, 64, 77, 78, 84, 85, 86, 88, 89, 90, 96, 97, 99, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 120, 122, 123, 127, 129, 131, 132, 133, 134, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 149, 152, 157, 158, 159, 162, 167], "m4": [38, 39, 42, 48, 49, 171], "beyond": [38, 78, 144, 171], "parametr": [40, 132, 138, 143, 144, 145, 160, 163, 168, 170, 177], "implic": 40, "dimension": [40, 70, 75, 78, 99, 128, 131, 146, 156, 159, 163], "effect": [40, 46, 51, 63, 64, 86, 97, 101, 102, 111, 112, 114, 121, 122, 123, 135, 136, 141, 142, 168, 171], "relationship": [40, 78, 84, 89, 90, 105, 112, 114, 135, 141, 145, 148, 156, 158, 160, 164, 171], "adjust": [41, 62, 156, 159], "successfulli": [41, 103, 119], "scale": [41, 46, 51, 64, 76, 77, 86, 89, 90, 97, 99, 102, 106, 114, 120, 151, 156, 157, 160, 162, 183, 189, 191], "approxim": [41, 64, 81, 85, 86, 94, 96, 99, 103, 114, 126, 162, 191], "dynam": 41, "linearli": [41, 43, 46, 84, 137, 147], "extra": [41, 109, 149, 152, 158], "Is": [43, 45, 83, 88, 108], "linearregress": [44, 46, 133, 135, 137, 139, 140, 141, 143, 144, 151, 153, 168, 170, 183], "coef_": [44, 45, 51, 111, 112, 130, 137, 140, 141, 142, 143, 144, 146, 157, 188], "intercept_": [44, 45, 143, 144], "extract": [45, 81, 99, 109, 112, 114, 156, 160, 191], "straight": [45, 90, 144, 146, 147, 168], "float": [45, 51, 109, 111, 120, 160], "robust": [46, 94, 106, 112, 122], "outlier": [46, 96, 111, 167], "wide": [46, 84], "forc": [46, 86, 92, 94, 113, 120, 123, 137, 143], "penal": 46, "scientist": [46, 101], "prepar": 46, "plan": 46, "strength": [46, 51, 136, 137, 142, 160], "penalti": [47, 51, 112, 136, 141, 142, 146], "magnitud": [47, 51, 112, 136, 137, 141, 142, 178], "l2": [47, 136, 141, 142], "l1": [47, 112], "boundari": [47, 136, 142, 146, 147, 163, 165, 167, 168, 169], "ames_housing_no_miss": [51, 77, 108, 183], "ames_h": [51, 77, 95, 108, 141, 150, 151, 153, 183], "salepric": [51, 77, 95, 108, 141, 150, 151, 153, 183], "numerical_featur": [51, 77, 108, 183], "lotfrontag": [51, 77, 95, 108, 183], "lotarea": [51, 77, 95, 108, 183], "masvnrarea": [51, 77, 108, 183], "bsmtfinsf1": [51, 77, 108, 183], "bsmtfinsf2": [51, 77, 108, 183], "bsmtunfsf": [51, 77, 108, 183], "totalbsmtsf": [51, 77, 108, 183], "1stflrsf": [51, 77, 108, 183], "2ndflrsf": [51, 77, 108, 183], "lowqualfinsf": [51, 77, 108, 183], "grlivarea": [51, 77, 108, 183], "bedroomabvgr": [51, 77, 108, 183], "kitchenabvgr": [51, 77, 108, 183], "totrmsabvgrd": [51, 77, 108, 183], "fireplac": [51, 77, 108, 183], "garagecar": [51, 77, 108, 183], "garagearea": [51, 77, 108, 183], "wooddecksf": [51, 77, 108, 183], "openporchsf": [51, 77, 108, 183], "enclosedporch": [51, 77, 108, 183], "3ssnporch": [51, 77, 108, 183], "screenporch": [51, 77, 95, 108, 183], "poolarea": [51, 77, 95, 108, 183], "miscval": [51, 77, 95, 108, 183], "data_numer": [51, 81, 83, 84, 86, 88, 183], "argument": [51, 64, 82, 86, 87, 89, 91, 93, 109, 191], "largest": [51, 111], "1e0": 51, "000": [51, 53, 77, 93, 96, 104, 106, 111, 119, 120, 128, 131, 135, 141, 146, 151, 161, 162], "1e5": 51, "larger": [51, 86, 89, 107, 121, 126, 144, 145, 154, 155, 158, 161, 162, 180], "express": [51, 65, 77, 94, 97, 102, 106, 111, 112, 119, 134, 140, 144, 147, 159, 162, 167, 185], "notat": 51, "box": [51, 101, 111, 118, 127, 129, 130, 134, 137, 140, 149, 152, 191], "garag": 51, "just": [51, 93, 105, 106, 107, 109, 112, 113, 114, 117, 121, 123, 126, 137, 144, 148], "logspac": [51, 97, 102, 111, 137, 155, 162], "num": [51, 78, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 102, 103, 111, 114, 119, 123, 125, 132, 137, 138, 143, 145, 154, 155, 156, 158, 160, 161, 162], "101": [51, 191], "rememb": [51, 78, 114, 191], "alpha_": [51, 137], "fall": [51, 106, 160], "snippet": [51, 114, 185], "adult_censu": [51, 68, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 98, 103, 123, 154, 156, 157, 158, 159, 160, 161], "select_dtyp": [51, 77, 108, 150, 151, 153], "dummyclassifi": [51, 64, 83, 88, 93, 98, 103, 148], "frequent": [51, 88, 93, 98, 103, 108, 160, 180], "loss": [51, 78, 81, 83, 84, 85, 86, 88, 89, 90, 151, 156, 157, 160], "week": [51, 78, 81, 83, 84, 85, 86, 88, 89, 90, 156, 157, 160], "hot": [51, 73, 89, 90], "preprocessor": [51, 90, 91, 92, 93, 94, 95, 99, 108, 123, 154, 156, 157, 158, 160, 161, 183, 191], "named_transformers_": 51, "onehotencod": [51, 76, 77, 89, 90, 91, 92, 93, 94, 95, 137, 141], "get_feature_names_out": [51, 89, 137, 141], "categorical_column": [51, 78, 89, 90, 91, 92, 93, 94, 141, 156, 158, 160], "tolist": [51, 108], "numerical_column": [51, 78, 81, 83, 84, 86, 88, 90, 92, 94, 157], "There": [51, 80, 86, 106, 110], "pair": [51, 86, 109, 110, 111, 132, 138, 159], "rel": [51, 93, 98, 103, 106, 122, 130, 144, 148, 151], "country_columbia": 51, "workclass_": [51, 89], "native_country_": 51, "education_doctor": 51, "varianc": [51, 55, 60, 62, 99, 107, 112, 151, 171], "influenc": [51, 100, 107, 112, 151, 160, 176], "studi": [53, 64, 78, 97, 99, 102, 106, 135, 137, 141, 147, 191], "apart": [53, 112], "estat": [53, 106], "thousand": [53, 106, 111, 112, 134, 140], "entertain": 53, "spaciou": 53, "updat": [53, 95, 191], "bedroom": [53, 106, 111, 112], "bathroom": 53, "lakeview": 53, "97630": 53, "1st": [53, 78, 89], "nightlif": 53, "privat": [53, 78, 84, 89, 90, 156, 160], "backyard": 53, "buyer": 53, "market": 53, "kind": [53, 78, 90, 94, 112, 126, 141, 144, 178, 191], "sub": [54, 101, 102, 163], "vocabulari": 54, "low": [57, 68, 78, 80, 84, 88, 99, 109, 111, 112, 114, 121, 148, 163, 167, 185], "littl": [57, 84, 99, 104, 159], "reduct": [57, 112], "steadi": 57, "label": [57, 62, 73, 80, 84, 89, 90, 93, 100, 102, 103, 104, 105, 107, 113, 114, 119, 125, 126, 138, 145, 146, 148, 149, 151, 152, 168, 170], "slow": [57, 94, 121], "tradeoff": [57, 62, 107], "m2": [59, 61, 63, 171], "trade": [60, 62, 81, 167, 171, 176, 178], "off": [60, 62, 78, 81, 96, 108, 148, 167, 171, 176, 178], "character": [60, 112, 148], "why": [60, 64, 70, 78, 90, 98, 103, 109, 112, 142, 153, 185], "aris": [60, 78, 137, 141, 151], "Then": [60, 75, 81, 86, 90, 96, 106, 114, 118, 122, 127, 128, 129, 130, 131, 144, 149, 150, 151, 152, 153, 158, 160, 163], "quantifi": [60, 78, 107, 112, 132, 138, 191], "contrast": [60, 78, 89, 106, 119, 145, 168], "importantli": 60, "emphas": [60, 122, 144], "happen": [62, 70, 78, 89, 91, 93, 123, 136, 142, 163], "suffer": [62, 86, 110, 141], "lack": 62, "captur": [62, 78, 107, 112], "neither": [62, 104], "nor": 62, "still": [62, 81, 86, 89, 90, 94, 107, 111, 112, 113, 115, 124, 144, 151, 159, 160, 167], "variat": [62, 81, 106, 107, 112, 114, 137], "fulli": [62, 89, 106, 117, 121, 126], "determin": [62, 97, 102, 148, 151], "irreduc": 62, "decompos": 62, "chapter": [62, 191], "diagnos": 62, "blood_transfus": [64, 97, 102, 110, 148, 149, 152], "propos": [64, 191], "multiclass": [64, 191], "proport": [64, 100, 103, 110, 148, 151, 191], "imbalanc": [64, 78, 103, 137, 148, 191], "twice": [64, 135, 141, 148, 191], "value_count": [64, 78, 79, 80, 88, 89, 104, 108, 110, 148, 191], "most_frequ": [64, 88, 93, 103, 108, 148], "balanced_accuraci": [64, 148, 149, 152, 191], "remaind": [64, 89, 90, 92, 94, 123, 154, 156, 158, 160, 161], "add": [64, 107, 109, 112, 119, 120, 129, 134, 137, 140, 145, 148, 149, 152, 166, 170], "faster": [64, 70, 78, 86, 121, 154, 161], "distanc": [64, 86, 162], "normal": [64, 86, 95, 99, 108, 109, 110, 111, 112, 120, 133, 139, 148, 151, 155, 156, 162], "irrelev": 64, "make_pipelin": [64, 70, 81, 86, 89, 90, 91, 92, 93, 94, 99, 102, 103, 104, 108, 111, 112, 114, 120, 123, 129, 130, 131, 136, 137, 141, 142, 144, 146, 147, 162], "get_param": [64, 97, 102, 115, 124, 157, 187, 191], "n_neighbor": [64, 82, 87, 155, 162, 188, 191], "clearli": [64, 88, 100, 102], "param_rang": [64, 102, 107, 117, 126], "affirm": 64, "highli": [65, 78], "much": [65, 78, 93, 94, 96, 103, 106, 107, 112, 120, 121, 123, 124, 129, 137, 185], "m1": [67, 69, 72, 171], "comma": [68, 78, 108, 109, 110], "file": [68, 78, 84, 85, 108, 109, 110, 149, 152, 191], "alreadi": [68, 78, 84, 85, 86, 112, 121, 123, 134, 137, 140, 155, 160, 162], "packag": [68, 120, 137, 149, 152], "survei": 68, "incom": [68, 78, 84, 88, 96, 106, 111, 112], "manipul": [68, 78, 82, 87, 97, 102, 106], "seaborn": [68, 78, 79, 80, 86, 109, 110, 111, 112, 113, 114, 119, 125, 133, 138, 139, 142, 143, 144, 145, 146, 147, 151, 156, 159, 163, 164, 167, 168, 169, 170], "visual": [68, 72, 86, 89, 100, 105, 106, 109, 114, 119, 132, 138, 146, 148, 151, 156, 159, 164, 168, 171, 188], "scipi": [68, 121, 124, 160], "organ": [68, 169], "five": [70, 85, 90, 106], "overlap": [70, 80, 81, 114, 160], "lie": [70, 151], "fewer": 70, "elimin": 70, "wrong": [70, 103, 128, 131, 159], "jupyt": [72, 84, 86, 87, 90, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170, 171], "categori": [73, 77, 78, 84, 90, 91, 93, 108, 110, 123, 137, 141, 156, 164], "ordin": [73, 77, 90, 93, 120], "string": [73, 84, 89, 90, 91, 93, 106, 108, 149, 152, 153, 158, 191], "meaning": [73, 89, 94, 128, 130, 131, 145, 151, 156], "represent": [73, 84, 86, 87, 89, 90, 92, 94, 95, 100, 101, 106, 110, 111, 113, 120, 123, 139, 143, 147, 148, 156, 158, 160, 163, 167, 169, 170], "compani": [73, 105], "sector": 73, "construct": [73, 114, 123, 160], "retail": 73, "energi": [73, 105, 109], "insur": 73, "phone": 73, "sale": [73, 77, 90], "depart": 73, "employe": 73, "profit": 73, "quarter": [73, 105], "head": [73, 77, 78, 80, 84, 85, 89, 90, 106, 108, 109, 110, 111, 112, 134, 137, 140, 145, 156, 157, 160, 164], "tabl": [75, 78, 123, 156], "progress": [75, 155, 162], "attent": [75, 113], "extend": [75, 84], "mix": [75, 76, 78, 90, 99, 167], "unknown": [75, 89, 91, 93, 123], "notabl": [76, 148], "ordinalencod": [76, 89, 90, 91, 92, 93, 94, 123, 154, 156, 158, 160, 161, 183], "200_000": [77, 95], "astyp": [77, 95, 108, 155, 160, 162, 167], "int": [77, 81, 95, 113, 160], "did": [77, 78, 86, 89, 98, 103, 105, 106, 108, 109, 121, 129, 131, 137, 146, 148, 149, 152, 156, 157, 158, 160, 162, 165, 169, 188], "convert": [77, 100, 106, 113, 114, 125, 162], "info": [77, 99, 108, 109, 110, 111], "examin": 77, "79": [77, 108, 160], "36": [77, 80, 106, 108, 121, 124, 164, 168], "make_column_selector": [77, 89, 90, 91, 92, 93, 94, 123, 154, 156, 158, 160, 161], "shown": [77, 78, 106, 119, 134, 140, 158, 165, 169, 185], "among": [77, 89, 90, 104, 129, 162], "quantit": [77, 84, 119, 132, 138, 143], "exclud": [77, 78, 129], "overallqu": [77, 108], "overallcond": [77, 108], "yearbuilt": [77, 108], "sole": [77, 131, 151], "treat": [77, 90, 95], "issu": [77, 78, 89, 90, 104, 105, 106, 109, 110, 120, 137, 141, 144, 151], "rare": [77, 78, 89, 90, 108, 123, 137], "handle_unknown": [77, 89, 90, 91, 92, 93, 94, 95, 123, 154, 156, 158, 160, 161], "latter": [77, 78, 86, 89, 101, 129, 148], "place": [78, 131, 137], "workflow": 78, "1994": [78, 99], "download": [78, 106, 111], "openml": [78, 85], "webpag": 78, "1590": [78, 85], "tutori": 78, "50k": [78, 83, 84, 85, 86, 87, 88, 90, 156, 160], "year": [78, 84, 108, 133, 137, 139, 156], "heterogen": [78, 84, 90, 108], "employ": 78, "covari": 78, "workclass": [78, 84, 89, 90, 156, 158, 160], "marit": [78, 84, 89, 90, 156, 158, 160], "occup": [78, 84, 89, 90, 111, 112, 156, 158, 160], "race": [78, 84, 89, 90, 109, 156, 158, 160], "sex": [78, 84, 89, 90, 156, 158, 160], "countri": [78, 84, 89, 90, 156, 158, 160], "11th": [78, 84, 89, 156, 160], "marri": [78, 84, 89, 90, 156, 160], "op": [78, 84, 89, 156, 160], "inspct": [78, 84, 89, 156, 160], "own": [78, 84, 89, 90, 121, 143, 156, 160], "child": [78, 84, 89, 90, 156, 160], "male": [78, 84, 89, 90, 156, 160], "lt": [78, 84, 85, 160], "hs": [78, 84, 89, 90, 156, 160], "grad": [78, 84, 89, 90, 156, 160], "civ": [78, 84, 89, 90, 156, 160], "spous": [78, 84, 89, 90, 156, 160], "farm": [78, 84, 89, 156, 160], "fish": [78, 84, 89, 156, 160], "husband": [78, 84, 89, 90, 156, 160], "white": [78, 84, 89, 90, 156, 160], "local": [78, 84, 89, 95, 110, 144, 156, 160], "gov": [78, 84, 89, 156, 160], "assoc": [78, 84, 89, 156, 160], "acdm": [78, 84, 89, 156, 160], "protect": [78, 84, 89, 156, 160], "serv": [78, 84, 89, 92, 94, 109, 148, 156, 160], "gt": [78, 84, 160], "colleg": [78, 84, 89, 156, 160], "7688": [78, 84, 156, 157, 160], "femal": [78, 84, 89, 90, 156, 160], "revenu": [78, 88, 89, 137], "target_column": [78, 113, 136, 142, 146, 163, 164, 165, 169], "37155": [78, 88], "11687": [78, 88], "dtype": [78, 80, 84, 85, 86, 87, 88, 89, 90, 91, 93, 96, 103, 106, 108, 109, 110, 111, 113, 135, 137, 141, 148, 156, 160, 162, 163], "int64": [78, 80, 84, 88, 89, 108, 110, 162], "imbal": [78, 110], "special": [78, 109], "healthi": 78, "ill": [78, 137, 141], "all_column": 78, "print": [78, 81, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 99, 101, 102, 104, 105, 106, 111, 112, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 131, 132, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 151, 152, 153, 155, 156, 157, 158, 160, 161, 162, 163, 169], "48842": [78, 84, 89, 156, 160], "14": [78, 96, 99, 108, 109, 120, 121, 124, 141, 148, 151, 162], "subtract": [78, 86], "mayb": [78, 99, 107, 111], "peculiar": [78, 108], "malfunct": 78, "afterward": [78, 85, 112], "cap": [78, 101, 111, 127, 129, 130, 137, 140, 152], "hist": [78, 80, 96, 99, 103, 106, 107, 108, 109, 110, 111, 146], "figsiz": [78, 80, 108, 109, 110, 111, 112, 126, 137, 163, 167, 168, 169], "func": [78, 106, 111], "assign": [78, 86, 103, 108, 113, 119, 144, 150, 153], "underscor": [78, 86, 157], "garbag": 78, "comment": 78, "retir": 78, "filter": [78, 89, 109, 156], "peak": 78, "ll": 78, "32650": 78, "16192": 78, "disproport": 78, "fair": [78, 101, 122], "deploi": [78, 90, 106, 158, 168], "mitig": [78, 121], "deploy": [78, 158], "compon": [78, 144, 187], "unexpect": [78, 104], "gender": 78, "15784": 78, "10878": 78, "bachelor": [78, 89, 90], "8025": 78, "master": [78, 89], "2657": 78, "voc": [78, 89], "2061": 78, "1812": 78, "1601": 78, "10th": [78, 89], "1389": 78, "7th": [78, 89], "8th": [78, 89], "955": 78, "prof": [78, 89, 90], "school": [78, 89, 99], "834": 78, "9th": [78, 89], "756": 78, "12th": [78, 89], "657": 78, "doctor": [78, 89], "594": 78, "5th": [78, 89], "6th": [78, 89], "509": 78, "4th": [78, 89], "247": 78, "preschool": [78, 89], "crosstab": 78, "entri": [78, 81, 106, 108, 109, 110, 111, 118, 127, 132, 138], "lose": 78, "redund": [78, 106, 129, 141], "upcom": [78, 148, 157], "pairplot": [78, 79, 80, 109, 110, 111, 112, 164], "diagon": [78, 110, 148, 151, 156, 164], "reveal": [78, 106], "sn": [78, 86, 109, 110, 111, 112, 113, 114, 119, 125, 133, 138, 139, 142, 143, 144, 145, 146, 147, 151, 156, 159, 163, 164, 167, 168, 169, 170], "readabl": [78, 156, 159, 185], "n_samples_to_plot": 78, "5000": [78, 110, 129, 130, 138, 145], "var": 78, "hue": [78, 80, 109, 110, 111, 113, 142, 146, 147, 159, 163, 164, 167, 169], "plot_kw": [78, 112], "height": [78, 80], "diag_kind": [78, 112], "diag_kw": 78, "written": [78, 99, 111], "scatterplot": [78, 86, 111, 113, 114, 119, 125, 133, 138, 139, 142, 143, 144, 145, 146, 147, 151, 159, 163, 164, 167, 168, 169, 170], "region": [78, 106, 107, 156, 160], "pyplot": [78, 86, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 125, 126, 127, 129, 130, 137, 138, 140, 142, 143, 146, 147, 148, 151, 152, 163, 167, 168, 169, 170], "plt": [78, 86, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 119, 125, 126, 127, 129, 130, 137, 138, 140, 142, 143, 146, 147, 148, 151, 152, 163, 167, 168, 169, 170], "ax": [78, 86, 108, 109, 112, 113, 123, 126, 138, 139, 144, 145, 147, 148, 156, 159, 163, 167, 168, 169], "age_limit": 78, "axvlin": [78, 111, 112], "ymin": [78, 111], "ymax": [78, 111], "linestyl": [78, 111, 114, 125, 148, 168], "hours_per_week_limit": 78, "axhlin": 78, "xmin": 78, "xmax": 78, "annot": [78, 156], "fontsiz": 78, "AND": 78, "seem": [78, 81, 84, 87, 88, 92, 94, 102, 105, 111, 112, 121, 123, 126, 138, 157, 163], "complic": [78, 111, 129], "similarli": [78, 97, 98, 100, 102, 103, 105, 116, 123, 125, 137, 141, 148, 160, 170], "somewhat": [78, 114], "arbitrari": [78, 89, 90, 91, 93, 94, 95, 112], "straightforward": [78, 114], "obviou": [78, 99, 109, 147], "highlight": [78, 85, 99, 101, 105, 113, 119, 128, 129, 131, 137, 141, 144, 148, 156, 158, 163, 168], "imagin": [79, 80, 112, 147], "feel": [79, 80, 118, 121, 127, 191], "penguins_classif": [79, 80, 113, 136, 142, 146, 163, 164, 165, 167, 169], "adeli": [80, 136, 142, 146, 163, 164, 169], "151": [80, 89, 137, 159], "gentoo": [80, 163, 164, 169], "123": [80, 137], "chinstrap": [80, 136, 142, 146, 163, 164], "pairplot_figur": [80, 164], "prioriti": 80, "tweak": 80, "subfigur": 80, "perfectli": [80, 94, 110, 119, 121, 135, 141, 144, 167], "downsid": 81, "amount": [81, 99, 106, 110, 123, 137], "smaller": [81, 106, 120, 121, 126, 153, 180], "repetit": [81, 99, 141, 156], "aggreg": [81, 111, 118, 127, 137, 148], "partit": [81, 149, 152, 163, 165, 167, 168, 169], "clone": [81, 114], "earlier": [81, 90, 111, 122, 141, 148, 163], "computation": [81, 120, 144, 156, 185], "intens": [81, 103, 185], "cv_result": [81, 89, 90, 92, 93, 94, 95, 102, 106, 107, 111, 121, 122, 124, 129, 130, 137, 140, 153, 156, 157, 158, 159, 160, 162, 185], "cpu": [81, 90, 107, 119, 122, 156, 160], "901": [81, 108], "ms": [81, 90, 107, 122, 156, 160], "sy": [81, 90, 107, 122, 156, 160], "212": [81, 137], "total": [81, 90, 99, 105, 106, 107, 108, 109, 110, 111, 112, 122, 148, 156, 160, 162], "wall": [81, 90, 107, 122, 156, 160], "626": 81, "fit_tim": [81, 89, 90, 102, 106, 119, 120, 129, 152, 158], "0960834": 81, "0877049": 81, "08731437": 81, "09305048": 81, "08830786": 81, "score_tim": [81, 89, 90, 102, 106, 119, 120, 129, 152, 158], "01920891": 81, "0191915": 81, "01904273": 81, "02260065": 81, "01912594": 81, "79557785": 81, "80049135": 81, "79965192": 81, "79873055": 81, "80436118": 81, "iii": 81, "distinct": [81, 84, 101, 104], "match": [81, 82, 87, 101, 144], "stabil": [81, 112], "discard": [81, 106, 111, 113, 163], "round": [81, 98, 103, 113], "themselv": 81, "3f": [81, 84, 85, 86, 88, 89, 90, 92, 93, 94, 95, 99, 101, 102, 104, 111, 119, 120, 122, 123, 125, 127, 131, 132, 137, 138, 140, 146, 148, 151, 152, 153, 157, 158, 161, 163], "std": [81, 84, 86, 89, 90, 92, 93, 94, 95, 96, 99, 100, 101, 102, 104, 105, 106, 107, 111, 112, 114, 119, 120, 122, 123, 126, 127, 134, 137, 140, 152, 153, 157, 158], "800": [81, 157], "crucial": [81, 112, 121], "bar": [81, 104, 108, 112, 137, 163], "decim": 81, "trustworthi": [81, 101], "compat": [81, 158], "familiar": [82, 87, 111, 118, 127, 150, 153], "conveni": [82, 87], "directli": [82, 85, 87, 90, 112, 119, 144, 163], "insid": [82, 87, 89, 108, 149, 152, 183], "pager": [82, 87], "roughli": [83, 88, 114, 126, 145], "simplest": [83, 88], "irrespect": [83, 88, 103, 185, 191], "train_test_split": [83, 84, 86, 88, 90, 105, 106, 112, 115, 116, 117, 121, 124, 125, 126, 131, 136, 141, 142, 146, 148, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 169], "behavior": [83, 88, 137, 147, 168], "oversimplifi": 84, "exclus": 84, "helper": [84, 86, 89, 90, 132, 138, 149, 152], "duplic": [84, 89, 90, 114, 156, 160], "48837": [84, 89, 156, 160], "48838": [84, 89, 156, 160], "48839": [84, 89, 156, 160], "48840": [84, 89, 156, 160], "48841": [84, 89, 156, 160], "explicit": [84, 85, 106, 144, 150, 153], "At": [84, 101, 104, 106, 114, 148, 169], "moreov": 84, "o": 84, "self": [84, 89, 101, 149, 152, 160], "explanatori": [84, 105], "000000": [84, 86, 96, 109, 111, 135, 137, 141], "643585": 84, "710510": 84, "min": [84, 86, 96, 109, 111, 114, 132, 137, 138, 143, 145, 167, 168, 170, 180], "max": [84, 86, 96, 109, 111, 114, 132, 137, 138, 143, 144, 145, 161, 167, 168, 170, 180, 185], "float64": [84, 96, 103, 106, 108, 109, 110, 111, 135, 141], "unusu": 84, "memori": [84, 105, 108, 109, 110, 111, 157, 158], "test_siz": [84, 96, 100, 103, 106, 107, 115, 117, 124, 126, 141, 148, 158], "determinist": [84, 103, 133, 139], "specifi": [84, 89, 90, 108, 109, 123, 145, 158, 160, 188], "remain": [84, 85, 104, 105, 112, 129, 147, 160], "quickli": [84, 108, 111, 112, 121, 144, 146, 148, 159, 160], "got": [84, 118, 127, 147, 170], "1f": [84, 114], "12211": 84, "36631": [84, 86], "cours": [84, 89, 108, 129, 132, 138, 141, 144, 149, 152, 165, 169], "environ": [84, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "pleas": [84, 86, 87, 90, 95, 98, 101, 103, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170, 183, 191], "rerun": [84, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "unabl": [84, 86, 87, 90, 95, 101, 104, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "render": [84, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "nbviewer": [84, 86, 87, 90, 95, 101, 106, 113, 139, 143, 147, 148, 156, 158, 160, 163, 169, 170], "logisticregressionlogisticregress": [84, 86, 90, 95, 148, 163], "807": [84, 86], "fraction": [84, 107, 121, 148], "correctli": [84, 94, 95, 104, 113, 148], "fed": 85, "73": [85, 108], "3273": 85, "side": [85, 96, 123, 126, 137, 158, 168], "39068": 85, "39069": 85, "39070": 85, "39071": 85, "39072": 85, "39073": 85, "linger": [85, 89, 99, 106], "denomin": 85, "major": [85, 88, 103], "seldom": 85, "target_predict": [85, 105, 106, 113, 124, 125, 132, 133, 138, 139, 144, 148, 151, 167, 168], "sake": [85, 95, 98, 103, 121, 147, 158, 183], "simplic": [85, 89, 95, 98, 103, 147, 183], "agre": [85, 126], "bool": [85, 108, 148], "mistak": [85, 113, 131, 148, 167], "success": [85, 86, 119, 169], "8242776341719346": 85, "harder": [85, 129], "conclud": [85, 91, 93, 103, 114, 163], "ones": [85, 89, 156, 157, 160], "adult_census_test": [85, 87], "9769": 85, "manual": [85, 89, 90, 114, 119, 128, 131, 144, 148, 157, 163, 171, 188], "deal": [85, 89, 90, 94, 104, 105, 110, 128, 131, 135, 137, 144, 146, 153, 164, 183], "model_nam": [85, 86, 157], "__class__": [85, 86], "__name__": [85, 86], "804": 85, "underli": [85, 86, 89, 99, 113, 119, 148], "wrongli": [85, 90], "held": [85, 96, 117, 121, 126, 158], "642352": 86, "1087": 86, "077721": 86, "89": [86, 96, 129], "665311": 86, "431247": 86, "725748": 86, "7522": 86, "692939": 86, "407": 86, "110175": 86, "423952": 86, "99999": 86, "4356": 86, "span": 86, "assumpt": [86, 89, 93, 105, 130, 147, 167, 168], "address": 86, "solver": [86, 137], "descent": [86, 109], "scaler": [86, 95, 137, 157, 162, 185, 187, 191], "standardscalerstandardscal": [86, 90, 95, 147], "wherea": [86, 121, 136, 142, 155, 162], "fashion": 86, "mean_": 86, "64235211": 86, "07772106": 86, "6653108": 86, "43124676": 86, "scale_": 86, "72556083": 86, "59025606": 86, "10461772": 86, "42378265": 86, "data_train_sc": 86, "17177061": 86, "14450843": 86, "71188483": 86, "28845333": 86, "02605707": 86, "22025127": 86, "27618374": 86, "33822677": 86, "77019645": 86, "77536738": 86, "03471139": 86, "53605445": 86, "48319243": 86, "69090725": 86, "perspect": [86, 92, 94, 107], "predefin": 86, "shorthand": 86, "663100e": 86, "273364e": 86, "530310e": 86, "840667e": 86, "844684e": 86, "000014e": 86, "576792e": 86, "445084e": 86, "202513e": 86, "173852e": 86, "753674e": 86, "471139e": 86, "196565e": 86, "817680e": 86, "677425e": 86, "741752e": 86, "314865e": 86, "047970e": 86, "714245e": 86, "jointplot": 86, "clearer": 86, "num_points_to_plot": 86, "300": [86, 109, 114, 119, 125, 132, 138, 143, 145, 167], "marginal_kw": 86, "dict": [86, 157], "suptitl": [86, 126], "nbefor": 86, "nafter": 86, "x27": [86, 90, 95, 101, 113, 147, 156, 158, 160], "pipelinepipelin": [86, 90, 95, 147, 156, 158, 160], "named_step": 86, "expos": [86, 89, 123, 148], "addition": 86, "predict_proba": [86, 148, 156, 163], "decision_funct": 86, "elapsed_tim": [86, 92, 94], "predicted_target": 86, "n_iter_": [86, 127], "080": 86, "164": [86, 159], "scenario": [86, 90, 137], "kneighborsclassifierkneighborsclassifi": 87, "first_data_valu": 87, "first_predict": 87, "first_target_valu": 87, "number_of_correct_predict": 87, "number_of_predict": 87, "len": [87, 106, 112, 113, 120, 121], "8290379545978042": 87, "8177909714402702": 87, "data_numeric_train": 88, "data_numeric_test": 88, "class_to_predict": 88, "high_revenue_clf": 88, "234": 88, "low_revenue_clf": 88, "766": 88, "7607182343065395": 88, "appear": [88, 114], "most_freq_revenue_clf": 88, "76": [88, 102, 108, 110, 148], "reassur": [88, 126, 158], "arithmet": 89, "instruct": 89, "taken": [89, 112, 123, 145], "symbol": [89, 105], "sort_index": 89, "857": [89, 161], "cambodia": 89, "canada": 89, "182": 89, "china": 89, "122": [89, 106, 111, 112, 134, 137, 140], "columbia": 89, "85": [89, 95, 106, 111, 112, 121, 134, 137, 140, 160, 185], "cuba": 89, "138": 89, "dominican": 89, "republ": 89, "103": [89, 109, 153, 163], "ecuador": 89, "el": 89, "salvador": 89, "155": [89, 160], "england": 89, "127": 89, "franc": 89, "germani": 89, "206": [89, 168], "greec": 89, "guatemala": 89, "88": [89, 90, 106, 111, 112, 134, 137, 140, 156], "haiti": 89, "holand": 89, "netherland": 89, "hondura": 89, "hong": 89, "hungari": 89, "india": 89, "iran": 89, "ireland": 89, "itali": 89, "105": [89, 109], "jamaica": 89, "106": [89, 109], "japan": 89, "lao": 89, "mexico": 89, "951": 89, "nicaragua": 89, "outli": 89, "guam": 89, "usvi": 89, "peru": 89, "philippin": 89, "295": 89, "poland": 89, "portug": 89, "67": [89, 108, 109, 112], "puerto": 89, "rico": 89, "184": 89, "scotland": 89, "21": [89, 96, 106, 108, 109, 111, 112, 124, 134, 137, 140, 153, 160, 162], "south": [89, 112], "115": [89, 106, 149, 152], "taiwan": 89, "65": [89, 95, 108, 121], "thailand": 89, "trinadad": 89, "tobago": 89, "43832": 89, "vietnam": 89, "86": [89, 95, 106, 111, 112, 134, 137, 140, 159], "yugoslavia": 89, "recogn": [89, 99], "li": [89, 114], "categorical_columns_selector": [89, 90, 91, 92, 93, 94, 156, 158, 160], "dtype_includ": [89, 90, 91, 92, 93, 94, 123, 154, 156, 158, 160, 161], "unwant": [89, 111], "data_categor": [89, 91, 93], "education_column": 89, "education_encod": 89, "map": [89, 93, 162], "categories_": 89, "data_encod": 89, "downstream": 89, "lexicograph": 89, "meaningless": [89, 114, 168], "suppos": [89, 99], "l": [89, 99], "xl": 89, "alphabet": 89, "accept": [89, 106], "constructor": 89, "explicitli": [89, 149, 152, 160, 162], "mislead": [89, 94, 112], "altern": [89, 160, 167], "sparse_output": [89, 92, 94, 141], "spars": [89, 92, 94, 106, 111], "effici": [89, 113, 120, 123, 137, 144], "won": [89, 112], "associ": [89, 90, 99, 109, 111, 148, 156], "input_featur": [89, 137, 141, 144], "education_": 89, "becam": 89, "102": [89, 109], "wrap": [89, 114, 171], "columns_encod": 89, "feder": 89, "emp": 89, "inc": 89, "country_": 89, "amp": 89, "violat": [89, 105], "realli": [89, 99, 105, 107, 109, 113, 148], "misord": 89, "liner": 89, "met": 89, "ineffici": 89, "integr": [89, 120, 137], "abl": [89, 90, 102, 109, 114, 115, 119, 120, 123, 124, 144, 147, 148, 149, 152, 159, 163, 166, 168, 170, 177, 188, 191], "bypass": 89, "keyword": 89, "use_encoded_valu": [89, 90, 91, 92, 93, 94, 123, 154, 156, 158, 160, 161], "unknown_valu": [89, 90, 91, 92, 93, 94, 123, 154, 156, 158, 160, 161], "silenc": 89, "convergencewarn": 89, "83282137": 89, "75117898": 89, "75769806": 89, "7616365": 89, "7548697": 89, "03336763": 89, "03397489": 89, "03307819": 89, "03448153": 89, "03204823": 89, "83222438": 89, "83560242": 89, "82872645": 89, "83312858": 89, "83466421": 89, "833": [89, 93], "002": [89, 93, 94, 157], "decoupl": [90, 148], "numerical_columns_selector": [90, 92, 94], "dtype_exclud": [90, 92, 94], "properli": [90, 101, 109, 117, 126, 147, 167], "format": [90, 105, 109, 138, 145], "elaps": [90, 129], "introspect": [90, 191], "send": 90, "columntransfom": 90, "categorical_preprocessor": [90, 92, 94, 154, 156, 158, 160, 161], "numerical_preprocessor": 90, "standard_scal": 90, "concaten": [90, 98, 99, 103, 104, 141, 144, 147, 158, 167], "columntransformercolumntransform": [90, 95, 156, 158, 160], "onehotencoderonehotencod": [90, 95], "prefer": 90, "raw": [90, 151, 191], "7762": 90, "56": [90, 108, 109, 124, 152], "divorc": 90, "unmarri": 90, "23881": 90, "transport": 90, "30507": 90, "specialti": 90, "14344": 90, "28911": 90, "19484": 90, "wife": 90, "8575055278028008": 90, "usabl": 90, "93830132": 90, "97879648": 90, "88348508": 90, "97239208": 90, "96875858": 90, "04073191": 90, "03926468": 90, "03880358": 90, "04343271": 90, "04053926": 90, "8512642": 90, "8498311": 90, "84756347": 90, "8523751": 90, "85524161": 90, "851": [90, 123], "compound": 90, "isol": [90, 106, 121], "nice": [90, 113], "fast": [90, 94, 119], "passthrough": [90, 92, 94, 123, 154, 156, 158, 160, 161], "969": [90, 99], "973": 90, "8814183932519859": 90, "significantli": [90, 107, 112], "whenev": [90, 109], "popular": [90, 123], "datasci": 90, "practition": 90, "outperform": 90, "assembl": [91, 93, 119, 121], "rais": [91, 93, 113, 114, 123, 125, 149, 152], "warn": [91, 93, 113, 114, 120, 125, 137, 149, 152], "nan": [91, 93, 95, 104, 108, 149, 152], "traceback": [91, 93, 149, 152], "error_scor": [91, 93], "awai": [91, 93, 94, 114, 151, 171], "handi": [91, 93, 106, 109, 149, 152], "empir": [92, 94, 106], "util": [92, 94, 95, 103, 108], "873": [92, 94], "829": 92, "detriment": [92, 94, 121, 123, 137], "dens": [92, 94], "workaround": [92, 94], "755": 93, "anyth": [93, 105, 128, 131, 148], "constantli": [93, 98, 103], "761": 93, "messag": [93, 94], "874": 94, "935": 94, "872": 94, "889": 94, "signific": [94, 112, 121, 129, 158], "useless": [94, 126], "691": 94, "view": [94, 158], "longer": [94, 145, 157, 164], "current": [94, 126, 183], "implement": [94, 104, 113, 114, 120, 143, 146, 149, 152, 156, 159], "incomplet": 94, "yield": [94, 121, 143], "unnecessari": [94, 117, 126], "unless": 94, "long": [94, 108, 109, 111, 157], "reproduc": [95, 109, 158], "script": 95, "event": 95, "rerecord": 95, "ui": 95, "releas": 95, "house_pric": [95, 108, 141, 150, 151, 153], "na_valu": [95, 108, 141], "id": [95, 99, 108, 141], "mssubclass": [95, 108], "mszone": [95, 108], "street": [95, 108, 141], "allei": [95, 108], "lotshap": [95, 108], "landcontour": [95, 108], "poolqc": [95, 108], "fenc": [95, 108], "miscfeatur": [95, 108], "mosold": [95, 108], "yrsold": [95, 108], "saletyp": [95, 108], "salecondit": [95, 108], "rl": [95, 108], "8450": [95, 108], "pave": [95, 108], "reg": [95, 108, 112], "lvl": [95, 108], "allpub": [95, 108], "2008": [95, 108], "wd": [95, 108], "9600": [95, 108], "2007": [95, 108], "11250": [95, 108], "ir1": [95, 108], "9550": [95, 108], "2006": [95, 108], "abnorml": [95, 108], "84": [95, 108], "14260": [95, 108], "1455": 95, "1456": 95, "62": [95, 108, 126], "7917": 95, "1457": 95, "13175": 95, "mnprv": [95, 108], "2010": 95, "1458": 95, "66": [95, 108, 109, 121], "9042": 95, "gdprv": 95, "shed": [95, 108], "2500": 95, "1459": [95, 108], "9717": 95, "1460": [95, 108], "9937": 95, "cherri": 95, "retain": 95, "numeric_featur": 95, "fullbath": [95, 108], "halfbath": [95, 108], "categorical_featur": [95, 108], "neighborhood": [95, 96, 108, 112], "housestyl": [95, 108], "imput": [95, 108], "simpleimput": [95, 108], "numeric_transform": 95, "categorical_transform": 95, "join": 95, "simpleimputersimpleimput": 95, "859": [95, 161], "018": 95, "dollar": [95, 96, 106, 111, 134, 137, 140], "necessarili": [95, 106, 107, 122, 137, 156, 188], "richer": [95, 144], "level": [95, 101, 103, 121, 123, 128, 129, 131, 148, 165, 166, 167, 169, 170, 183], "probabl": [95, 106, 111, 112, 113, 146, 163, 169, 185], "coars": 95, "dummyregressor": [96, 151], "overview": [96, 97, 100, 102, 106, 107, 111, 113, 115, 116, 117, 120, 122, 123, 124, 125, 126, 132, 134, 136, 137, 138, 140, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 163, 165, 166, 167, 168, 169, 170, 171], "fetch_california_h": [96, 100, 106, 107, 111, 112, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 134, 137, 140, 155, 162], "return_x_i": [96, 101, 104, 112, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 134, 137, 140, 155, 162, 185], "as_fram": [96, 100, 104, 106, 107, 111, 112, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 134, 137, 140, 155, 162], "rescal": [96, 100, 107, 115, 117, 118, 119, 120, 121, 122, 124, 126, 127, 134, 137, 140, 151, 155, 157, 162], "splitter": 96, "cv_results_tree_regressor": 96, "n_job": [96, 99, 100, 101, 102, 103, 105, 107, 111, 112, 119, 120, 121, 122, 123, 124, 126, 127, 129, 131, 137, 140, 156, 158, 160, 162], "errors_tree_regressor": 96, "649339": 96, "204968": 96, "485407": 96, "815319": 96, "616791": 96, "661205": 96, "575505": 96, "result_dummi": 96, "errors_dummy_regressor": 96, "140009": 96, "821140": 96, "757566": 96, "543652": 96, "034555": 96, "979007": 96, "477244": 96, "all_error": 96, "concat": [96, 103, 104, 112, 127, 129, 130, 142], "679694": 96, "713153": 96, "040524": 96, "539353": 96, "455735": 96, "941912": 96, "879692": 96, "213912": 96, "568890": 96, "015862": 96, "831142": 96, "542490": 96, "859949": 96, "810044": 96, "947952": 96, "108976": 96, "991373": 96, "605737": 96, "023571": 96, "888824": 96, "556965": 96, "489502": 96, "539567": 96, "730880": 96, "185225": 96, "453819": 96, "298971": 96, "205588": 96, "084639": 96, "399344": 96, "984471": 96, "860603": 96, "981744": 96, "476758": 96, "547140": 96, "080492": 96, "820219": 96, "750598": 96, "768721": 96, "167433": 96, "305556": 96, "099895": 96, "503017": 96, "871895": 96, "147974": 96, "294401": 96, "386320": 96, "878024": 96, "815660": 96, "130063": 96, "216574": 96, "298054": 96, "107460": 96, "502703": 96, "620318": 96, "165331": 96, "linspac": [96, 100, 102, 103, 114, 119, 125, 132, 138, 143, 145, 159], "edgecolor": [96, 99, 103, 106, 107, 108, 109, 110, 111, 159], "legend": [96, 99, 100, 102, 103, 104, 105, 107, 109, 111, 113, 114, 119, 125, 126, 138, 142, 146, 148, 151, 159, 163, 167, 168, 169, 170], "bbox_to_anchor": [96, 99, 102, 103, 104, 105, 109, 111, 113, 114, 119, 125, 138, 142, 148, 159, 163, 167, 169], "loc": [96, 99, 102, 103, 104, 105, 109, 111, 113, 114, 119, 125, 136, 138, 142, 146, 148, 159, 163, 167, 169], "upper": [96, 99, 102, 103, 104, 105, 109, 111, 112, 114, 119, 125, 142, 148, 163, 167, 169], "xlabel": [96, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 112, 127, 129, 130, 137, 146, 148], "Such": 96, "onlin": [96, 98, 103], "extrem": [96, 101, 110, 111, 128, 131, 137], "gamma": [97, 101, 102, 147], "svm": [97, 101, 102, 144, 147], "form": [97, 99, 101, 102, 112, 132, 138, 143, 145, 157], "kernel": [97, 102, 144, 147], "accomplish": [97, 102], "rbf": [97, 102, 147], "svc": [97, 101, 102, 147], "scheme": [97, 102, 105, 113, 168], "validation_curv": [97, 102, 107, 126], "10e": [97, 102], "10e2": [97, 102], "logarithm": [97, 102], "svc__gamma": [97, 102], "retriev": [97, 102, 106, 112], "learning_curv": [97, 100, 102], "half": [98, 103, 147, 148], "uniform": [98, 103, 111, 114, 160], "handwritten": 99, "digit": 99, "load_digit": 99, "recreat": 99, "minmaxscal": [99, 114, 191], "kfold": [99, 101, 104, 127, 150, 153, 158], "test_score_no_shuffl": 99, "931": 99, "026": 99, "test_score_with_shuffl": 99, "005": [99, 123], "all_scor": [99, 101], "xlim": [99, 112, 119, 137, 148], "impos": [99, 121, 146, 160], "94166667": 99, "89722222": 99, "94986072": 99, "9637883": 99, "90250696": 99, "ship": 99, "descr": [99, 106, 111], "_digits_dataset": 99, "optic": 99, "recognit": 99, "characterist": [99, 106, 111, 148], "1797": 99, "8x8": 99, "pixel": 99, "creator": 99, "alpaydin": 99, "boun": 99, "edu": 99, "tr": 99, "juli": 99, "1998": 99, "copi": [99, 106, 109, 112, 132, 138, 185], "uci": 99, "ic": 99, "nist": 99, "bitmap": 99, "preprint": 99, "32x32": 99, "nonoverlap": 99, "block": [99, 105, 106, 111, 112, 120], "4x4": 99, "invari": 99, "distort": 99, "garri": 99, "j": 99, "candela": 99, "dimmick": 99, "geist": 99, "grother": 99, "janet": 99, "wilson": 99, "handprint": 99, "nistir": 99, "5469": 99, "kaynak": 99, "1995": 99, "Their": 99, "msc": 99, "thesi": 99, "institut": 99, "graduat": 99, "bogazici": 99, "univers": 99, "cascad": 99, "kybernetika": 99, "ken": 99, "tang": 99, "ponnuthurai": 99, "n": [99, 101, 102, 111, 114, 120, 124, 126, 127, 132, 137, 138, 141, 142, 146, 148, 151, 157, 158, 161, 163], "suganthan": 99, "xi": 99, "yao": 99, "kai": 99, "qin": 99, "dimensionalityreduct": 99, "lda": 99, "electr": [99, 108], "electron": 99, "nanyang": 99, "2005": 99, "claudio": 99, "gentil": 99, "nip": 99, "2000": 99, "writer": 99, "wrote": 99, "ensur": [99, 101, 104, 121], "certain": [99, 127], "130": [99, 120], "hypothesi": [99, 105], "itertool": [99, 108], "bound": [99, 148, 151], "writer_boundari": 99, "256": [99, 120, 121, 160], "386": 99, "516": 99, "646": 99, "776": 99, "915": 99, "1029": 99, "1157": 99, "1287": 99, "1415": 99, "1545": 99, "1667": 99, "zeros_lik": [99, 113], "lower_bound": 99, "upper_bound": 99, "group_id": 99, "lb": 99, "zip": [99, 109, 119, 132, 138], "ytick": [99, 104], "xtick": 99, "ylabel": [99, 100, 102, 104, 105, 107, 127, 137, 148, 163], "groupkfold": 99, "920": 99, "021": 99, "realiti": 99, "synthet": [100, 114, 119, 129, 148, 166, 167, 168, 170], "train_siz": [100, 102, 154, 161], "endpoint": 100, "325": [100, 109], "775": 100, "train_error": [100, 107, 137], "test_error": [100, 106, 107, 137], "errorbar": [100, 102, 107, 126, 137], "yerr": [100, 102, 107, 126, 137], "xscale": [100, 102], "log": [100, 102, 159, 160], "alon": 100, "anymor": [100, 103, 105, 106, 121, 147], "bay": 100, "especi": [100, 141], "report": [100, 101, 106], "problemat": [101, 137, 141, 160], "underestim": 101, "philosoph": 101, "breast": 101, "cancer": 101, "load_breast_canc": 101, "param_grid": [101, 122, 124, 156, 158, 167, 185, 191], "model_to_tun": 101, "gridsearchcvgridsearchcv": [101, 156, 158], "svcsvc": [101, 147], "best_params_": [101, 127, 155, 156, 158, 160, 162, 167, 185, 191], "best_score_": 101, "627": 101, "stage": [101, 104, 120, 128, 129, 131, 148, 169], "misinterpret": 101, "forget": 101, "pitfal": 101, "emb": [101, 158], "dedic": [101, 151], "declar": 101, "inner_cv": 101, "outer_cv": 101, "014": 101, "trial": 101, "test_score_not_nest": 101, "test_score_nest": 101, "n_trial": 101, "non_nest": 101, "append": [101, 104, 112, 114, 125, 127, 142], "merg": [101, 129], "whisker": [101, 111, 127, 129, 130, 137, 140, 152], "vert": [101, 111, 127, 129, 130, 137, 140, 152], "highest": [101, 113, 128, 129, 131, 148, 159, 160], "lure": 101, "overli": [101, 106], "020784": 102, "003680": 102, "680000": 102, "020032": 102, "003309": 102, "746667": 102, "018614": 102, "003263": 102, "786667": 102, "017825": 102, "003284": 102, "800000": 102, "018301": 102, "003292": 102, "018270": 102, "003044": 102, "017695": 102, "003330": 102, "016951": 102, "003296": 102, "826667": 102, "017549": 102, "003138": 102, "017619": 102, "003312": 102, "733333": 102, "765": 102, "043": 102, "param_nam": [102, 107, 126, 156, 159, 160, 185, 191], "regim": 102, "oscil": 102, "donat": [102, 110, 148, 149, 152], "simplist": 102, "imposs": [102, 147], "cv_results_logistic_regress": 103, "test_score_logistic_regress": 103, "815937": 103, "813849": 103, "815036": 103, "815569": 103, "810982": 103, "814709": 103, "813112": 103, "810327": 103, "812416": 103, "816388": 103, "most_frequent_classifi": 103, "cv_results_most_frequ": 103, "test_score_most_frequ": 103, "760329": 103, "756808": 103, "759142": 103, "760739": 103, "761681": 103, "761885": 103, "757463": 103, "757176": 103, "763114": 103, "all_test_scor": 103, "stratified_dummi": 103, "cv_results_stratifi": 103, "test_score_dummy_stratifi": 103, "uniform_dummi": 103, "cv_results_uniform": 103, "test_score_dummy_uniform": 103, "henc": [103, 112, 119, 160], "uniformli": [103, 114], "weakest": 103, "argu": 103, "chanc": [103, 106, 114, 128, 131, 148], "permutation_test_scor": 103, "permut": [103, 185], "quit": [103, 104, 105, 107, 109, 120, 146], "strongest": 103, "load_iri": [104, 185], "toi": [104, 144, 147], "nine": 104, "data_random": 104, "randn": [104, 114, 119, 128, 131, 133, 139, 144], "train_index": 104, "test_index": 104, "six": 104, "train_cv_count": 104, "test_cv_count": 104, "fold_idx": 104, "train_idx": 104, "test_idx": 104, "enumer": [104, 113, 114, 125, 127, 129, 132, 138, 158], "idx": [104, 129], "953": 104, "009": [104, 120], "frequenc": [104, 110, 148], "preserv": [104, 147, 156], "stratifiedkfold": [104, 149, 152], "960": 104, "016": 104, "past": [105, 110, 132, 138, 148], "acronym": 105, "ident": [105, 106, 120, 148, 158], "financi": 105, "quotat": 105, "tot": 105, "xom": 105, "exxon": 105, "cvx": 105, "chevron": 105, "cop": 105, "conocophillip": 105, "vlo": 105, "valero": 105, "template_nam": 105, "quot": 105, "stock": 105, "2f": [105, 106, 121, 124, 126, 132, 137, 138, 141, 142, 143, 144, 145, 148, 156, 160, 163, 169], "07": [105, 112], "surprisingli": [105, 106, 111, 131], "outstand": 105, "eas": [105, 106, 133, 139, 144, 147], "r2_score": 105, "verifi": [105, 117, 126, 144], "doesn": 105, "proper": [105, 111, 144, 158], "to_period": 105, "q": 105, "97": [105, 159, 169, 191], "forecast": 105, "ulterior": 105, "timeseriessplit": 105, "behaviour": [105, 121, 130, 141, 163], "nuniqu": [105, 109, 141, 167, 191], "shelv": 105, "absurd": 105, "intend": [106, 110, 183], "dive": 106, "area": [106, 107, 108, 114, 147, 148, 167], "geograph": [106, 111, 122], "_california_housing_dataset": [106, 111], "20640": [106, 111], "medinc": [106, 111, 112, 134, 137, 140], "houseag": [106, 111, 112, 134, 137, 140], "averoom": [106, 111, 112, 134, 137, 140, 162], "household": [106, 111], "avebedrm": [106, 111, 112, 134, 137, 140], "aveoccup": [106, 111, 112, 134, 137, 140], "member": [106, 111], "latitud": [106, 111, 112, 134, 137, 140], "longitud": [106, 111, 112, 134, 137, 140], "statlib": [106, 111], "dcc": [106, 111], "fc": [106, 111], "pt": [106, 111], "ltorgo": [106, 111], "cal_hous": [106, 111], "district": [106, 111, 112, 122, 134, 140], "hundr": [106, 111, 129], "deriv": [106, 109, 111, 134, 140, 144], "1990": [106, 111], "u": [106, 111], "smallest": [106, 111, 120], "bureau": [106, 111], "600": [106, 111], "resid": [106, 111], "home": [106, 111], "empti": [106, 111], "vacat": [106, 111], "resort": [106, 111], "pace": [106, 111], "kellei": [106, 111], "ronald": [106, 111], "barri": [106, 111], "spatial": [106, 111], "autoregress": [106, 111], "1997": [106, 111], "291": [106, 111], "297": [106, 111, 137], "3252": [106, 111, 112, 134, 137, 140], "984127": [106, 111, 112, 134, 137, 140], "023810": [106, 111, 112, 134, 137, 140], "322": [106, 111, 112, 134, 137, 140], "555556": [106, 111, 112, 134, 137, 140], "3014": [106, 111, 112, 134, 137, 140], "238137": [106, 111, 112, 134, 137, 140], "971880": [106, 111, 112, 134, 137, 140], "2401": [106, 111, 112, 134, 137, 140], "109842": [106, 111, 112, 134, 137, 140], "2574": [106, 111, 112, 134, 137, 140], "52": [106, 108, 109, 111, 112, 124, 129, 134, 137, 140, 163], "288136": [106, 111, 112, 134, 137, 140], "073446": [106, 111, 112, 134, 137, 140], "496": [106, 111, 112, 134, 137, 140, 159, 160], "802260": [106, 111, 112, 134, 137, 140], "6431": [106, 111, 112, 134, 137, 140], "817352": [106, 111, 112, 134, 137, 140], "073059": [106, 111, 112, 134, 137, 140], "558": [106, 111, 112, 134, 137, 140], "547945": [106, 111, 112, 134, 137, 140], "8462": [106, 111, 112, 134, 137, 140], "281853": [106, 111, 112, 134, 137, 140], "081081": [106, 111, 112, 134, 137, 140], "565": [106, 111, 112, 120, 134, 137, 140], "181467": [106, 111, 112, 134, 137, 140], "452": [106, 140], "358": 106, "352": 106, "341": 106, "342": 106, "medhousev": [106, 111, 112], "decisiontreeregressordecisiontreeregressor": [106, 170], "mean_absolute_error": [106, 117, 124, 125, 126, 143, 151], "grown": [106, 117, 121, 126], "leaf": [106, 121, 156, 160, 161, 167, 169, 179, 180], "node": [106, 121, 123, 156, 161, 167, 169, 178, 179, 180], "phenomena": 106, "unstabl": 106, "wouldn": 106, "unlimit": [106, 121], "lucki": [106, 107], "easiest": 106, "variant": 106, "172038": 106, "004298": 106, "909797": 106, "168437": 106, "004324": 106, "421170": 106, "168335": 106, "004101": 106, "411089": 106, "165946": 106, "004257": 106, "319824": 106, "161776": 106, "004121": 106, "607875": 106, "neg_": [106, 153], "front": 106, "revert": 106, "negat": 106, "163984": 106, "004281": 106, "901300": 106, "166276": 106, "004179": 106, "572767": 106, "164489": 106, "004044": 106, "194585": 106, "166911": 106, "004155": 106, "590236": 106, "165035": 106, "004256": 106, "727998": 106, "furthermor": [106, 137, 141, 146], "percentag": [106, 114, 151], "tag": [106, 132, 138], "expert": [106, 144, 147], "20057034": 106, "19432807": 106, "19427562": 106, "19485879": 106, "18581939": 106, "00308609": 106, "00311017": 106, "00305271": 106, "00292754": 106, "00290322": 106, "26291527": 106, "41947109": 106, "44492564": 106, "23357874": 106, "40788361": 106, "overal": [106, 117, 121, 122, 126, 137, 148, 167], "fluctuat": [107, 156], "hopefulli": [107, 121, 143], "285": 107, "328": [107, 160], "harm": 107, "matter": [107, 130, 158], "compromis": [107, 148], "dispers": [107, 120, 141], "directori": [108, 109, 110], "charact": 108, "marker": [108, 113, 148], "pars": [108, 109], "lotconfig": 108, "208500": 108, "fr2": 108, "181500": 108, "223500": 108, "corner": [108, 148], "140000": 108, "250000": 108, "nin": 108, "tail": [108, 109, 111], "coupl": [108, 109, 111, 120, 121, 137, 160], "core": [108, 109, 110, 111, 119, 120], "rangeindex": [108, 109, 110, 111], "null": [108, 109, 110, 111, 146], "1201": 108, "landslop": 108, "condition1": 108, "condition2": 108, "bldgtype": 108, "yearremodadd": 108, "roofstyl": 108, "roofmatl": 108, "exterior1st": 108, "exterior2nd": 108, "masvnrtyp": 108, "588": 108, "1452": 108, "exterqu": 108, "extercond": 108, "foundat": [108, 141], "bsmtqual": 108, "1423": 108, "bsmtcond": 108, "bsmtexposur": 108, "1422": 108, "bsmtfintype1": 108, "bsmtfintype2": 108, "heat": 108, "heatingqc": 108, "centralair": [108, 141], "bsmtfullbath": 108, "bsmthalfbath": 108, "51": [108, 124, 191], "kitchenqu": 108, "53": [108, 109, 120, 129, 160], "54": [108, 109, 121, 140], "fireplacequ": 108, "770": 108, "57": [108, 109, 124], "garagetyp": 108, "1379": 108, "garageyrblt": 108, "garagefinish": 108, "garagequ": 108, "garagecond": 108, "paveddr": [108, 141], "72": [108, 121], "281": 108, "kb": [108, 110], "numerical_data": 108, "410": 108, "layout": 108, "subplots_adjust": [108, 109, 111, 112], "hspace": [108, 109, 111], "wspace": [108, 111], "criterion": [108, 112, 163], "swim": 108, "pool": [108, 131], "string_data": 108, "490": 108, "ceil": 108, "zip_longest": 108, "n_string_featur": 108, "nrow": 108, "ncol": [108, 126, 138], "fig": [108, 112, 126, 159, 162, 163, 164, 185], "subplot": [108, 112, 126, 163, 167, 168, 169], "ravel": [108, 109, 138], "barh": [108, 110, 112, 135, 141, 142, 146, 148], "set_titl": [108, 126, 144, 145, 148], "databas": [108, 162], "grvl": 108, "gd": 108, "make_column_transform": [108, 123], "most_frequent_imput": 108, "mean_imput": 108, "ames_housing_preprocess": 108, "timestamp": 109, "150": [109, 113], "0880": 109, "033870": 109, "161": [109, 120, 163], "336": 109, "0842": 109, "033571": 109, "163": 109, "409": 109, "0234": 109, "033223": 109, "156": [109, 137], "445": 109, "0016": 109, "032908": 109, "148": 109, "441": 109, "1144": 109, "38254": 109, "38253": 109, "mb": [109, 111], "str": 109, "datetim": 109, "direct": [109, 160], "reopen": 109, "explan": [109, 164], "soup": 109, "blender": 109, "blend": 109, "veget": 109, "instantan": 109, "profession": 109, "calibr": 109, "track": 109, "spent": [109, 129], "food": 109, "uranium": 109, "petrol": 109, "ga": 109, "coal": 109, "plant": 109, "400": 109, "cheaper": [109, 112], "w": 109, "deliv": 109, "breakout": 109, "kilomet": 109, "costli": [109, 155, 156, 162], "cruis": 109, "datetime64": 109, "ns": 109, "freq": 109, "august": 109, "septemb": 109, "date_first_rid": 109, "cycling_rid": 109, "data_rid": 109, "target_rid": 109, "tempor": 109, "resolut": [109, 160], "smoother": [109, 114], "set_xlabel": [109, 126], "extremum": 109, "rng": [109, 111, 112, 114, 119, 131, 133, 139, 144], "randomst": [109, 111, 112, 114, 119, 131, 133, 139, 144], "arang": [109, 111, 112, 114, 167, 168, 170], "quantiz": [109, 111], "midpoint": [109, 111], "interv": [109, 111, 114, 116, 119, 125, 166, 168, 170], "qcut": [109, 111], "retbin": [109, 111], "lambda": [109, 111, 159, 185], "mid": [109, 111], "palett": [109, 111, 113, 142, 146, 147, 163, 167, 169], "viridi": [109, 111, 159, 185], "uphil": 109, "physiolog": 109, "stimuli": 109, "recenc": [110, 148], "monetari": [110, 148], "12500": 110, "98": [110, 112, 163], "3250": [110, 145], "4000": 110, "6000": 110, "748": 110, "747": 110, "noth": [110, 114], "shock": 110, "her": 110, "762032": 110, "237968": 110, "strike": 110, "fetch": 111, "internet": 111, "california_h": 111, "526": 111, "585": 111, "521": [111, 148], "413": [111, 119, 160], "422": [111, 148], "demographi": [111, 134, 140], "granular": [111, 148], "20639": 111, "640": [111, 163], "unnotic": 111, "features_of_interest": 111, "429000": 111, "096675": 111, "070655": 111, "1425": 111, "476744": 111, "474173": 111, "473911": 111, "386050": 111, "1132": 111, "462122": 111, "846154": 111, "333333": 111, "692308": 111, "440716": 111, "006079": 111, "429741": 111, "787": [111, 157], "229129": 111, "048780": 111, "818116": 111, "1166": [111, 141], "052381": 111, "099526": 111, "282261": 111, "1725": 111, "141": 111, "909091": 111, "066667": 111, "1243": 111, "35682": 111, "huge": [111, 141], "datapoint": 111, "coast": 111, "big": [111, 151], "citi": [111, 151], "san": 111, "diego": 111, "lo": 111, "angel": 111, "jose": 111, "francisco": 111, "columns_drop": 111, "distinguish": 111, "curiou": [111, 147, 191], "553": [111, 148], "062": 111, "coef": [111, 112, 135, 137, 141, 142, 146], "est": [111, 137, 140], "spot": [111, 137], "10000": 112, "100k": 112, "assert": [112, 121, 191], "un": [112, 137], "bin_var": 112, "randint": [112, 124, 128, 131], "rnd_bin": 112, "num_var": 112, "rnd_num": 112, "x_with_rnd_feat": 112, "x_train": [112, 141], "x_test": [112, 141], "y_train": [112, 141, 180], "y_test": [112, 141], "train_dataset": 112, "insert": 112, "kde": 112, "scatter_kw": 112, "x_i": 112, "versu": [112, 151, 171], "6013466090490024": 112, "5975757793803438": 112, "Its": 112, "somehow": 112, "rest": [112, 144], "worth": 112, "habit": 112, "nb": 112, "outcom": [112, 146, 148, 162], "shall": [112, 114], "rise": 112, "80k": 112, "gaug": 112, "decad": 112, "visibl": 112, "dev": 112, "6013157556102924": 112, "5972410717953726": 112, "safe": 112, "perturb": 112, "repeatedkfold": 112, "cv_model": 112, "n_repeat": [112, 129, 130], "boxplot": 112, "cyan": 112, "satur": 112, "pretti": 112, "015": 112, "5899811014945939": 112, "5769786920519312": 112, "partli": 112, "multivari": 112, "instabl": 112, "teas": 112, "inher": 112, "979744472893218": 112, "8486014957626168": 112, "formal": 112, "brought": 112, "argsort": [112, 129], "set_ytick": 112, "set_yticklabel": 112, "9794681714118251": 112, "8483050516199635": 112, "def": [112, 114, 119, 132, 133, 138, 139, 145, 156, 159, 160, 167, 185], "get_score_after_permut": 112, "curr_feat": 112, "x_permut": 112, "col_idx": 112, "permuted_scor": 112, "get_feature_import": 112, "baseline_score_train": 112, "permuted_score_train": 112, "feature_import": 112, "688": [112, 148], "list_feature_import": 112, "n_round": 112, "678": 112, "0105": 112, "heavili": 112, "permutation_import": 112, "calcul": [112, 113, 148], "importances_mean": 112, "importances_std": 112, "plot_feature_import": 112, "perm_importance_result": 112, "feat_nam": 112, "xerr": 112, "perm_importance_result_train": 112, "realist": [112, 146], "unclear": 112, "culmen_column": [113, 136, 142, 146, 163, 164, 165, 169], "purposefulli": 113, "unlik": [113, 117, 126, 163], "misclassifi": 113, "decisiontreeclassifi": [113, 123, 149, 152, 163, 167, 169], "tab": [113, 114, 119, 142, 146, 147, 148, 163, 167, 168, 169], "decisiontreeclassifierdecisiontreeclassifi": [113, 163, 169], "misclassified_samples_idx": 113, "flatnonzero": 113, "data_misclassifi": 113, "decisionboundarydisplai": [113, 136, 142, 146, 147, 163, 165, 167, 169], "from_estim": [113, 136, 142, 146, 147, 148, 163, 167, 169], "response_method": [113, 142, 146, 147, 163, 167, 169], "cmap": [113, 142, 146, 147, 156, 163, 167, 169], "rdbu": [113, 147, 163, 167, 169], "center": [113, 138, 159, 162, 167], "nwith": [113, 119], "misclassif": [113, 148], "sample_weight": 113, "trick": [113, 147], "drastic": 113, "qualit": [113, 114, 132, 138, 169], "newly_misclassified_samples_idx": 113, "remaining_misclassified_samples_idx": 113, "intersect1d": 113, "ensemble_weight": 113, "935672514619883": 113, "6929824561403509": 113, "94": [113, 126], "adaboostclassifi": 113, "samm": 113, "adaboostclassifieradaboostclassifi": 113, "boosting_round": 113, "estimators_": [113, 114, 116, 125], "to_numpi": [113, 114, 125, 148], "640x480": 113, "estimator_weights_": 113, "58351894": 113, "46901998": 113, "03303773": 113, "estimator_errors_": 113, "05263158": 113, "05864198": 113, "08787269": 113, "sens": [113, 170], "stand": [114, 185], "generate_data": [114, 119], "x_min": [114, 119], "x_max": [114, 119], "capabl": [114, 119, 137, 148, 166, 168, 170], "y_pred": [114, 149, 152], "data_bootstrap": 114, "target_bootstrap": 114, "bootstrap_sampl": 114, "bootstrap_indic": 114, "n_bootstrap": 114, "bootstrap_idx": 114, "facecolor": 114, "180": [114, 137, 145], "linewidth": [114, 167], "darker": 114, "data_train_hug": 114, "data_test_hug": 114, "target_train_hug": 114, "100_000": 114, "data_bootstrap_sampl": 114, "target_bootstrap_sampl": 114, "ratio_unique_sampl": 114, "bag_of_tre": 114, "tree_idx": [114, 125], "tree_predict": [114, 125], "feed": 114, "bag_predict": 114, "unbroken": [114, 119], "whole": [114, 116, 121, 123, 125, 144], "meta": 114, "smooth": [114, 147], "bagged_tre": [114, 123], "bagged_trees_predict": 114, "els": [114, 167], "opac": 114, "appreci": 114, "space": [114, 116, 118, 119, 125, 127, 131, 137, 146, 163, 168, 169], "polynomialfeatur": [114, 137, 144], "polynomial_regressor": 114, "1e": [114, 120, 157, 160], "intention": 114, "simpli": [114, 169], "regressor_predict": 114, "base_model_lin": 114, "bagging_predict": 114, "ylim": [114, 137, 148], "shade": 114, "randomizedsearchcv": [115, 121, 124, 155, 160, 162, 185], "penguins_regress": [116, 125, 132, 138, 143, 145, 164, 166, 167, 168, 170], "evenli": [116, 125], "170": [116, 125], "230": [116, 125], "newli": [116, 125], "displai": [116, 125, 146, 148, 159, 185], "conduct": [117, 126, 162], "learning_r": [117, 118, 121, 126, 127, 154, 156, 159, 160, 161, 185, 187], "slower": [117, 126, 158], "offer": [117, 126, 160], "n_iter_no_chang": [117, 126], "max_leaf_nod": [118, 121, 127, 154, 156, 158, 159, 160, 161, 167, 185, 187], "residu": [119, 121, 160], "back": [119, 146, 148, 159, 163], "len_x": 119, "rand": [119, 133, 139, 144], "target_train_predict": 119, "target_test_predict": 119, "line_predict": 119, "lines_residu": 119, "edit": 119, "initi": [119, 158, 188], "tree_residu": 119, "target_train_predicted_residu": 119, "target_test_predicted_residu": 119, "manag": 119, "x_sampl": 119, "target_tru": 119, "target_true_residu": 119, "commit": [119, 151], "y_pred_first_tre": 119, "517": 119, "393": 119, "145": 119, "248": [119, 120], "y_pred_first_and_second_tre": 119, "gradientboostingregressor": [119, 120, 121, 126], "gradient_boost": [119, 120], "cv_results_gbdt": [119, 120], "411": 119, "910": 119, "010": [119, 120, 161], "random_forest": [119, 123], "cv_results_rf": 119, "359": 119, "301": 119, "715": 119, "224": 119, "brute": [120, 143], "overcom": [120, 122, 141, 144], "benchmark": 120, "385": 120, "909": 120, "kbinsdiscret": [120, 144], "n_bin": [120, 144], "quantil": [120, 147], "data_tran": 120, "opt": [120, 137, 149, 152], "hostedtoolcach": [120, 137, 149, 152], "x64": [120, 137, 149, 152], "lib": [120, 137, 149, 152], "python3": [120, 137, 149, 152], "site": [120, 137, 149, 152], "_discret": 120, "py": [120, 137, 149, 152], "279": 120, "userwarn": [120, 149, 152], "249": [120, 152], "231": [120, 160], "162": 120, "203": 120, "242": 120, "125": 120, "160": 120, "126": 120, "136": 120, "199": 120, "col": [120, 141], "253": [120, 160, 161], "207": 120, "235": [120, 125, 170], "759": 120, "956": 120, "013": 120, "histogram_gradient_boost": 120, "cv_results_hgbdt": 120, "758": 120, "694": 120, "039": 120, "076": 120, "clariti": 121, "doubl": [121, 156, 157], "max_featur": [121, 123, 124], "grow": [121, 122, 167, 185], "uncorrel": 121, "symmetr": [121, 167], "constraint": [121, 137, 167], "min_samples_leaf": [121, 122, 159, 160, 167, 185], "minimum": [121, 148, 160, 166, 167, 168, 170], "branch": [121, 167], "promot": [121, 137], "altogeth": 121, "param_distribut": [121, 160, 162], "search_cv": 121, "n_iter": [121, 124, 155, 160, 162, 185], "param_": [121, 124, 127, 156, 160], "mean_test_error": [121, 124], "std_test_error": [121, 124], "cv_results_": [121, 124, 127, 156, 158, 160, 162, 185], "mean_test_scor": [121, 124, 127, 156, 158, 159, 160, 162, 185], "std_test_scor": [121, 124, 156, 158, 159, 160], "sort_valu": [121, 124, 156, 160, 162], "param_max_featur": [121, 124], "param_max_leaf_nod": 121, "param_min_samples_leaf": 121, "108263": 121, "349563": 121, "850820": 121, "472980": 121, "299892": 121, "408875": 121, "107302": 121, "453772": 121, "378509": 121, "632535": 121, "827916": 121, "451935": 121, "824775": 121, "640650": 121, "291459": 121, "743104": 121, "927279": 121, "348528": 121, "981786": 121, "566974": 121, "role": 121, "inter": 121, "refit": [121, 154, 158, 161], "overlook": 121, "stat": [121, 124, 160], "loguniform": [121, 160], "param_n_estim": [121, 124], "param_learning_r": 121, "160519": 121, "877832": 121, "422907": 121, "110585": 121, "782952": 121, "291240": 121, "771785": 121, "791215": 121, "539520": 121, "109889": 121, "014289": 121, "384717": 121, "709894": 121, "536440": 121, "385697": 121, "637819": 121, "535730": 121, "338066": 121, "07502": 121, "457866": 121, "704599": 121, "0351": 121, "558900": 121, "578629": 121, "202432": 121, "387176": 121, "610988": 121, "462636": 121, "114017": 121, "846987": 121, "088556": 121, "243538": 121, "720131": 121, "010904": 121, "847050": 121, "683326": 121, "421054": 121, "384704": 121, "791104": 121, "070357": 121, "007841": 121, "789595": 121, "167568": 121, "131005": 121, "850380": 121, "190477": 121, "819015": 121, "976351": 121, "033815": 121, "765509": 121, "974672": 121, "125207": 121, "363288": 121, "040982": 121, "081715": 121, "373374": 121, "071555": 121, "014937": 121, "531295": 121, "113892": 121, "rank": [121, 127, 191], "hassl": 122, "354": 122, "087": 122, "min_samples_split": [122, 167], "523": [122, 138], "107": 122, "bagging_regressor": 122, "642": [122, 137], "083": 122, "\u00b5s": 122, "decent": [122, 159, 160], "modif": 123, "inject": [123, 141], "decorrel": 123, "categorical_encod": 123, "scores_tre": 123, "820": [123, 137], "006": [123, 127], "scores_bagged_tre": 123, "846": 123, "randomforestclassifi": [123, 129, 130], "scores_random_forest": 123, "004": 123, "disabl": [123, 136, 142], "sqrt": 123, "literatur": 123, "agnost": 123, "param": [124, 127, 156, 159], "bootstrap_featur": 124, "estimator__ccp_alpha": 124, "estimator__criterion": 124, "estimator__max_depth": 124, "estimator__max_featur": 124, "estimator__max_leaf_nod": 124, "estimator__min_impurity_decreas": 124, "estimator__min_samples_leaf": 124, "estimator__min_samples_split": 124, "estimator__min_weight_fraction_leaf": 124, "estimator__random_st": 124, "estimator__splitt": 124, "max_sampl": 124, "oob_scor": 124, "verbos": [124, 157, 160, 162, 187], "warm_start": 124, "param_max_sampl": 124, "param_estimator__max_depth": 124, "456533": 124, "182241": 124, "525065": 124, "298821": 124, "139530": 124, "423465": 124, "381965": 124, "126641": 124, "513850": 124, "174667": 124, "650547": 124, "064347": 124, "751006": 124, "338440": 124, "374693": 124, "414905": 124, "097428": 124, "752504": 124, "143232": 124, "165292": 124, "655313": 124, "926118": 124, "278847": 124, "853100": 124, "448280": 124, "187587": 124, "928912": 124, "838754": 124, "946150": 124, "844826": 124, "986043": 124, "122050": 124, "053572": 124, "123527": 124, "907842": 124, "208966": 124, "525999": 124, "488946": 124, "666802": 124, "349725": 124, "gram": [125, 143], "367": 125, "017": 125, "data_rang": 125, "forest_predict": 125, "gbdt_train_scor": 126, "gbdt_validation_scor": 126, "gbdt_train_error": 126, "gbdt_validation_error": 126, "forest_train_scor": 126, "forest_validation_scor": 126, "forest_train_error": 126, "forest_validation_error": 126, "sharex": 126, "sharei": 126, "set_ylabel": 126, "n_estimators_": 126, "hist_gbdt": 127, "839": 127, "best_estimator_": 127, "528": 127, "447": 127, "576": 127, "290": 127, "414": 127, "index_column": 127, "inner_cv_result": 127, "cv_idx": 127, "search_cv_result": 127, "set_index": [127, 136, 142, 146], "renam": [127, 156, 159, 160, 162, 185], "coincid": [127, 148], "bioinformat": [128, 131], "rna": [128, 131], "seq": [128, 131], "ten": [128, 131], "anova": [128, 129, 131], "pre": [128, 131], "princip": 129, "make_classif": [129, 130], "n_inform": [129, 130, 135, 141], "n_redund": [129, 130], "univari": 129, "model_without_select": [129, 130], "feature_select": [129, 130, 131], "selectkbest": [129, 131], "f_classif": [129, 131], "model_with_select": [129, 130], "score_func": [129, 131], "cv_results_without_select": [129, 130], "incorpor": 129, "cv_results_with_select": [129, 130], "analyz": [129, 185], "swap": 129, "swaplevel": [129, 130], "Of": 129, "scores_": 129, "percentil": 129, "alien": 129, "primari": 129, "feature_importances_": 130, "suffici": 130, "class_sep": 130, "selectfrommodel": 130, "feature_selector": [130, 131], "overestim": 130, "100000": [131, 137], "550": 131, "data_subset": 131, "940": 131, "succeed": 131, "legit": 131, "leak": 131, "data_train_subset": 131, "520": 131, "460": 131, "boilerpl": 131, "linear_model_flipper_mass": [132, 138, 145], "flipper_length": [132, 138, 145], "weight_flipper_length": [132, 138, 143, 145], "intercept_body_mass": [132, 138, 143, 145], "body_mass": [132, 138, 145], "flipper_length_rang": [132, 138, 143, 145], "goodness_fit_measur": [132, 138], "true_valu": [132, 138], "scalar": [132, 138], "model_idx": [132, 138], "seed": [133, 139], "reproduct": [133, 139], "data_max": [133, 139, 144], "data_min": [133, 139, 144], "len_data": [133, 139, 144], "full_data": [133, 139, 144], "reshap": [133, 139, 144], "geographi": [134, 140], "make_regress": [135, 141], "2_000": [135, 141], "566665": [135, 141], "192077": [135, 141], "infinit": [136, 142], "yourself": [136, 142], "penguins_train": [136, 142, 146], "penguins_test": [136, 142, 146], "candid": [136, 142, 160, 162, 163], "cs": [136, 142], "augment": [137, 147], "linear_regress": [137, 139, 140, 141, 143, 144, 170], "4190": 137, "13334": 137, "943": 137, "20292": 137, "681": 137, "model_first_fold": 137, "weights_linear_regress": 137, "homogen": 137, "_ridg": 137, "216": 137, "linalgwarn": 137, "rcond": 137, "672e": 137, "linalg": 137, "xy": 137, "assume_a": 137, "po": 137, "overwrite_a": 137, "67257e": 137, "75536e": 137, "67367e": 137, "5546e": 137, "75974e": 137, "82401e": 137, "96672e": 137, "68318e": 137, "68514e": 137, "4373": 137, "153": 137, "942": 137, "7303": 137, "589": 137, "4950": 137, "732": 137, "weights_ridg": [137, 142], "shrunk": 137, "omit": 137, "annual": 137, "unscal": 137, "4347": 137, "036": 137, "666": 137, "5508": 137, "472": 137, "1816": 137, "sweet": 137, "1_000_000": 137, "enhanc": 137, "occurr": 137, "presenc": 137, "divis": 137, "beforehand": 137, "store_cv_valu": 137, "4301": 137, "922": 137, "826": 137, "4458": 137, "556": 137, "462": 137, "192": [137, 160], "mse_alpha": 137, "cv_values_": 137, "cv_alpha": 137, "010000": 137, "10805": 137, "760257": 137, "7859": 137, "294941": 137, "012589": 137, "9835": 137, "307516": 137, "6588": 137, "155387": 137, "015849": 137, "8925": 137, "577610": 137, "5409": 137, "395931": 137, "019953": 137, "8100": 137, "047161": 137, "4353": 137, "016704": 137, "025119": 137, "7375": 137, "000527": 137, "3438": 137, "794963": 137, "031623": 137, "6758": 137, "474506": 137, "2674": 137, "639258": 137, "039811": 137, "6250": 137, "760542": 137, "2056": 137, "950531": 137, "050119": 137, "5846": 137, "266069": 137, "1572": 137, "763214": 137, "063096": 137, "5536": 137, "215174": 137, "1202": 137, "943947": 137, "079433": 137, "5311": 137, "576140": 137, "925": 137, "547806": 137, "5165": 137, "715922": 137, "718": 137, "596591": 137, "125893": 137, "5096": 137, "474028": 137, "562": 137, "042934": 137, "158489": 137, "5107": 137, "489238": 137, "439": 137, "763119": 137, "199526": 137, "5208": 137, "638340": 137, "345": 137, "021050": 137, "251189": 137, "5415": 137, "385561": 137, "489290": 137, "316228": 137, "5746": 137, "801131": 137, "353": 137, "672626": 137, "398107": 137, "6222": 137, "125875": 137, "535": 137, "737882": 137, "501187": 137, "6856": 137, "124687": 137, "747311": 137, "630957": 137, "7654": 137, "025118": 137, "1192": 137, "443073": 137, "794328": 137, "8607": 137, "322588": 137, "1638": 137, "892918": 137, "9691": 137, "803104": 137, "2144": 137, "446582": 137, "4_500": 137, "11_000": 137, "salt": 137, "cook": 137, "best_alpha": 137, "07943282347242812": 137, "12589254117941676": 137, "31622776601683794": 137, "09999999999999999": 137, "stem": 137, "15000": 138, "14000": 138, "predicted_body_mass": [138, 143, 145], "misleadingli": 138, "mse": [138, 139, 144, 151], "ab": [138, 144], "2764": 138, "854": 138, "338": 138, "573": 138, "041": 138, "mean_squared_error": [139, 143, 144, 151], "38118083900814376": 139, "data_2d": 139, "linearregressionlinearregress": [139, 143], "37117544002508424": 139, "109": [140, 160], "89587004": 141, "41128042": 141, "20542454": 141, "18954462": 141, "11129768": 141, "43893463e": 141, "74709879e": 141, "11755293e": 141, "36787998e": 141, "36848689e": 141, "19467317e": 141, "52329981e": 141, "29476881e": 141, "norm": 141, "1e14": 141, "pose": 141, "invert": [141, 159], "6313933": 141, "46802113": 141, "20549345": 141, "18929961": 141, "11117205": 141, "invers": [141, 142], "89417991": 141, "40406338": 141, "61648035": 141, "56789883": 141, "33351616": 141, "collinear": 141, "618": 141, "870": [141, 161], "817": 141, "302": 141, "763": 141, "835": [141, 161], "1216": 141, "559": 141, "684": 141, "1168": 141, "single_featur": 141, "int32": [141, 155, 162, 167], "x_tran": 141, "centralair_n": 141, "centralair_i": 141, "1163": 141, "1164": 141, "1165": 141, "1167": 141, "arbitrarili": 141, "binary_onli": 141, "kept": 141, "symmetri": 141, "n_categori": 141, "set_param": [142, 157, 161, 187, 191], "logisticregression__c": [142, 185, 187], "rdbu_r": [142, 146], "perpendicular": [142, 163], "lowest": 143, "68556640610011": 143, "5780": 143, "831358077066": 143, "inferred_body_mass": 143, "model_error": 143, "154546": 143, "313": 143, "sort": 144, "global": 144, "cubic": [144, 180], "expans": [144, 147], "data_expand": 144, "polynomial_regress": 144, "include_bia": 144, "440892098500626e": 144, "encourag": 144, "svr": 144, "poli": 144, "medium": 144, "10_000": [144, 163], "nystroem": 144, "binned_regress": 144, "kernel_approxim": 144, "nystroem_regress": 144, "n_compon": 144, "181": 145, "3750": 145, "186": [145, 152], "3800": 145, "195": 145, "193": [145, 160], "3450": 145, "190": 145, "3650": 145, "formul": 145, "2700": 145, "6300": 145, "heavier": [145, 164], "formula": 145, "shorter": 145, "13000": 145, "millimet": 145, "body_mass_180": 145, "body_mass_181": 145, "7200": 145, "7240": 145, "goe": [145, 148], "170mm": 145, "230mm": 145, "redefin": 145, "groupbi": 146, "obliqu": [146, 163], "horizont": [146, 167], "vertic": 146, "coordin": [146, 158, 159, 162, 185], "inclin": 146, "coef0": 146, "x0": 146, "coef1": 146, "x1": 146, "hold": [147, 159, 162, 185, 191], "interlac": [147, 167], "make_moon": 147, "moon": 147, "newaxi": [147, 167], "data_moon": 147, "target_moon": 147, "depict": [147, 164], "push": 147, "surround": 147, "make_gaussian_quantil": 147, "n_class": 147, "gauss": 147, "data_gauss": 147, "target_gauss": 147, "gaussian": 147, "radial": 147, "basi": 147, "kernel_model": 147, "donor": 148, "ago": 148, "new_donor": 148, "That": [148, 153, 156, 158], "505": 148, "665": 148, "615": 148, "743": 148, "374": 148, "7780748663101604": 148, "accuracy_scor": 148, "778": 148, "finer": 148, "confusionmatrixdisplai": 148, "incorrect": 148, "erron": 148, "tp": 148, "tn": 148, "fn": 148, "fp": 148, "precision_scor": [148, 149, 152], "recall_scor": 148, "pos_label": [148, 149, 152], "124": 148, "mislabel": 148, "ratio": 148, "dummy_classifi": 148, "762": 148, "balanced_accuracy_scor": 148, "haven": 148, "confid": 148, "target_proba_predict": 148, "classes_": [148, 163, 169, 187], "271820": 148, "728180": 148, "451764": 148, "548236": 148, "445211": 148, "554789": 148, "441577": 148, "558423": 148, "870583": 148, "129417": 148, "equivalence_pred_proba": 148, "idxmax": 148, "graph": 148, "precisionrecalldisplai": 148, "disp": 148, "ax_": 148, "tpr": 148, "ppv": 148, "ap": 148, "preval": 148, "discrimin": 148, "roccurvedisplai": 148, "dash": 148, "worst": 148, "ambigu": [149, 152], "valueerror": [149, 152], "exc": [149, 152], "_valid": [149, 152], "794": [149, 152, 153], "recent": [149, 152], "_scorer": [149, 152], "__call__": [149, 152], "scorer": [149, 150, 152, 153], "_score": [149, 152], "cached_cal": [149, 152], "arg": [149, 152, 160], "kwarg": [149, 152, 160], "282": [149, 152], "_sign": [149, 152], "_score_func": [149, 152], "y_true": [149, 152], "_kwarg": [149, 152], "_classif": [149, 152], "1954": [149, 152], "precision_recall_fscore_support": [149, 152], "1573": [149, 152], "_check_set_wise_label": [149, 152], "1382": [149, 152], "catch": [149, 152], "make_scor": [149, 152], "syntax": [150, 153], "iowa": 151, "intro": [151, 171], "said": 151, "996": 151, "902": 151, "2064": 151, "736": 151, "6872520581075487": 151, "dummy_regressor": 151, "608": 151, "disadvantag": 151, "median_absolute_error": 151, "137": [151, 152], "mean_absolute_percentage_error": 151, "574": 151, "predicted_actu": 151, "axlin": 151, "ntarget": 151, "quantiletransform": [151, 191], "transformedtargetregressor": 151, "n_quantil": [151, 191], "900": 151, "output_distribut": 151, "model_transformed_target": 151, "633": 152, "507": 152, "113": 152, "00329304": 152, "00338125": 152, "00345182": 152, "00340033": 152, "00337386": 152, "00338674": 152, "00333381": 152, "00331569": 152, "00332189": 152, "00337768": 152, "00291085": 152, "00273776": 152, "00286865": 152, "00275493": 152, "00285649": 152, "00272155": 152, "00273085": 152, "00274348": 152, "00274253": 152, "00274396": 152, "test_accuraci": 152, "26666667": 152, "50666667": 152, "77333333": 152, "58666667": 152, "64864865": 152, "75675676": 152, "test_balanced_accuraci": 152, "38450292": 152, "46637427": 152, "66081871": 152, "40643275": 152, "42397661": 152, "44736842": 152, "54239766": 152, "73684211": 152, "4623323": 152, "51186791": 152, "892": 153, "225": 153, "test_r2": 153, "test_neg_mean_absolute_error": 153, "848721": 153, "256799": 153, "816374": 153, "084083": 153, "813513": 153, "113367": 153, "814138": 153, "448279": 153, "637473": 153, "370341": 153, "exhaust": [154, 161, 188], "cat_preprocessor": [154, 156, 158, 160, 161], "sparse_threshold": [154, 156, 158, 160, 161], "kneighborsregressor": [155, 162], "with_mean": [155, 162], "with_std": [155, 162], "reload": [156, 160], "dealt": 156, "ordinalencoderordinalencod": [156, 158, 160], "remainderpassthroughpassthroughhistgradientboostingclassifierhistgradientboostingclassifi": [156, 158, 160], "classifier__learning_r": [156, 158, 160, 161], "classifier__max_leaf_nod": [156, 158, 160, 161], "model_grid_search": [156, 158], "charg": 156, "rapidli": 156, "ascend": [156, 160, 162], "mean_fit_tim": [156, 159], "std_fit_tim": [156, 159], "mean_score_tim": [156, 159], "std_score_tim": [156, 159], "param_classifier__learning_r": [156, 158, 159], "param_classifier__max_leaf_nod": [156, 158, 159], "split0_test_scor": [156, 159], "split1_test_scor": [156, 159], "rank_test_scor": [156, 158, 159, 160], "555677": 156, "049212": 156, "246502": 156, "011545": 156, "868912": 156, "867213": 156, "868063": 156, "000850": 156, "424974": 156, "004050": 156, "224132": 156, "003323": 156, "866783": 156, "866066": 156, "866425": 156, "000359": 156, "142677": 156, "006164": 156, "091421": 156, "001444": 156, "classifier__": 156, "858648": 156, "862408": [156, 158, 159], "860528": 156, "001880": 156, "153695": 156, "011157": 156, "094709": 156, "001546": 156, "859358": 156, "859514": 156, "859436": 156, "000078": 156, "144618": 156, "001319": 156, "090917": 156, "000673": 156, "855536": 156, "856129": 156, "855832": 156, "000296": 156, "shorten": 156, "param_classifier__": 156, "prefix": [156, 159], "column_result": [156, 160], "shorten_param": [156, 159, 160, 185], "__": [156, 157, 159, 160, 185], "rsplit": [156, 159, 160, 185], "853266": 156, "000515": 156, "843330": 156, "002917": 156, "817832": 156, "001124": 156, "797166": 156, "000715": 156, "288200": 156, "050539": 156, "283476": 156, "003775": 156, "262564": 156, "006326": 156, "heatmap": [156, 159], "pivoted_cv_result": 156, "pivot_t": 156, "ylgnbu": 156, "vmin": 156, "vmax": 156, "invert_yaxi": 156, "degrad": 156, "patholog": 156, "accordingli": 156, "hyperparamt": 156, "interchang": 157, "recogniz": 157, "spell": 157, "classifier__c": [157, 185, 187], "parameter_nam": 157, "middl": 157, "preprocessor__copi": 157, "preprocessor__with_mean": 157, "preprocessor__with_std": 157, "classifier__class_weight": 157, "classifier__du": 157, "classifier__fit_intercept": 157, "classifier__intercept_sc": 157, "classifier__l1_ratio": 157, "classifier__max_it": 157, "classifier__multi_class": 157, "classifier__n_job": 157, "classifier__penalti": 157, "classifier__random_st": 157, "classifier__solv": 157, "classifier__tol": 157, "classifier__verbos": 157, "classifier__warm_start": 157, "001": [157, 160], "799": 157, "622088": 158, "097119": 158, "863241": 158, "615943": 158, "097753": 158, "860784": 158, "621131": 158, "100581": 158, "860360": [158, 159], "621246": 158, "100806": 158, "621342": 158, "098672": 158, "866912": 158, "863": 158, "embed": 158, "864195": 158, "000061": 158, "870910": 158, "869743": 158, "000532": 158, "866058": 158, "001515": 158, "concern": 158, "extern": 158, "877": 158, "schemat": 158, "green": 158, "intermedi": [158, 159], "rough": 158, "cv_test_scor": 158, "871": 158, "apprehend": 158, "cv_inner": 158, "cv_outer": 158, "greed": 158, "cv_fold": 158, "estimator_in_fold": 158, "vote": 158, "randomized_search_result": [159, 160, 185], "param_classifier__l2_regular": 159, "param_classifier__max_bin": 159, "param_classifier__min_samples_leaf": 159, "split2_test_scor": 159, "split3_test_scor": 159, "split4_test_scor": 159, "540456": 159, "062725": 159, "052069": 159, "002661": 159, "467047": 159, "550075": 159, "classifier__l2_regular": [159, 160], "4670474863": 159, "856558": 159, "862271": 159, "857767": 159, "854491": 159, "856675": 159, "857552": 159, "002586": 159, "110536": 159, "033403": 159, "074142": 159, "002165": 159, "015449": 159, "001146": 159, "0154488709": 159, "758974": 159, "758941": 159, "758947": [159, 160], "000013": [159, 160], "323": [159, 163], "137484": 159, "053150": 159, "092993": 159, "029005": 159, "095093": 159, "004274": 159, "0950934559": 159, "783267": 159, "776413": 159, "779143": 159, "771341": 159, "010357": 159, "311": 159, "935108": 159, "202993": 159, "118105": 159, "023658": 159, "003621": 159, "001305": 159, "0036210968": 159, "255219": 159, "038301": 159, "056048": 159, "016736": 159, "000081": [159, 160], "407382": 159, "1060737427": 159, "495": 159, "452411": 159, "023006": 159, "055563": 159, "000846": 159, "000075": 159, "364373": 159, "4813767874": 159, "858332": 159, "865001": 159, "862681": 159, "860770": 159, "861429": 159, "002258": 159, "133042": 159, "014456": 159, "078186": 159, "002199": 159, "065946": 159, "001222": 159, "0659455480": 159, "497": [159, 160], "911828": 159, "017167": 159, "076563": 159, "005130": 159, "460025": 159, "044408": 159, "4600250010": 159, "839907": 159, "849713": 159, "846847": 159, "846028": 159, "844390": 159, "845377": 159, "003234": 159, "140": 159, "498": 159, "168120": 159, "121819": 159, "061283": 159, "000760": 159, "000068": 159, "287904": 159, "227": 159, "146": 159, "7755366885": 159, "861881": 159, "859951": 159, "861862": 159, "862221": 159, "001623": 159, "499": [159, 160], "823774": 159, "120686": 159, "060351": 159, "014958": 159, "445218": 159, "005112": 159, "4452178932": 159, "764569": 159, "765902": 159, "764947": 159, "765083": 159, "765281": 159, "000535": 159, "319": 159, "l2_regular": [159, 160, 185], "max_bin": [159, 160, 185], "score_bin": 159, "cut": [159, 167], "set_palett": 159, "ylgnbu_r": 159, "set_xscal": 159, "set_yscal": 159, "band": 159, "plotli": [159, 162, 185], "px": [159, 162, 185], "parallel_coordin": [159, 162, 185], "log10": [159, 185], "log2": [159, 185], "color_continuous_scal": [159, 162, 185], "spread": [159, 185], "undo": 159, "yellow": 159, "tick": 159, "untract": 160, "situat": 160, "stochast": 160, "loguniform_int": 160, "__init__": 160, "_distribut": 160, "rv": 160, "processor": 160, "1e3": 160, "classifier__min_samples_leaf": 160, "classifier__max_bin": 160, "255": 160, "model_random_search": [160, 162], "597": 160, "_distn_infrastructur": 160, "rv_continuous_frozen": 160, "0x7fba26306070": 160, "0x7fba257d2880": 160, "__main__": 160, "0x7fba257ce7c0": 160, "0x7fba257ce520": 160, "0x7fba257d23a0": 160, "randomizedsearchcvrandomizedsearchcv": 160, "pprint": 160, "12816745209735544": 160, "06770728079441525": 160, "128167": 160, "067707": 160, "861702": 160, "002244": 160, "061511": 160, "859545": 160, "003664": 160, "008849": 160, "552886": 160, "179": 160, "859027": 160, "002096": 160, "200322": 160, "028161": 160, "851574": 160, "001622": 160, "000033": 160, "006561": 160, "209": 160, "817859": 160, "002317": 160, "799448": 160, "029782": 160, "807513": 160, "001863": 160, "138199": 160, "675442": 160, "801916": 160, "003067": 160, "136257": 160, "0138": 160, "801152": 160, "002997": 160, "186824": 160, "027647": 160, "762632": 160, "013421": 160, "476059": 160, "001836": 160, "to_csv": 160, "208": 160, "011775": 160, "076653": 160, "871393": 160, "001588": 160, "343": 160, "000404": 160, "244503": 160, "229": 160, "871339": 160, "002741": 160, "994918": 160, "077047": 160, "870793": 160, "001993": 160, "036232": 160, "224702": 160, "236": 160, "869837": 160, "000808": 160, "327": 160, "733808": 160, "036786": 160, "241": 160, "869673": 160, "002417": 160, "232": 160, "000097": 160, "976823": 160, "448205": 160, "253714": 160, "000001": 160, "828574": 160, "144": 160, "344": 160, "000003": 160, "091079": 160, "000444": 160, "236325": 160, "344629": 160, "207156": 160, "357": 160, "000026": 160, "075318": 160, "241053": 160, "valuabl": 160, "allevi": 160, "best_scor": 161, "best_param": 161, "lr": 161, "mln": 161, "mean_scor": 161, "789": 161, "813": 161, "842": 161, "847": 161, "855": 161, "828": 161, "288": 161, "437": 161, "best_lr": 161, "best_mln": 161, "kneighborsregressor__n_neighbor": 162, "standardscaler__with_mean": 162, "standardscaler__with_std": 162, "welcom": 162, "column_name_map": 162, "param_kneighborsregressor__n_neighbor": 162, "param_standardscaler__with_mean": 162, "param_standardscaler__with_std": 162, "boolean": 162, "column_scal": 162, "687926": 162, "674812": 162, "668778": 162, "648317": 162, "629772": 162, "215": 162, "617295": 162, "464": 162, "567164": 162, "508809": 162, "486503": 162, "103390": 162, "061394": 162, "033122": 162, "017583": 162, "007987": 162, "002900": 162, "238830": 162, "diverg": 162, "tealros": 162, "kneighbor": 162, "plot_tre": [163, 165, 167, 168, 169], "class_nam": [163, 169], "impur": [163, 169], "inferior": 163, "superior": 163, "settabl": 163, "45mm": 163, "sample_1": 163, "sample_2": 163, "y_pred_proba": 163, "y_proba_class_0": 163, "adelie_proba": 163, "chinstrap_proba": 163, "gentoo_proba": 163, "037": 163, "disregard": 163, "moment": 163, "sample_3": 163, "63975155": 163, "32298137": 163, "03726708": 163, "fairli": 163, "palmer": 164, "anatom": 164, "set_size_inch": 164, "deduc": 164, "extrapol": [166, 170, 177], "superimpos": [166, 170], "data_clf_column": 167, "target_clf_column": 167, "data_clf": 167, "data_reg_column": 167, "target_reg_column": 167, "data_reg": 167, "fit_and_plot_classif": 167, "fit_and_plot_regress": 167, "tree_clf": 167, "tree_reg": 167, "asymmetri": 167, "make_blob": 167, "blob": 167, "x_1": 167, "y_1": 167, "x_2": 167, "y_2": 167, "min_impurity_decreas": 167, "asymmetr": 167, "priori": 168, "3698": 168, "5032": 168, "target_predicted_linear_regress": 170, "target_predicted_tre": 170, "interpol": 170, "offset": 170, "175": 170, "shortest": 170, "longest": 170, "m3": [171, 184, 186], "m5": [171, 173, 174, 175, 182], "glossari": 171, "acknowledg": 171, "prune": 177, "children": 178, "increment": 179, "refin": 179, "author": 183, "re": [183, 191], "circular": 185, "budget": [185, 189], "sandbox": 185, "badli": 185, "histgradientbosstingclassifi": 187, "get_paramet": 187, "penguins_non_miss": 191, "anim": 191, "param_valu": 191, "powertransform": 191, "all_preprocessor": 191, "cox": 191, "classifier__n_neighbor": 191, "forgot": 191, "enabl": 191}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"acknowledg": 0, "figur": 0, "attribut": [0, 3], "The": [1, 6, 78, 81, 108, 109, 110, 111, 148, 164, 171], "adult": [1, 78], "censu": [1, 78], "dataset": [1, 2, 6, 78, 84, 85, 95, 108, 109, 110, 111, 112, 158, 164], "descript": 2, "glossari": 3, "main": [3, 14, 23, 34, 41, 62, 76, 132, 138, 177, 189], "term": 3, "us": [3, 6, 11, 81, 90, 129, 130, 143, 156, 160], "thi": [3, 6], "cours": [3, 36], "classif": [3, 30, 38, 146, 147, 148, 163, 164, 173], "classifi": [3, 148], "cross": [3, 20, 21, 81, 90, 100, 101, 106], "valid": [3, 6, 20, 21, 63, 71, 81, 90, 100, 101, 106, 107], "data": [3, 6, 67, 69, 72, 78, 81, 84, 85, 86, 89, 90, 105, 132, 138], "matrix": [3, 148], "input": 3, "earli": 3, "stop": 3, "estim": [3, 106], "featur": [3, 32, 42, 86, 89, 92, 94, 112, 129, 130, 137, 141, 144, 171], "variabl": [3, 78, 89, 90, 92, 94, 112], "descriptor": 3, "covari": 3, "gener": [3, 107, 167], "perform": [3, 96, 171], "predict": [3, 6, 85, 89, 148, 156, 158, 160, 171], "statist": 3, "hyperparamet": [3, 12, 121, 123, 156, 157, 158, 159, 160, 167, 171, 174, 190], "infer": 3, "learn": [3, 6, 13, 22, 33, 36, 40, 54, 60, 63, 69, 74, 75, 85, 95, 100, 112, 114, 143, 145, 157, 171, 176, 188], "paramet": [3, 137, 167], "meta": 3, "model": [3, 6, 8, 9, 19, 38, 39, 42, 49, 50, 52, 69, 71, 81, 85, 86, 90, 95, 96, 112, 122, 130, 132, 137, 138, 146, 156, 158, 160, 171, 172, 175], "overfit": [3, 61, 66, 107], "predictor": 3, "regress": [3, 31, 48, 137, 143, 144, 145, 151, 164, 168, 182], "regressor": 3, "regular": [3, 49, 52, 137], "penal": 3, "sampl": [3, 99, 100], "instanc": 3, "observ": 3, "supervis": 3, "target": [3, 42, 85, 144], "label": [3, 6], "annot": 3, "test": [3, 58, 84, 85, 106], "set": [3, 157], "train": [3, 58, 84, 85, 106], "fit": [3, 69, 85, 86, 90], "transform": 3, "underfit": [3, 61, 66, 107], "unsupervis": 3, "other": [3, 167], "notebook": [4, 78, 81, 84, 85], "time": [4, 6, 13, 22, 33, 40, 60, 75, 176, 188], "tabl": [5, 171], "content": [5, 171], "conclud": [6, 7, 171], "remark": [6, 7, 171], "last": 6, "lesson": [6, 112], "goal": 6, "big": 6, "messag": 6, "mooc": [6, 36], "1": [6, 77, 112], "machin": [6, 54, 171], "pipelin": [6, 74, 89, 92, 94, 95, 114, 171], "2": [6, 64, 112], "adapt": [6, 113], "complex": [6, 114], "3": [6, 112, 191], "specif": [6, 90], "go": [6, 14, 23, 34, 41, 62, 76, 177, 189], "further": [6, 14, 23, 34, 41, 62, 76, 177, 189], "more": [6, 90, 106], "about": [6, 123], "scikit": [6, 36, 69, 74, 85, 95, 114, 143, 145, 157], "we": [6, 95], "ar": 6, "an": [6, 89], "open": 6, "sourc": 6, "commun": 6, "topic": 6, "have": 6, "cover": 6, "studi": 6, "bring": 6, "valu": 6, "bigger": 6, "pictur": 6, "beyond": [6, 147], "evalu": [6, 81, 89, 90, 148, 158, 171], "matter": 6, "small": 6, "part": 6, "problem": 6, "most": 6, "technic": 6, "craft": 6, "all": 6, "how": 6, "choic": [6, 20], "output": 6, "bias": 6, "versu": [6, 56, 59], "causal": 6, "societ": 6, "impact": 6, "intuit": [8, 9, 39, 50, 52, 172, 175], "ensembl": [8, 9, 10, 11, 12, 122, 171], "bag": [8, 114], "boost": [9, 10, 113, 119, 120, 121], "base": [10, 89, 90, 172, 175], "method": [11, 12], "bootstrap": [11, 114], "tune": [12, 121, 137, 156, 158, 160, 171, 184, 186], "modul": [13, 22, 33, 40, 60, 75, 176, 188], "overview": [13, 22, 33, 40, 60, 75, 176, 188], "what": [13, 22, 33, 40, 60, 75, 176, 188], "you": [13, 22, 33, 40, 60, 75, 176, 188], "befor": [13, 22, 33, 40, 60, 75, 176, 188], "get": [13, 22, 33, 40, 60, 75, 157, 176, 188], "start": [13, 22, 33, 40, 60, 75, 176, 188], "object": [13, 22, 33, 40, 60, 75, 176, 188], "schedul": [13, 22, 33, 40, 60, 75, 176, 188], "take": [14, 23, 34, 41, 62, 76, 112, 177, 189], "awai": [14, 23, 34, 41, 62, 76, 112, 177, 189], "wrap": [14, 18, 23, 29, 34, 41, 51, 62, 64, 76, 77, 177, 183, 189, 191], "up": [14, 18, 23, 29, 34, 41, 51, 62, 64, 76, 77, 120, 177, 183, 189, 191], "To": [14, 23, 34, 41, 62, 76, 177, 189], "quiz": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 43, 44, 45, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 178, 179, 180, 181, 183, 185, 187, 191], "m6": [15, 16, 17, 115, 116, 117, 118, 124, 125, 126, 127], "01": [15, 24, 43, 53, 65, 68, 79, 80, 97, 98, 102, 103, 115, 124, 128, 131, 132, 138, 154, 161, 165, 169, 178, 187], "question": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 43, 44, 45, 46, 47, 51, 53, 55, 57, 64, 65, 68, 70, 73, 77, 178, 179, 180, 181, 183, 185, 187, 191], "02": [16, 25, 44, 57, 70, 82, 87, 116, 125, 133, 139, 149, 152, 155, 162, 166, 170, 179, 185], "03": [17, 26, 45, 55, 73, 83, 88, 117, 126, 134, 140, 150, 153, 180], "6": 18, "compar": [19, 58, 96], "simpl": [19, 96], "baselin": [19, 96, 148], "nest": [21, 101], "m7": [24, 25, 26, 27, 28, 98, 103, 149, 150, 152, 153], "04": [27, 46, 91, 93, 118, 127, 135, 141, 181], "05": [28, 47, 92, 94, 136, 142], "7": 29, "metric": [30, 31, 148], "caveat": 32, "select": [32, 89, 90, 129, 130, 171], "introduct": 36, "present": [36, 112], "welcom": 36, "follow": 36, "prerequisit": [36, 132, 138], "materi": 36, "social": 36, "network": 36, "linear": [38, 39, 42, 48, 49, 50, 52, 112, 137, 143, 144, 145, 146, 147, 171], "non": [42, 105, 144], "relationship": [42, 144], "m4": [43, 44, 45, 46, 47, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142], "4": 51, "intro": 53, "introduc": 54, "concept": [54, 171], "m2": [55, 57, 65, 97, 102], "bia": [56, 59], "varianc": [56, 59], "error": [58, 106], "trade": 59, "off": 59, "curv": [63, 100, 107], "tabular": 67, "explor": 67, "m1": [68, 70, 73, 79, 80, 82, 83, 87, 88, 91, 92, 93, 94], "numer": [69, 84, 86, 90, 92, 94], "handl": 72, "categor": [72, 89, 90, 92, 94], "visual": [74, 78, 95], "jupyt": [74, 95], "first": [78, 85, 95], "look": [78, 123], "our": [78, 89, 156, 158, 160], "load": [78, 84, 85, 95, 132, 138, 158], "column": [78, 90], "inspect": [78, 112], "creat": [78, 95, 167], "decis": [78, 119, 121, 163, 167, 168, 171, 173, 174, 182], "rule": 78, "hand": 78, "recap": [78, 81, 84, 85], "exercis": [79, 80, 82, 83, 87, 88, 91, 92, 93, 94, 97, 98, 102, 103, 115, 116, 117, 118, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 149, 150, 152, 153, 154, 155, 161, 162, 165, 166, 169, 170], "solut": [80, 87, 88, 93, 94, 102, 103, 124, 125, 126, 127, 131, 138, 139, 140, 141, 142, 152, 153, 161, 162, 169, 170], "prepar": [81, 86], "need": 81, "work": 84, "entir": 84, "identifi": [84, 89], "split": [84, 85], "panda": 85, "separ": [85, 147], "make": 85, "preprocess": 86, "encod": [89, 92, 94, 141], "type": [89, 90], "strategi": 89, "categori": [89, 92, 94], "ordin": 89, "nomin": 89, "without": [89, 145, 158], "assum": 89, "ani": 89, "order": 89, "choos": 89, "togeth": 90, "dispatch": 90, "processor": 90, "power": 90, "refer": [92, 94], "scale": [92, 94, 112, 137], "integ": [92, 94], "code": [92, 94], "One": [92, 94], "hot": [92, 94, 141], "analysi": [94, 159, 190], "Then": 95, "final": 95, "score": 95, "group": 99, "effect": [100, 137, 167], "size": 100, "summari": [100, 106, 107], "stratif": 104, "i": 105, "d": 105, "framework": 106, "vs": [106, 107], "stabil": 106, "detail": [106, 123], "regard": 106, "cross_valid": 106, "am": 108, "hous": [108, 111], "bike": 109, "ride": 109, "blood": 110, "transfus": 110, "california": 111, "import": [112, 167], "0": 112, "sign": 112, "coeffici": 112, "A": [112, 123], "surpris": 112, "associ": 112, "check": 112, "spars": 112, "lasso": 112, "randomforest": 112, "feature_importances_": 112, "permut": 112, "discuss": 112, "adaboost": 113, "resampl": 114, "aggreg": 114, "gradient": [119, 120, 121], "tree": [119, 121, 163, 167, 168, 171, 172, 173, 174, 175, 182], "gbdt": 119, "speed": 120, "random": [121, 123, 160], "forest": [121, 123], "introductori": 122, "exampl": 122, "default": 123, "benefit": 129, "limit": 130, "definit": [132, 138], "fine": 137, "deal": 141, "correl": 141, "between": 141, "one": 141, "accuraci": 148, "confus": 148, "deriv": 148, "issu": 148, "class": 148, "imbal": 148, "differ": 148, "probabl": 148, "threshold": 148, "m3": [154, 155, 161, 162, 185, 187], "grid": 156, "search": [156, 159, 160, 190], "With": 158, "result": [159, 190], "build": 163, "penguin": 164, "m5": [165, 166, 169, 170, 178, 179, 180, 181], "helper": 167, "function": 167, "max_depth": 167, "best": 171, "appendix": 171, "interpret": 171, "5": 183, "autom": 184, "manual": 186}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})